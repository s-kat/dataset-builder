{"_get_stderr_fileno": {"line": 68, "args": [{"func_args": {}, "return_value": "2"}]}, "_format_trimmed": {"line": 1262, "args": [{"func_args": {"format": "' - {}'", "msg": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'", "available_width": "43"}, "return_value": "' - AttributeError: /usr/app/src/test_rep...'"}, {"func_args": {"format": "' - {}'", "msg": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'", "available_width": "53"}, "return_value": "' - AttributeError: /usr/app/src/test_repos/python-...'"}, {"func_args": {"format": "' - {}'", "msg": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'", "available_width": "55"}, "return_value": "' - AttributeError: /usr/app/src/test_repos/python-li...'"}, {"func_args": {"format": "' - {}'", "msg": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'", "available_width": "54"}, "return_value": "' - AttributeError: /usr/app/src/test_repos/python-l...'"}, {"func_args": {"format": "' - {}'", "msg": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'", "available_width": "57"}, "return_value": "' - AttributeError: /usr/app/src/test_repos/python-liba...'"}, {"func_args": {"format": "' - {}'", "msg": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'", "available_width": "46"}, "return_value": "' - AttributeError: /usr/app/src/test_repos/...'"}], "text": "def _format_trimmed(format: str, msg: str, available_width: int) -> Optional[str]:\n    \"\"\"Format msg into format, ellipsizing it if doesn't fit in available_width.\n\n    Returns None if even the ellipsis can't fit.\n    \"\"\"\n    # Only use the first line.\n    i = msg.find(\"\\n\")\n    if i != -1:\n        msg = msg[:i]\n\n    ellipsis = \"...\"\n    format_width = wcswidth(format.format(\"\"))\n    if format_width + len(ellipsis) > available_width:\n        return None\n\n    if format_width + wcswidth(msg) > available_width:\n        available_width -= len(ellipsis)\n        msg = msg[:available_width]\n        while format_width + wcswidth(msg) > available_width:\n            msg = msg[:-1]\n        msg += ellipsis\n\n    return format.format(msg)"}, "pluralize": {"line": 1350, "args": [{"func_args": {"count": "1", "noun": "'warnings'"}, "return_value": "(1, 'warning')"}, {"func_args": {"count": "6", "noun": "'error'"}, "return_value": "(6, 'errors')"}], "text": "def pluralize(count: int, noun: str) -> Tuple[int, str]:\n    # No need to pluralize words such as `failed` or `passed`.\n    if noun not in [\"error\", \"warnings\", \"test\"]:\n        return count, noun\n\n    # The `warnings` key is plural. To avoid API breakage, we keep it that way but\n    # set it to singular here so we can determine plurality in the same way as we do\n    # for `error`.\n    noun = noun.replace(\"warnings\", \"warning\")\n\n    return count, noun + \"s\" if count != 1 else noun"}, "format_session_duration": {"line": 1377, "args": [{"func_args": {"seconds": "2.5706064701080322"}, "return_value": "'2.57s'"}], "text": "def format_session_duration(seconds: float) -> str:\n    \"\"\"Format the given seconds in a human readable manner to show in the final summary.\"\"\"\n    if seconds < 60:\n        return f\"{seconds:.2f}s\"\n    else:\n        dt = datetime.timedelta(seconds=int(seconds))\n        return f\"{seconds:.2f}s ({dt})\""}, "reorder_items": {"line": 270, "args": [{"func_args": {"items": "[]"}, "return_value": "[]"}], "text": "def reorder_items(items: Sequence[nodes.Item]) -> List[nodes.Item]:\n    argkeys_cache: Dict[int, Dict[nodes.Item, Dict[_Key, None]]] = {}\n    items_by_argkey: Dict[int, Dict[_Key, Deque[nodes.Item]]] = {}\n    for scopenum in range(0, scopenum_function):\n        d: Dict[nodes.Item, Dict[_Key, None]] = {}\n        argkeys_cache[scopenum] = d\n        item_d: Dict[_Key, Deque[nodes.Item]] = defaultdict(deque)\n        items_by_argkey[scopenum] = item_d\n        for item in items:\n            keys = dict.fromkeys(get_parametrized_fixture_keys(item, scopenum), None)\n            if keys:\n                d[item] = keys\n                for key in keys:\n                    item_d[key].append(item)\n    items_dict = dict.fromkeys(items, None)\n    return list(reorder_items_atscope(items_dict, argkeys_cache, items_by_argkey, 0))"}, "get_terminal_width": {"line": 15, "args": [{"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}, {"func_args": {}, "return_value": "80"}], "text": "def get_terminal_width() -> int:\n    width, _ = shutil.get_terminal_size(fallback=(80, 24))\n\n    # The Windows get_terminal_size may be bogus, let's sanify a bit.\n    if width < 40:\n        width = 80\n\n    return width"}, "actual_path": {"line": 139, "args": [{"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}], "text": "def actual_path(path):\n        \"\"\"The actual path for non-Windows platforms.\"\"\"\n        return path"}, "abs_file": {"line": 144, "args": [{"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'.'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"path": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}]}, "find_python_files": {"line": 403, "args": [{"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"dirname": "'/usr/app/src/test_repos/python-libarchive-c/libarchive'"}, "return_value": "None"}], "text": "def find_python_files(dirname):\n    \"\"\"Yield all of the importable Python files in `dirname`, recursively.\n\n    To be importable, the files have to be in a directory with a __init__.py,\n    except for `dirname` itself, which isn't required to have one.  The\n    assumption is that `dirname` was specified directly, so the user knows\n    best, but sub-directories are checked for a __init__.py to be sure we only\n    find the importable files.\n\n    \"\"\"\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dirname)):\n        if i > 0 and '__init__.py' not in filenames:\n            # If a directory doesn't have __init__.py, then it isn't\n            # importable and neither are its files\n            del dirnames[:]\n            continue\n        for filename in filenames:\n            # We're only interested in files that look like reasonable Python\n            # files: Must end with .py or .pyw, and must not have certain funny\n            # characters that probably mean they are editor junk.\n            if re.match(r\"^[^.#~!$@%^&*()+=,]+\\.pyw?$\", filename):\n                yield os.path.join(dirpath, filename)"}, "canonical_filename": {"line": 53, "args": [{"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}]}, "relative_filename": {"line": 39, "args": [{"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'libarchive/entry.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'libarchive/ffi.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'libarchive/extract.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'libarchive/exception.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'libarchive/__init__.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'libarchive/read.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'libarchive/flags.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'libarchive/write.py'"}]}, "join_regex": {"line": 182, "args": [{"func_args": {"regexes": "['#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)']"}, "return_value": "'(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}, {"func_args": {"regexes": "('(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER))',)"}, "return_value": "'(?:(?:#\\\\s*(pragma|PRAGMA)[:\\\\s]?\\\\s*(no|NO)\\\\s*(cover|COVER)))'"}], "text": "def join_regex(regexes):\n    \"\"\"Combine a list of regexes into one that matches any of them.\"\"\"\n    return \"|\".join(f\"(?:{r})\" for r in regexes)"}, "nice_pair": {"line": 140, "args": [{"func_args": {"pair": "(2, 10)"}, "return_value": "'2-10'"}, {"func_args": {"pair": "(7, 182)"}, "return_value": "'7-182'"}, {"func_args": {"pair": "(5, 8)"}, "return_value": "'5-8'"}, {"func_args": {"pair": "(11, 12)"}, "return_value": "'11-12'"}, {"func_args": {"pair": "(1, 74)"}, "return_value": "'1-74'"}, {"func_args": {"pair": "(8, 9)"}, "return_value": "'8-9'"}, {"func_args": {"pair": "(67, 67)"}, "return_value": "'67'"}, {"func_args": {"pair": "(73, 79)"}, "return_value": "'73-79'"}, {"func_args": {"pair": "(83, 84)"}, "return_value": "'83-84'"}, {"func_args": {"pair": "(88, 90)"}, "return_value": "'88-90'"}, {"func_args": {"pair": "(94, 100)"}, "return_value": "'94-100'"}, {"func_args": {"pair": "(105, 110)"}, "return_value": "'105-110'"}, {"func_args": {"pair": "(114, 121)"}, "return_value": "'114-121'"}, {"func_args": {"pair": "(125, 132)"}, "return_value": "'125-132'"}, {"func_args": {"pair": "(136, 143)"}, "return_value": "'136-143'"}, {"func_args": {"pair": "(147, 154)"}, "return_value": "'147-154'"}, {"func_args": {"pair": "(164, 331)"}, "return_value": "'164-331'"}, {"func_args": {"pair": "(1, 7)"}, "return_value": "'1-7'"}, {"func_args": {"pair": "(1, 155)"}, "return_value": "'1-155'"}, {"func_args": {"pair": "(1, 242)"}, "return_value": "'1-242'"}], "text": "def nice_pair(pair):\n    \"\"\"Make a nice string representation of a pair of numbers.\n\n    If the numbers are equal, just return the number, otherwise return the pair\n    with a dash between them, indicating the range.\n\n    \"\"\"\n    start, end = pair\n    if start == end:\n        return \"%d\" % start\n    else:\n        return \"%d-%d\" % (start, end)"}, "tryint": {"line": 370, "args": [{"func_args": {"s": "'libarchive/__init__.py        '"}, "return_value": "'libarchive/__init__.py        '"}, {"func_args": {"s": "'6'"}, "return_value": "6"}, {"func_args": {"s": "'      '"}, "return_value": "'      '"}, {"func_args": {"s": "'5'"}, "return_value": "5"}, {"func_args": {"s": "'    '"}, "return_value": "'    '"}, {"func_args": {"s": "'17'"}, "return_value": "17"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'2'"}, "return_value": "2"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'10'"}, "return_value": "10"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/entry.py         '"}, "return_value": "'libarchive/entry.py         '"}, {"func_args": {"s": "'124'"}, "return_value": "124"}, {"func_args": {"s": "'    '"}, "return_value": "'    '"}, {"func_args": {"s": "'121'"}, "return_value": "121"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'2'"}, "return_value": "2"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'7'"}, "return_value": "7"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'182'"}, "return_value": "182"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/exception.py       '"}, "return_value": "'libarchive/exception.py       '"}, {"func_args": {"s": "'9'"}, "return_value": "9"}, {"func_args": {"s": "'      '"}, "return_value": "'      '"}, {"func_args": {"s": "'6'"}, "return_value": "6"}, {"func_args": {"s": "'    '"}, "return_value": "'    '"}, {"func_args": {"s": "'33'"}, "return_value": "33"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'5'"}, "return_value": "5"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'8'"}, "return_value": "8"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'11'"}, "return_value": "11"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'12'"}, "return_value": "12"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/extract.py        '"}, "return_value": "'libarchive/extract.py        '"}, {"func_args": {"s": "'50'"}, "return_value": "50"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'50'"}, "return_value": "50"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'0'"}, "return_value": "0"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'1'"}, "return_value": "1"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'74'"}, "return_value": "74"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/ffi.py           '"}, "return_value": "'libarchive/ffi.py           '"}, {"func_args": {"s": "'200'"}, "return_value": "200"}, {"func_args": {"s": "'    '"}, "return_value": "'    '"}, {"func_args": {"s": "'156'"}, "return_value": "156"}, {"func_args": {"s": "'    '"}, "return_value": "'    '"}, {"func_args": {"s": "'22'"}, "return_value": "22"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'8'"}, "return_value": "8"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'9'"}, "return_value": "9"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'67'"}, "return_value": "67"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'73'"}, "return_value": "73"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'79'"}, "return_value": "79"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'83'"}, "return_value": "83"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'84'"}, "return_value": "84"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'88'"}, "return_value": "88"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'90'"}, "return_value": "90"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'94'"}, "return_value": "94"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'100'"}, "return_value": "100"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'105'"}, "return_value": "105"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'110'"}, "return_value": "110"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'114'"}, "return_value": "114"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'121'"}, "return_value": "121"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'125'"}, "return_value": "125"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'132'"}, "return_value": "132"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'136'"}, "return_value": "136"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'143'"}, "return_value": "143"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'147'"}, "return_value": "147"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'154'"}, "return_value": "154"}, {"func_args": {"s": "', '"}, "return_value": "', '"}, {"func_args": {"s": "'164'"}, "return_value": "164"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'331'"}, "return_value": "331"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/flags.py           '"}, "return_value": "'libarchive/flags.py           '"}, {"func_args": {"s": "'7'"}, "return_value": "7"}, {"func_args": {"s": "'      '"}, "return_value": "'      '"}, {"func_args": {"s": "'7'"}, "return_value": "7"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'0'"}, "return_value": "0"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'1'"}, "return_value": "1"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'7'"}, "return_value": "7"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/read.py           '"}, "return_value": "'libarchive/read.py           '"}, {"func_args": {"s": "'85'"}, "return_value": "85"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'85'"}, "return_value": "85"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'0'"}, "return_value": "0"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'1'"}, "return_value": "1"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'155'"}, "return_value": "155"}, {"func_args": {"s": "''"}, "return_value": "''"}, {"func_args": {"s": "'libarchive/write.py         '"}, "return_value": "'libarchive/write.py         '"}, {"func_args": {"s": "'142'"}, "return_value": "142"}, {"func_args": {"s": "'    '"}, "return_value": "'    '"}, {"func_args": {"s": "'142'"}, "return_value": "142"}, {"func_args": {"s": "'     '"}, "return_value": "'     '"}, {"func_args": {"s": "'0'"}, "return_value": "0"}, {"func_args": {"s": "'%   '"}, "return_value": "'%   '"}, {"func_args": {"s": "'1'"}, "return_value": "1"}, {"func_args": {"s": "'-'"}, "return_value": "'-'"}, {"func_args": {"s": "'242'"}, "return_value": "242"}, {"func_args": {"s": "''"}, "return_value": "''"}], "text": "def tryint(s):\n        \"\"\"If `s` is a number, return an int, else `s` unchanged.\"\"\"\n        try:\n            return int(s)\n        except ValueError:\n            return s"}, "human_key": {"line": 366, "args": [{"func_args": {"s": "'libarchive/__init__.py        6      5    17%   2-10'"}, "return_value": "['libarchive/__init__.py        ', 6, '      ', 5, '    ', 17, '%   ', 2, '-', 10, '']"}, {"func_args": {"s": "'libarchive/entry.py         124    121     2%   7-182'"}, "return_value": "['libarchive/entry.py         ', 124, '    ', 121, '     ', 2, '%   ', 7, '-', 182, '']"}, {"func_args": {"s": "'libarchive/exception.py       9      6    33%   5-8, 11-12'"}, "return_value": "['libarchive/exception.py       ', 9, '      ', 6, '    ', 33, '%   ', 5, '-', 8, ', ', 11, '-', 12, '']"}, {"func_args": {"s": "'libarchive/extract.py        50     50     0%   1-74'"}, "return_value": "['libarchive/extract.py        ', 50, '     ', 50, '     ', 0, '%   ', 1, '-', 74, '']"}, {"func_args": {"s": "'libarchive/ffi.py           200    156    22%   8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331'"}, "return_value": "['libarchive/ffi.py           ', 200, '    ', 156, '    ', 22, '%   ', 8, '-', 9, ', ', 67, ', ', 73, '-', 79, ', ', 83, '-', 84, ', ', 88, '-', 90, ', ', 94, '-', 100, ', ', 105, '-', 110, ', ', 114, '-', 121, ', ', 125, '-', 132, ', ', 136, '-', 143, ', ', 147, '-', 154, ', ', 164, '-', 331, '']"}, {"func_args": {"s": "'libarchive/flags.py           7      7     0%   1-7'"}, "return_value": "['libarchive/flags.py           ', 7, '      ', 7, '     ', 0, '%   ', 1, '-', 7, '']"}, {"func_args": {"s": "'libarchive/read.py           85     85     0%   1-155'"}, "return_value": "['libarchive/read.py           ', 85, '     ', 85, '     ', 0, '%   ', 1, '-', 155, '']"}, {"func_args": {"s": "'libarchive/write.py         142    142     0%   1-242'"}, "return_value": "['libarchive/write.py         ', 142, '    ', 142, '     ', 0, '%   ', 1, '-', 242, '']"}], "text": "def human_key(s):\n    \"\"\"Turn a string into a list of string and number chunks.\n        \"z23a\" -> [\"z\", 23, \"a\"]\n    \"\"\"\n    def tryint(s):\n        \"\"\"If `s` is a number, return an int, else `s` unchanged.\"\"\"\n        try:\n            return int(s)\n        except ValueError:\n            return s\n\n    return [tryint(c) for c in re.split(r\"(\\d+)\", s)]"}, "<lambda>": {"line": 394, "args": [{"func_args": {"pair": "('libarchive/__init__.py        6      5    17%   2-10', ('libarchive/__init__.py', 6, 5, '17', '2-10', 16.666666666666668))"}, "return_value": "(['libarchive/__init__.py        ', 6, '      ', 5, '    ', 17, '%   ', 2, '-', 10, ''], ('libarchive/__init__.py', 6, 5, '17', '2-10', 16.666666666666668))"}, {"func_args": {"pair": "('libarchive/entry.py         124    121     2%   7-182', ('libarchive/entry.py', 124, 121, '2', '7-182', 2.4193548387096775))"}, "return_value": "(['libarchive/entry.py         ', 124, '    ', 121, '     ', 2, '%   ', 7, '-', 182, ''], ('libarchive/entry.py', 124, 121, '2', '7-182', 2.4193548387096775))"}, {"func_args": {"pair": "('libarchive/exception.py       9      6    33%   5-8, 11-12', ('libarchive/exception.py', 9, 6, '33', '5-8, 11-12', 33.333333333333336))"}, "return_value": "(['libarchive/exception.py       ', 9, '      ', 6, '    ', 33, '%   ', 5, '-', 8, ', ', 11, '-', 12, ''], ('libarchive/exception.py', 9, 6, '33', '5-8, 11-12', 33.333333333333336))"}, {"func_args": {"pair": "('libarchive/extract.py        50     50     0%   1-74', ('libarchive/extract.py', 50, 50, '0', '1-74', 0.0))"}, "return_value": "(['libarchive/extract.py        ', 50, '     ', 50, '     ', 0, '%   ', 1, '-', 74, ''], ('libarchive/extract.py', 50, 50, '0', '1-74', 0.0))"}, {"func_args": {"pair": "('libarchive/ffi.py           200    156    22%   8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', ('libarchive/ffi.py', 200, 156, '22', '8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', 22.0))"}, "return_value": "(['libarchive/ffi.py           ', 200, '    ', 156, '    ', 22, '%   ', 8, '-', 9, ', ', 67, ', ', 73, '-', 79, ', ', 83, '-', 84, ', ', 88, '-', 90, ', ', 94, '-', 100, ', ', 105, '-', 110, ', ', 114, '-', 121, ', ', 125, '-', 132, ', ', 136, '-', 143, ', ', 147, '-', 154, ', ', 164, '-', 331, ''], ('libarchive/ffi.py', 200, 156, '22', '8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', 22.0))"}, {"func_args": {"pair": "('libarchive/flags.py           7      7     0%   1-7', ('libarchive/flags.py', 7, 7, '0', '1-7', 0.0))"}, "return_value": "(['libarchive/flags.py           ', 7, '      ', 7, '     ', 0, '%   ', 1, '-', 7, ''], ('libarchive/flags.py', 7, 7, '0', '1-7', 0.0))"}, {"func_args": {"pair": "('libarchive/read.py           85     85     0%   1-155', ('libarchive/read.py', 85, 85, '0', '1-155', 0.0))"}, "return_value": "(['libarchive/read.py           ', 85, '     ', 85, '     ', 0, '%   ', 1, '-', 155, ''], ('libarchive/read.py', 85, 85, '0', '1-155', 0.0))"}, {"func_args": {"pair": "('libarchive/write.py         142    142     0%   1-242', ('libarchive/write.py', 142, 142, '0', '1-242', 0.0))"}, "return_value": "(['libarchive/write.py         ', 142, '    ', 142, '     ', 0, '%   ', 1, '-', 242, ''], ('libarchive/write.py', 142, 142, '0', '1-242', 0.0))"}]}, "human_sorted_items": {"line": 389, "args": [{"func_args": {"items": "[('libarchive/__init__.py        6      5    17%   2-10', ('libarchive/__init__.py', 6, 5, '17', '2-10', 16.666666666666668)), ('libarchive/entry.py         124    121     2%   7-182', ('libarchive/entry.py', 124, 121, '2', '7-182', 2.4193548387096775)), ('libarchive/exception.py       9      6    33%   5-8, 11-12', ('libarchive/exception.py', 9, 6, '33', '5-8, 11-12', 33.333333333333336)), ('libarchive/extract.py        50     50     0%   1-74', ('libarchive/extract.py', 50, 50, '0', '1-74', 0.0)), ('libarchive/ffi.py           200    156    22%   8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', ('libarchive/ffi.py', 200, 156, '22', '8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', 22.0)), ('libarchive/flags.py           7      7     0%   1-7', ('libarchive/flags.py', 7, 7, '0', '1-7', 0.0)), ('libarchive/read.py           85     85     0%   1-155', ('libarchive/read.py', 85, 85, '0', '1-155', 0.0)), ('libarchive/write.py         142    142     0%   1-242', ('libarchive/write.py', 142, 142, '0', '1-242', 0.0))]", "reverse": "False"}, "return_value": "[('libarchive/__init__.py        6      5    17%   2-10', ('libarchive/__init__.py', 6, 5, '17', '2-10', 16.666666666666668)), ('libarchive/entry.py         124    121     2%   7-182', ('libarchive/entry.py', 124, 121, '2', '7-182', 2.4193548387096775)), ('libarchive/exception.py       9      6    33%   5-8, 11-12', ('libarchive/exception.py', 9, 6, '33', '5-8, 11-12', 33.333333333333336)), ('libarchive/extract.py        50     50     0%   1-74', ('libarchive/extract.py', 50, 50, '0', '1-74', 0.0)), ('libarchive/ffi.py           200    156    22%   8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', ('libarchive/ffi.py', 200, 156, '22', '8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331', 22.0)), ('libarchive/flags.py           7      7     0%   1-7', ('libarchive/flags.py', 7, 7, '0', '1-7', 0.0)), ('libarchive/read.py           85     85     0%   1-155', ('libarchive/read.py', 85, 85, '0', '1-155', 0.0)), ('libarchive/write.py         142    142     0%   1-242', ('libarchive/write.py', 142, 142, '0', '1-242', 0.0))]"}], "text": "def human_sorted_items(items, reverse=False):\n    \"\"\"Sort the (string, value) items the way humans expect.\n\n    Returns the sorted list of items.\n    \"\"\"\n    return sorted(items, key=lambda pair: (human_key(pair[0]), pair[1]), reverse=reverse)"}, "_to_blob": {"line": 21, "args": [{"func_args": {"b": "b'\\x02'"}, "return_value": "b'\\x02'"}, {"func_args": {"b": "b'\\x16'"}, "return_value": "b'\\x16'"}, {"func_args": {"b": "b'\\xc2\\xf8\\xa5\\x86\\x7f\\xd8\\xb6a\\x03\\x01\\x84 \\x80\\x01\\x02\\x10\\x80\\x00\\x04\\x00\\x01'"}, "return_value": "b'\\xc2\\xf8\\xa5\\x86\\x7f\\xd8\\xb6a\\x03\\x01\\x84 \\x80\\x01\\x02\\x10\\x80\\x00\\x04\\x00\\x01'"}, {"func_args": {"b": "b'\\x14\\x04'"}, "return_value": "b'\\x14\\x04'"}], "text": "def _to_blob(b):\n    \"\"\"Convert a bytestring into a type SQLite will accept for a blob.\"\"\"\n    return b"}, "nums_to_numbits": {"line": 28, "args": [{"func_args": {"nums": "{1}"}, "return_value": "b'\\x02'"}, {"func_args": {"nums": "{1, 2, 4}"}, "return_value": "b'\\x16'"}, {"func_args": {"nums": "{1, 6, 7, 135, 11, 12, 13, 14, 15, 16, 18, 146, 21, 23, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 160, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 61, 62, 64, 65, 72, 82, 87, 93, 103, 104, 113, 124}"}, "return_value": "b'\\xc2\\xf8\\xa5\\x86\\x7f\\xd8\\xb6a\\x03\\x01\\x84 \\x80\\x01\\x02\\x10\\x80\\x00\\x04\\x00\\x01'"}, {"func_args": {"nums": "{2, 10, 4}"}, "return_value": "b'\\x14\\x04'"}]}, "numbits_to_nums": {"line": 49, "args": [{"func_args": {"numbits": "b'\\x02'"}, "return_value": "[1]"}, {"func_args": {"numbits": "b'\\x16'"}, "return_value": "[1, 2, 4]"}, {"func_args": {"numbits": "b'\\x14\\x04'"}, "return_value": "[2, 4, 10]"}, {"func_args": {"numbits": "b'\\xc2\\xf8\\xa5\\x86\\x7f\\xd8\\xb6a\\x03\\x01\\x84 \\x80\\x01\\x02\\x10\\x80\\x00\\x04\\x00\\x01'"}, "return_value": "[1, 6, 7, 11, 12, 13, 14, 15, 16, 18, 21, 23, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 46, 47, 49, 50, 52, 53, 55, 56, 61, 62, 64, 65, 72, 82, 87, 93, 103, 104, 113, 124, 135, 146, 160]"}]}, "combinable_files": {"line": 55, "args": [{"func_args": {"data_file": "'/usr/app/src/test_repos/python-libarchive-c/.coverage'", "data_paths": "None"}, "return_value": "['/usr/app/src/test_repos/python-libarchive-c/.coverage.cae2a1e14906.61196.796385']"}], "text": "def combinable_files(data_file, data_paths=None):\n    \"\"\"Make a list of data files to be combined.\n\n    `data_file` is a path to a data file.  `data_paths` is a list of files or\n    directories of files.\n\n    Returns a list of absolute file paths.\n    \"\"\"\n    data_dir, local = os.path.split(os.path.abspath(data_file))\n\n    data_paths = data_paths or [data_dir]\n    files_to_combine = []\n    for p in data_paths:\n        if os.path.isfile(p):\n            files_to_combine.append(os.path.abspath(p))\n        elif os.path.isdir(p):\n            pattern = os.path.join(os.path.abspath(p), f\"{local}.*\")\n            files_to_combine.extend(glob.glob(pattern))\n        else:\n            raise NoDataError(f\"Couldn't combine from non-existent path '{p}'\")\n    return files_to_combine"}, "_line_ranges": {"line": 270, "args": [{"func_args": {"statements": "{1, 2, 3, 4, 8, 10}", "lines": "{2, 3, 4, 8, 10}"}, "return_value": "[(2, 10)]"}, {"func_args": {"statements": "{1, 2, 4, 7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 23, 25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 88, 89, 91, 92, 93, 95, 96, 97, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 123, 124, 127, 128, 129, 130, 131, 133, 134, 137, 138, 139, 140, 141, 143, 144, 147, 148, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163, 164, 166, 167, 168, 170, 171, 174, 176, 177, 178, 180, 181, 182}", "lines": "{7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 23, 25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 88, 89, 91, 92, 93, 95, 96, 97, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 123, 124, 127, 128, 129, 130, 131, 133, 134, 137, 138, 139, 140, 141, 143, 144, 147, 148, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163, 164, 166, 167, 168, 170, 171, 174, 176, 177, 178, 180, 181, 182}"}, "return_value": "[(7, 182)]"}, {"func_args": {"statements": "{2, 4, 5, 6, 7, 8, 10, 11, 12}", "lines": "{5, 6, 7, 8, 11, 12}"}, "return_value": "[(5, 8), (11, 12)]"}, {"func_args": {"statements": "{1, 2, 4, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 61, 62, 65, 67, 68, 71, 73, 74}", "lines": "{1, 2, 4, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 61, 62, 65, 67, 68, 71, 73, 74}"}, "return_value": "[(1, 74)]"}, {"func_args": {"statements": "{1, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 23, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 43, 46, 49, 52, 53, 55, 56, 61, 62, 64, 65, 67, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 160, 164, 165, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 206, 207, 211, 213, 217, 218, 219, 224, 228, 229, 230, 235, 237, 240, 241, 243, 245, 246, 248, 249, 253, 254, 255, 256, 257, 258, 262, 265, 266, 270, 271, 273, 274, 276, 281, 282, 283, 288, 292, 293, 294, 299, 302, 303, 304, 305, 309, 310, 311, 312, 314, 315, 316, 318, 320, 322, 323, 327, 328, 329, 330, 331}", "lines": "{8, 9, 67, 73, 74, 75, 76, 77, 78, 79, 83, 84, 88, 89, 90, 94, 95, 96, 97, 98, 100, 105, 106, 107, 108, 109, 110, 114, 115, 116, 117, 118, 119, 120, 121, 125, 126, 127, 128, 129, 130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 164, 165, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 206, 207, 211, 213, 217, 218, 219, 224, 228, 229, 230, 235, 237, 240, 241, 243, 245, 246, 248, 249, 253, 254, 255, 256, 257, 258, 262, 265, 266, 270, 271, 273, 274, 276, 281, 282, 283, 288, 292, 293, 294, 299, 302, 303, 304, 305, 309, 310, 311, 312, 314, 315, 316, 318, 320, 322, 323, 327, 328, 329, 330, 331}"}, "return_value": "[(8, 9), (67, 67), (73, 79), (83, 84), (88, 90), (94, 100), (105, 110), (114, 121), (125, 132), (136, 143), (147, 154), (164, 331)]"}, {"func_args": {"statements": "{1, 2, 3, 4, 5, 6, 7}", "lines": "{1, 2, 3, 4, 5, 6, 7}"}, "return_value": "[(1, 7)]"}, {"func_args": {"statements": "{1, 2, 3, 5, 6, 10, 13, 15, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54, 57, 58, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 82, 83, 84, 87, 88, 91, 92, 97, 98, 99, 102, 103, 106, 107, 110, 111, 112, 115, 116, 127, 128, 130, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 155}", "lines": "{1, 2, 3, 5, 6, 10, 13, 15, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54, 57, 58, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 82, 83, 84, 87, 88, 91, 92, 97, 98, 99, 102, 103, 106, 107, 110, 111, 112, 115, 116, 127, 128, 130, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 155}"}, "return_value": "[(1, 155)]"}, {"func_args": {"statements": "{1, 2, 3, 5, 6, 7, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 35, 38, 39, 40, 41, 42, 43, 45, 50, 52, 53, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 104, 106, 107, 108, 109, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 178, 179, 180, 181, 182, 183, 184, 187, 188, 194, 195, 196, 198, 199, 200, 202, 204, 205, 206, 207, 210, 211, 215, 217, 218, 221, 222, 226, 228, 229, 232, 233, 237, 239, 240, 241, 242}", "lines": "{1, 2, 3, 5, 6, 7, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 35, 38, 39, 40, 41, 42, 43, 45, 50, 52, 53, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 104, 106, 107, 108, 109, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 178, 179, 180, 181, 182, 183, 184, 187, 188, 194, 195, 196, 198, 199, 200, 202, 204, 205, 206, 207, 210, 211, 215, 217, 218, 221, 222, 226, 228, 229, 232, 233, 237, 239, 240, 241, 242}"}, "return_value": "[(1, 242)]"}], "text": "def _line_ranges(statements, lines):\n    \"\"\"Produce a list of ranges for `format_lines`.\"\"\"\n    statements = sorted(statements)\n    lines = sorted(lines)\n\n    pairs = []\n    start = None\n    lidx = 0\n    for stmt in statements:\n        if lidx >= len(lines):\n            break\n        if stmt == lines[lidx]:\n            lidx += 1\n            if not start:\n                start = stmt\n            end = stmt\n        elif start:\n            pairs.append((start, end))\n            start = None\n    if start:\n        pairs.append((start, end))\n    return pairs"}, "format_lines": {"line": 294, "args": [{"func_args": {"statements": "{1, 2, 3, 4, 8, 10}", "lines": "{2, 3, 4, 8, 10}", "arcs": "None"}, "return_value": "'2-10'"}, {"func_args": {"statements": "{1, 2, 4, 7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 23, 25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 88, 89, 91, 92, 93, 95, 96, 97, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 123, 124, 127, 128, 129, 130, 131, 133, 134, 137, 138, 139, 140, 141, 143, 144, 147, 148, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163, 164, 166, 167, 168, 170, 171, 174, 176, 177, 178, 180, 181, 182}", "lines": "{7, 8, 9, 10, 11, 13, 16, 18, 19, 20, 23, 25, 27, 28, 29, 31, 32, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 78, 79, 81, 82, 88, 89, 91, 92, 93, 95, 96, 97, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 123, 124, 127, 128, 129, 130, 131, 133, 134, 137, 138, 139, 140, 141, 143, 144, 147, 148, 151, 152, 153, 154, 156, 158, 159, 161, 162, 163, 164, 166, 167, 168, 170, 171, 174, 176, 177, 178, 180, 181, 182}", "arcs": "None"}, "return_value": "'7-182'"}, {"func_args": {"statements": "{2, 4, 5, 6, 7, 8, 10, 11, 12}", "lines": "{5, 6, 7, 8, 11, 12}", "arcs": "None"}, "return_value": "'5-8, 11-12'"}, {"func_args": {"statements": "{1, 2, 4, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 61, 62, 65, 67, 68, 71, 73, 74}", "lines": "{1, 2, 4, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 61, 62, 65, 67, 68, 71, 73, 74}", "arcs": "None"}, "return_value": "'1-74'"}, {"func_args": {"statements": "{1, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 21, 23, 25, 26, 31, 32, 33, 34, 35, 36, 37, 38, 43, 46, 49, 52, 53, 55, 56, 61, 62, 64, 65, 67, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 160, 164, 165, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 206, 207, 211, 213, 217, 218, 219, 224, 228, 229, 230, 235, 237, 240, 241, 243, 245, 246, 248, 249, 253, 254, 255, 256, 257, 258, 262, 265, 266, 270, 271, 273, 274, 276, 281, 282, 283, 288, 292, 293, 294, 299, 302, 303, 304, 305, 309, 310, 311, 312, 314, 315, 316, 318, 320, 322, 323, 327, 328, 329, 330, 331}", "lines": "{8, 9, 67, 73, 74, 75, 76, 77, 78, 79, 83, 84, 88, 89, 90, 94, 95, 96, 97, 98, 100, 105, 106, 107, 108, 109, 110, 114, 115, 116, 117, 118, 119, 120, 121, 125, 126, 127, 128, 129, 130, 131, 132, 136, 137, 138, 139, 140, 141, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 164, 165, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 206, 207, 211, 213, 217, 218, 219, 224, 228, 229, 230, 235, 237, 240, 241, 243, 245, 246, 248, 249, 253, 254, 255, 256, 257, 258, 262, 265, 266, 270, 271, 273, 274, 276, 281, 282, 283, 288, 292, 293, 294, 299, 302, 303, 304, 305, 309, 310, 311, 312, 314, 315, 316, 318, 320, 322, 323, 327, 328, 329, 330, 331}", "arcs": "None"}, "return_value": "'8-9, 67, 73-79, 83-84, 88-90, 94-100, 105-110, 114-121, 125-132, 136-143, 147-154, 164-331'"}, {"func_args": {"statements": "{1, 2, 3, 4, 5, 6, 7}", "lines": "{1, 2, 3, 4, 5, 6, 7}", "arcs": "None"}, "return_value": "'1-7'"}, {"func_args": {"statements": "{1, 2, 3, 5, 6, 10, 13, 15, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54, 57, 58, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 82, 83, 84, 87, 88, 91, 92, 97, 98, 99, 102, 103, 106, 107, 110, 111, 112, 115, 116, 127, 128, 130, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 155}", "lines": "{1, 2, 3, 5, 6, 10, 13, 15, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54, 57, 58, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 82, 83, 84, 87, 88, 91, 92, 97, 98, 99, 102, 103, 106, 107, 110, 111, 112, 115, 116, 127, 128, 130, 132, 134, 135, 137, 139, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 155}", "arcs": "None"}, "return_value": "'1-155'"}, {"func_args": {"statements": "{1, 2, 3, 5, 6, 7, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 35, 38, 39, 40, 41, 42, 43, 45, 50, 52, 53, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 104, 106, 107, 108, 109, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 178, 179, 180, 181, 182, 183, 184, 187, 188, 194, 195, 196, 198, 199, 200, 202, 204, 205, 206, 207, 210, 211, 215, 217, 218, 221, 222, 226, 228, 229, 232, 233, 237, 239, 240, 241, 242}", "lines": "{1, 2, 3, 5, 6, 7, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 33, 35, 38, 39, 40, 41, 42, 43, 45, 50, 52, 53, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 104, 106, 107, 108, 109, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 178, 179, 180, 181, 182, 183, 184, 187, 188, 194, 195, 196, 198, 199, 200, 202, 204, 205, 206, 207, 210, 211, 215, 217, 218, 221, 222, 226, 228, 229, 232, 233, 237, 239, 240, 241, 242}", "arcs": "None"}, "return_value": "'1-242'"}], "text": "def format_lines(statements, lines, arcs=None):\n    \"\"\"Nicely format a list of line numbers.\n\n    Format a list of line numbers for printing by coalescing groups of lines as\n    long as the lines represent consecutive statements.  This will coalesce\n    even if there are gaps between statements.\n\n    For example, if `statements` is [1,2,3,4,5,10,11,12,13,14] and\n    `lines` is [1,2,5,10,11,13,14] then the result will be \"1-2, 5-11, 13-14\".\n\n    Both `lines` and `statements` can be any iterable. All of the elements of\n    `lines` must be in `statements`, and all of the values must be positive\n    integers.\n\n    If `arcs` is provided, they are (start,[end,end,end]) pairs that will be\n    included in the output as long as start isn't in `lines`.\n\n    \"\"\"\n    line_items = [(pair[0], nice_pair(pair)) for pair in _line_ranges(statements, lines)]\n    if arcs:\n        line_exits = sorted(arcs)\n        for line, exits in line_exits:\n            for ex in sorted(exits):\n                if line not in lines and ex not in lines:\n                    dest = (ex if ex > 0 else \"exit\")\n                    line_items.append((line, f\"{line}->{dest}\"))\n\n    ret = ', '.join(t[-1] for t in sorted(line_items))\n    return ret"}, "source_for_file": {"line": 97, "args": [{"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}], "text": "def source_for_file(filename):\n    \"\"\"Return the source filename for `filename`.\n\n    Given a file name being traced, return the best guess as to the source\n    file to attribute it to.\n\n    \"\"\"\n    if filename.endswith(\".py\"):\n        # .py files are themselves source files.\n        return filename\n\n    elif filename.endswith((\".pyc\", \".pyo\")):\n        # Bytecode files probably have source files near them.\n        py_filename = filename[:-1]\n        if os.path.exists(py_filename):\n            # Found a .py file, use that.\n            return py_filename\n        if env.WINDOWS:\n            # On Windows, it could be a .pyw file.\n            pyw_filename = py_filename + \"w\"\n            if os.path.exists(pyw_filename):\n                return pyw_filename\n        # Didn't find source, but it's probably the .py file we want.\n        return py_filename\n\n    elif filename.endswith(\"$py.class\"):\n        # Jython is easy to guess.\n        return filename[:-9] + \".py\"\n\n    # No idea, just use the file name as-is.\n    return filename"}, "source_for_morf": {"line": 130, "args": [{"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, {"func_args": {"morf": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}], "text": "def source_for_morf(morf):\n    \"\"\"Get the source filename for the module-or-file `morf`.\"\"\"\n    if hasattr(morf, '__file__') and morf.__file__:\n        filename = morf.__file__\n    elif isinstance(morf, types.ModuleType):\n        # A module should have had .__file__, otherwise we can't use it.\n        # This could be a PEP-420 namespace package.\n        raise CoverageException(f\"Module {morf} has no file\")\n    else:\n        filename = morf\n\n    filename = source_for_file(filename)\n    return filename"}, "read_python_source": {"line": 20, "args": [{"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "b'from .entry import ArchiveEntry\\nfrom .exception import ArchiveError\\nfrom .extract import extract_fd, extract_file, extract_memory\\nfrom .read import (\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader\\n)\\nfrom .write import custom_writer, fd_writer, file_writer, memory_writer\\n\\n__all__ = [x.__name__ for x in (\\n    ArchiveEntry,\\n    ArchiveError,\\n    extract_fd, extract_file, extract_memory,\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader,\\n    custom_writer, fd_writer, file_writer, memory_writer\\n)]\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "b'from contextlib import contextmanager\\nfrom ctypes import c_char_p, create_string_buffer\\n\\nfrom . import ffi\\n\\n\\n@contextmanager\\ndef new_archive_entry():\\n    entry_p = ffi.entry_new()\\n    try:\\n        yield entry_p\\n    finally:\\n        ffi.entry_free(entry_p)\\n\\n\\ndef format_time(seconds, nanos):\\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\\n    if nanos:\\n        return float(seconds) + float(nanos) / 1000000000.0\\n    return int(seconds)\\n\\n\\nclass ArchiveEntry:\\n\\n    __slots__ = (\\'_archive_p\\', \\'_entry_p\\')\\n\\n    def __init__(self, archive_p, entry_p):\\n        self._archive_p = archive_p\\n        self._entry_p = entry_p\\n\\n    def __str__(self):\\n        return self.pathname\\n\\n    @property\\n    def filetype(self):\\n        return ffi.entry_filetype(self._entry_p)\\n\\n    @property\\n    def uid(self):\\n        return ffi.entry_uid(self._entry_p)\\n\\n    @property\\n    def gid(self):\\n        return ffi.entry_gid(self._entry_p)\\n\\n    def get_blocks(self, block_size=ffi.page_size):\\n        archive_p = self._archive_p\\n        buf = create_string_buffer(block_size)\\n        read = ffi.read_data\\n        while 1:\\n            r = read(archive_p, buf, block_size)\\n            if r == 0:\\n                break\\n            yield buf.raw[0:r]\\n\\n    @property\\n    def isblk(self):\\n        return self.filetype & 0o170000 == 0o060000\\n\\n    @property\\n    def ischr(self):\\n        return self.filetype & 0o170000 == 0o020000\\n\\n    @property\\n    def isdir(self):\\n        return self.filetype & 0o170000 == 0o040000\\n\\n    @property\\n    def isfifo(self):\\n        return self.filetype & 0o170000 == 0o010000\\n\\n    @property\\n    def islnk(self):\\n        return bool(ffi.entry_hardlink_w(self._entry_p) or\\n                    ffi.entry_hardlink(self._entry_p))\\n\\n    @property\\n    def issym(self):\\n        return self.filetype & 0o170000 == 0o120000\\n\\n    def _linkpath(self):\\n        return (ffi.entry_symlink_w(self._entry_p) or\\n                ffi.entry_hardlink_w(self._entry_p) or\\n                ffi.entry_symlink(self._entry_p) or\\n                ffi.entry_hardlink(self._entry_p))\\n\\n    # aliases to get the same api as tarfile\\n    linkpath = property(_linkpath)\\n    linkname = property(_linkpath)\\n\\n    @property\\n    def isreg(self):\\n        return self.filetype & 0o170000 == 0o100000\\n\\n    @property\\n    def isfile(self):\\n        return self.isreg\\n\\n    @property\\n    def issock(self):\\n        return self.filetype & 0o170000 == 0o140000\\n\\n    @property\\n    def isdev(self):\\n        return self.ischr or self.isblk or self.isfifo or self.issock\\n\\n    @property\\n    def atime(self):\\n        sec_val = ffi.entry_atime(self._entry_p)\\n        nsec_val = ffi.entry_atime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_atime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_atime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def mtime(self):\\n        sec_val = ffi.entry_mtime(self._entry_p)\\n        nsec_val = ffi.entry_mtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_mtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_mtime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def ctime(self):\\n        sec_val = ffi.entry_ctime(self._entry_p)\\n        nsec_val = ffi.entry_ctime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_ctime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_ctime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def birthtime(self):\\n        sec_val = ffi.entry_birthtime(self._entry_p)\\n        nsec_val = ffi.entry_birthtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_birthtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_birthtime(self._entry_p,\\n                                       timestamp_sec, timestamp_nsec)\\n\\n    def _getpathname(self):\\n        return (ffi.entry_pathname_w(self._entry_p) or\\n                ffi.entry_pathname(self._entry_p))\\n\\n    def _setpathname(self, value):\\n        if not isinstance(value, bytes):\\n            value = value.encode(\\'utf8\\')\\n        ffi.entry_update_pathname_utf8(self._entry_p, c_char_p(value))\\n\\n    pathname = property(_getpathname, _setpathname)\\n    # aliases to get the same api as tarfile\\n    path = property(_getpathname, _setpathname)\\n    name = property(_getpathname, _setpathname)\\n\\n    @property\\n    def size(self):\\n        if ffi.entry_size_is_set(self._entry_p):\\n            return ffi.entry_size(self._entry_p)\\n\\n    @property\\n    def mode(self):\\n        return ffi.entry_mode(self._entry_p)\\n\\n    @property\\n    def strmode(self):\\n        # note we strip the mode because archive_entry_strmode\\n        # returns a trailing space: strcpy(bp, \"?rwxrwxrwx \");\\n        return ffi.entry_strmode(self._entry_p).strip()\\n\\n    @property\\n    def rdevmajor(self):\\n        return ffi.entry_rdevmajor(self._entry_p)\\n\\n    @property\\n    def rdevminor(self):\\n        return ffi.entry_rdevminor(self._entry_p)\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "b\"\\nclass ArchiveError(Exception):\\n\\n    def __init__(self, msg, errno=None, retcode=None, archive_p=None):\\n        self.msg = msg\\n        self.errno = errno\\n        self.retcode = retcode\\n        self.archive_p = archive_p\\n\\n    def __str__(self):\\n        p = '%s (errno=%s, retcode=%s, archive_p=%s)'\\n        return p % (self.msg, self.errno, self.retcode, self.archive_p)\\n\""}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "b'from contextlib import contextmanager\\nfrom ctypes import byref, c_longlong, c_size_t, c_void_p\\n\\nfrom .ffi import (\\n    write_disk_new, write_disk_set_options, write_free, write_header,\\n    read_data_block, write_data_block, write_finish_entry, ARCHIVE_EOF\\n)\\nfrom .read import fd_reader, file_reader, memory_reader\\n\\n\\nEXTRACT_OWNER = 0x0001\\nEXTRACT_PERM = 0x0002\\nEXTRACT_TIME = 0x0004\\nEXTRACT_NO_OVERWRITE = 0x0008\\nEXTRACT_UNLINK = 0x0010\\nEXTRACT_ACL = 0x0020\\nEXTRACT_FFLAGS = 0x0040\\nEXTRACT_XATTR = 0x0080\\nEXTRACT_SECURE_SYMLINKS = 0x0100\\nEXTRACT_SECURE_NODOTDOT = 0x0200\\nEXTRACT_NO_AUTODIR = 0x0400\\nEXTRACT_NO_OVERWRITE_NEWER = 0x0800\\nEXTRACT_SPARSE = 0x1000\\nEXTRACT_MAC_METADATA = 0x2000\\nEXTRACT_NO_HFS_COMPRESSION = 0x4000\\nEXTRACT_HFS_COMPRESSION_FORCED = 0x8000\\nEXTRACT_SECURE_NOABSOLUTEPATHS = 0x10000\\nEXTRACT_CLEAR_NOCHANGE_FFLAGS = 0x20000\\n\\n\\n@contextmanager\\ndef new_archive_write_disk(flags):\\n    archive_p = write_disk_new()\\n    write_disk_set_options(archive_p, flags)\\n    try:\\n        yield archive_p\\n    finally:\\n        write_free(archive_p)\\n\\n\\ndef extract_entries(entries, flags=0):\\n    \"\"\"Extracts the given archive entries into the current directory.\\n    \"\"\"\\n    buff, size, offset = c_void_p(), c_size_t(), c_longlong()\\n    buff_p, size_p, offset_p = byref(buff), byref(size), byref(offset)\\n    with new_archive_write_disk(flags) as write_p:\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            read_p = entry._archive_p\\n            while 1:\\n                r = read_data_block(read_p, buff_p, size_p, offset_p)\\n                if r == ARCHIVE_EOF:\\n                    break\\n                write_data_block(write_p, buff, size, offset)\\n            write_finish_entry(write_p)\\n\\n\\ndef extract_fd(fd, flags=0):\\n    \"\"\"Extracts an archive from a file descriptor into the current directory.\\n    \"\"\"\\n    with fd_reader(fd) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_file(filepath, flags=0):\\n    \"\"\"Extracts an archive from a file into the current directory.\"\"\"\\n    with file_reader(filepath) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_memory(buffer_, flags=0):\\n    \"\"\"Extracts an archive from memory into the current directory.\"\"\"\\n    with memory_reader(buffer_) as archive:\\n        extract_entries(archive, flags)\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "b'from ctypes import (\\n    c_char_p, c_int, c_uint, c_long, c_longlong, c_size_t, c_int64,\\n    c_void_p, c_wchar_p, CFUNCTYPE, POINTER,\\n)\\n\\ntry:\\n    from ctypes import c_ssize_t\\nexcept ImportError:\\n    from ctypes import c_longlong as c_ssize_t\\n\\nimport ctypes\\nfrom ctypes.util import find_library\\nimport logging\\nimport mmap\\nimport os\\nimport sysconfig\\n\\nfrom .exception import ArchiveError\\n\\n\\nlogger = logging.getLogger(\\'libarchive\\')\\n\\npage_size = mmap.PAGESIZE\\n\\nlibarchive_path = os.environ.get(\\'LIBARCHIVE\\') or find_library(\\'archive\\')\\nlibarchive = ctypes.cdll.LoadLibrary(libarchive_path)\\n\\n\\n# Constants\\n\\nARCHIVE_EOF = 1       # Found end of archive.\\nARCHIVE_OK = 0        # Operation was successful.\\nARCHIVE_RETRY = -10   # Retry might succeed.\\nARCHIVE_WARN = -20    # Partial success.\\nARCHIVE_FAILED = -25  # Current operation cannot complete.\\nARCHIVE_FATAL = -30   # No more operations are possible.\\nREGULAR_FILE = 0o100000\\nDEFAULT_UNIX_PERMISSION = 0o664\\n\\n\\n# Callback types\\n\\nWRITE_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p), c_size_t\\n)\\nREAD_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p)\\n)\\nSEEK_CALLBACK = CFUNCTYPE(\\n    c_longlong, c_void_p, c_void_p, c_longlong, c_int\\n)\\nOPEN_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\nCLOSE_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\n\\nNO_OPEN_CB = ctypes.cast(None, OPEN_CALLBACK)\\nNO_CLOSE_CB = ctypes.cast(None, CLOSE_CALLBACK)\\n\\n\\n# Type aliases, for readability\\n\\nc_archive_p = c_void_p\\nc_archive_entry_p = c_void_p\\n\\nif sysconfig.get_config_var(\\'SIZEOF_TIME_T\\') == 8:\\n    c_time_t = c_int64\\nelse:\\n    c_time_t = c_long\\n\\n\\n# Helper functions\\n\\ndef _error_string(archive_p):\\n    msg = error_string(archive_p)\\n    if msg is None:\\n        return\\n    try:\\n        return msg.decode(\\'ascii\\')\\n    except UnicodeDecodeError:\\n        return msg\\n\\n\\ndef archive_error(archive_p, retcode):\\n    msg = _error_string(archive_p)\\n    return ArchiveError(msg, errno(archive_p), retcode, archive_p)\\n\\n\\ndef check_null(ret, func, args):\\n    if ret is None:\\n        raise ArchiveError(func.__name__+\\' returned NULL\\')\\n    return ret\\n\\n\\ndef check_int(retcode, func, args):\\n    if retcode >= 0:\\n        return retcode\\n    elif retcode == ARCHIVE_WARN:\\n        logger.warning(_error_string(args[0]))\\n        return retcode\\n    else:\\n        raise archive_error(args[0], retcode)\\n\\n\\ndef ffi(name, argtypes, restype, errcheck=None):\\n    f = getattr(libarchive, \\'archive_\\'+name)\\n    f.argtypes = argtypes\\n    f.restype = restype\\n    if errcheck:\\n        f.errcheck = errcheck\\n    globals()[name] = f\\n    return f\\n\\n\\ndef get_read_format_function(format_name):\\n    function_name = \\'read_support_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read format %r is not available\\' % format_name)\\n\\n\\ndef get_read_filter_function(filter_name):\\n    function_name = \\'read_support_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read filter %r is not available\\' % filter_name)\\n\\n\\ndef get_write_format_function(format_name):\\n    function_name = \\'write_set_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write format %r is not available\\' % format_name)\\n\\n\\ndef get_write_filter_function(filter_name):\\n    function_name = \\'write_add_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write filter %r is not available\\' % filter_name)\\n\\n\\n# FFI declarations\\n\\n# library version\\nversion_number = ffi(\\'version_number\\', [], c_int, check_int)\\n\\n# archive_util\\n\\nerrno = ffi(\\'errno\\', [c_archive_p], c_int)\\nerror_string = ffi(\\'error_string\\', [c_archive_p], c_char_p)\\n\\n# archive_entry\\n\\nffi(\\'entry_new\\', [], c_archive_entry_p, check_null)\\n\\nffi(\\'entry_filetype\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_atime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_birthtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_mtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_ctime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_atime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_birthtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_mtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_ctime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_pathname\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_pathname_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_sourcepath\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_size\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_size_is_set\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_mode\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_strmode\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_symlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_symlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_rdevmajor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_rdevminor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_uid\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_gid\\', [c_archive_entry_p], c_longlong)\\n\\nffi(\\'entry_set_size\\', [c_archive_entry_p, c_longlong], None)\\nffi(\\'entry_set_filetype\\', [c_archive_entry_p, c_uint], None)\\nffi(\\'entry_set_perm\\', [c_archive_entry_p, c_int], None)\\nffi(\\'entry_set_atime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_mtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_ctime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_birthtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\n\\nffi(\\'entry_update_pathname_utf8\\', [c_archive_entry_p, c_char_p], None)\\n\\nffi(\\'entry_clear\\', [c_archive_entry_p], c_archive_entry_p)\\nffi(\\'entry_free\\', [c_archive_entry_p], None)\\n\\n# archive_read\\n\\nffi(\\'read_new\\', [], c_archive_p, check_null)\\n\\nREAD_FORMATS = set((\\n    \\'7zip\\', \\'all\\', \\'ar\\', \\'cab\\', \\'cpio\\', \\'empty\\', \\'iso9660\\', \\'lha\\', \\'mtree\\',\\n    \\'rar\\', \\'raw\\', \\'tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(READ_FORMATS):\\n    try:\\n        get_read_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FORMATS.remove(f_name)\\n\\nREAD_FILTERS = set((\\n    \\'all\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'none\\', \\'rpm\\', \\'uu\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(READ_FILTERS):\\n    try:\\n        get_read_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FILTERS.remove(f_name)\\n\\nffi(\\'read_set_seek_callback\\', [c_archive_p, SEEK_CALLBACK], c_int, check_int)\\n\\nffi(\\'read_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'read_open_fd\\', [c_archive_p, c_int, c_size_t], c_int, check_int)\\nffi(\\'read_open_filename_w\\', [c_archive_p, c_wchar_p, c_size_t],\\n    c_int, check_int)\\nffi(\\'read_open_memory\\', [c_archive_p, c_void_p, c_size_t], c_int, check_int)\\n\\nffi(\\'read_next_header\\', [c_archive_p, POINTER(c_void_p)], c_int, check_int)\\nffi(\\'read_next_header2\\', [c_archive_p, c_void_p], c_int, check_int)\\n\\nffi(\\'read_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_disk\\n\\nffi(\\'read_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'read_disk_set_behavior\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'read_disk_set_standard_lookup\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_disk_open\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'read_disk_open_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'read_disk_descend\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_data\\n\\nffi(\\'read_data_block\\',\\n    [c_archive_p, POINTER(c_void_p), POINTER(c_size_t), POINTER(c_longlong)],\\n    c_int, check_int)\\nffi(\\'read_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'read_data_skip\\', [c_archive_p], c_int, check_int)\\n\\n# archive_write\\n\\nffi(\\'write_new\\', [], c_archive_p, check_null)\\nffi(\\'write_set_options\\', [c_archive_p, c_char_p], c_int, check_int)\\n\\nffi(\\'write_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'write_disk_set_options\\', [c_archive_p, c_int], c_int, check_int)\\n\\nWRITE_FORMATS = set((\\n    \\'7zip\\', \\'ar_bsd\\', \\'ar_svr4\\', \\'cpio\\', \\'cpio_newc\\', \\'gnutar\\', \\'iso9660\\',\\n    \\'mtree\\', \\'mtree_classic\\', \\'pax\\', \\'pax_restricted\\', \\'shar\\', \\'shar_dump\\',\\n    \\'ustar\\', \\'v7tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(WRITE_FORMATS):\\n    try:\\n        get_write_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FORMATS.remove(f_name)\\n\\nWRITE_FILTERS = set((\\n    \\'b64encode\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'uuencode\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(WRITE_FILTERS):\\n    try:\\n        get_write_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FILTERS.remove(f_name)\\n\\nffi(\\'write_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'write_open_fd\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_open_filename\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'write_open_filename_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'write_open_memory\\',\\n    [c_archive_p, c_void_p, c_size_t, POINTER(c_size_t)],\\n    c_int, check_int)\\n\\nffi(\\'write_get_bytes_in_last_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_get_bytes_per_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_set_bytes_in_last_block\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_set_bytes_per_block\\', [c_archive_p, c_int], c_int, check_int)\\n\\nffi(\\'write_header\\', [c_archive_p, c_void_p], c_int, check_int)\\nffi(\\'write_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'write_data_block\\', [c_archive_p, c_void_p, c_size_t, c_longlong],\\n    c_int, check_int)\\nffi(\\'write_finish_entry\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_fail\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive encryption\\n\\ntry:\\n    ffi(\\'read_add_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\n    ffi(\\'write_set_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\nexcept AttributeError:\\n    logger.info(\\n        f\"the libarchive being used (version {version_number()}, \"\\n        f\"path {libarchive_path}) doesn\\'t support encryption\"\\n    )\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "b'READDISK_RESTORE_ATIME = 0x0001\\nREADDISK_HONOR_NODUMP = 0x0002\\nREADDISK_MAC_COPYFILE = 0x0004\\nREADDISK_NO_TRAVERSE_MOUNTS = 0x0008\\nREADDISK_NO_XATTR = 0x0010\\nREADDISK_NO_ACL = 0x0020\\nREADDISK_NO_FFLAGS = 0x0040\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "b'from contextlib import contextmanager\\nfrom ctypes import cast, c_void_p, POINTER, create_string_buffer\\nfrom os import fstat, stat\\n\\nfrom . import ffi\\nfrom .ffi import (\\n    ARCHIVE_EOF, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK, SEEK_CALLBACK,\\n    NO_OPEN_CB, NO_CLOSE_CB, page_size,\\n)\\nfrom .entry import ArchiveEntry, new_archive_entry\\n\\n\\nclass ArchiveRead:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def __iter__(self):\\n        \"\"\"Iterates through an archive\\'s entries.\\n        \"\"\"\\n        archive_p = self._pointer\\n        read_next_header2 = ffi.read_next_header2\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(archive_p, entry_p)\\n            while 1:\\n                r = read_next_header2(archive_p, entry_p)\\n                if r == ARCHIVE_EOF:\\n                    return\\n                yield entry\\n\\n\\n@contextmanager\\ndef new_archive_read(format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Creates an archive struct suitable for reading from an archive.\\n\\n    Returns a pointer if successful. Raises ArchiveError on error.\\n    \"\"\"\\n    archive_p = ffi.read_new()\\n    try:\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.read_add_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        ffi.get_read_filter_function(filter_name)(archive_p)\\n        ffi.get_read_format_function(format_name)(archive_p)\\n        yield archive_p\\n    finally:\\n        ffi.read_free(archive_p)\\n\\n\\n@contextmanager\\ndef custom_reader(\\n    read_func, format_name=\\'all\\', filter_name=\\'all\\',\\n    open_func=None, seek_func=None, close_func=None,\\n    block_size=page_size, archive_read_class=ArchiveRead, passphrase=None,\\n):\\n    \"\"\"Read an archive using a custom function.\\n    \"\"\"\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if seek_func:\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield archive_read_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_reader(\\n    fd, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file descriptor.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = fstat(fd).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_fd(archive_p, fd, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef file_reader(\\n    path, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = stat(path).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_filename_w(archive_p, path, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef memory_reader(buf, format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Read an archive from memory.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        ffi.read_open_memory(archive_p, cast(buf, c_void_p), len(buf))\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef stream_reader(\\n    stream, format_name=\\'all\\', filter_name=\\'all\\', block_size=page_size,\\n    passphrase=None,\\n):\\n    \"\"\"Read an archive from a stream.\\n\\n    The `stream` object must support the standard `readinto` method.\\n\\n    If `stream.seekable()` returns `True`, then an appropriate seek callback is\\n    passed to libarchive.\\n    \"\"\"\\n    buf = create_string_buffer(block_size)\\n    buf_p = cast(buf, c_void_p)\\n\\n    def read_func(archive_p, context, ptrptr):\\n        # readinto the buffer, returns number of bytes read\\n        length = stream.readinto(buf)\\n        # write the address of the buffer into the pointer\\n        ptrptr = cast(ptrptr, POINTER(c_void_p))\\n        ptrptr[0] = buf_p\\n        # tell libarchive how much data was written into the buffer\\n        return length\\n\\n    def seek_func(archive_p, context, offset, whence):\\n        stream.seek(offset, whence)\\n        # tell libarchive the current position\\n        return stream.tell()\\n\\n    open_cb = NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if stream.seekable():\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield ArchiveRead(archive_p)\\n\\n\\nseekable_stream_reader = stream_reader\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "b'from contextlib import contextmanager\\nfrom ctypes import byref, cast, c_char, c_size_t, c_void_p, POINTER\\nimport warnings\\n\\nfrom . import ffi\\nfrom .entry import ArchiveEntry, new_archive_entry\\nfrom .ffi import (\\n    OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK, NO_OPEN_CB, NO_CLOSE_CB,\\n    REGULAR_FILE, DEFAULT_UNIX_PERMISSION, ARCHIVE_EOF,\\n    page_size, entry_sourcepath, entry_clear, read_disk_new, read_disk_open_w,\\n    read_next_header2, read_disk_descend, read_free, write_header, write_data,\\n    write_finish_entry, entry_set_size, entry_set_filetype, entry_set_perm,\\n    read_disk_set_behavior\\n)\\n\\n\\n@contextmanager\\ndef new_archive_read_disk(path, flags=0, lookup=False):\\n    archive_p = read_disk_new()\\n    read_disk_set_behavior(archive_p, flags)\\n    if lookup:\\n        ffi.read_disk_set_standard_lookup(archive_p)\\n    read_disk_open_w(archive_p, path)\\n    try:\\n        yield archive_p\\n    finally:\\n        read_free(archive_p)\\n\\n\\nclass ArchiveWrite:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def add_entries(self, entries):\\n        \"\"\"Add the given entries to the archive.\\n        \"\"\"\\n        write_p = self._pointer\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            for block in entry.get_blocks():\\n                write_data(write_p, block, len(block))\\n            write_finish_entry(write_p)\\n\\n    def add_files(self, *paths, **kw):\\n        \"\"\"Read the given paths from disk and add them to the archive.\\n\\n        The keyword arguments (`**kw`) are passed to `new_archive_read_disk`.\\n        \"\"\"\\n        write_p = self._pointer\\n\\n        block_size = ffi.write_get_bytes_per_block(write_p)\\n        if block_size <= 0:\\n            block_size = 10240  # pragma: no cover\\n\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(None, entry_p)\\n            for path in paths:\\n                with new_archive_read_disk(path, **kw) as read_p:\\n                    while 1:\\n                        r = read_next_header2(read_p, entry_p)\\n                        if r == ARCHIVE_EOF:\\n                            break\\n                        entry.pathname = entry.pathname.lstrip(\\'/\\')\\n                        read_disk_descend(read_p)\\n                        write_header(write_p, entry_p)\\n                        if entry.isreg:\\n                            with open(entry_sourcepath(entry_p), \\'rb\\') as f:\\n                                while 1:\\n                                    data = f.read(block_size)\\n                                    if not data:\\n                                        break\\n                                    write_data(write_p, data, len(data))\\n                        write_finish_entry(write_p)\\n                        entry_clear(entry_p)\\n\\n    def add_file_from_memory(\\n        self, entry_path, entry_size, entry_data,\\n        filetype=REGULAR_FILE, permission=DEFAULT_UNIX_PERMISSION,\\n        atime=None, mtime=None, ctime=None, birthtime=None,\\n    ):\\n        \"\"\"\"Add file from memory to archive.\\n\\n        :param entry_path: where entry should be places in archive\\n        :type entry_path: str\\n        :param entry_size: entire size of entry in bytes\\n        :type entry_size: int\\n        :param entry_data: content of entry\\n        :type entry_data: bytes or Iterable[bytes]\\n        :param filetype: which type of file: normal, symlink etc.\\n        should entry be created as\\n        :type filetype: octal number\\n        :param permission: with which permission should entry be created\\n        :type permission: octal number\\n        :param atime: Last access time\\n        :type atime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param mtime: Last modified time\\n        :type mtime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param ctime: Creation time\\n        :type ctime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param birthtime: Birth time (for archive formats that support it)\\n        :type birthtime: int seconds or tuple (int seconds, int nanoseconds)\\n        \"\"\"\\n        archive_pointer = self._pointer\\n\\n        if isinstance(entry_data, bytes):\\n            entry_data = (entry_data,)\\n        elif isinstance(entry_data, str):\\n            raise TypeError(\\n                \"entry_data: expected bytes, got %r\" % type(entry_data)\\n            )\\n\\n        with new_archive_entry() as archive_entry_pointer:\\n            archive_entry = ArchiveEntry(None, archive_entry_pointer)\\n\\n            archive_entry.pathname = entry_path\\n            entry_set_size(archive_entry_pointer, entry_size)\\n            entry_set_filetype(archive_entry_pointer, filetype)\\n            entry_set_perm(archive_entry_pointer, permission)\\n\\n            if atime is not None:\\n                if not isinstance(atime, tuple):\\n                    atime = (atime, 0)\\n                archive_entry.set_atime(*atime)\\n            if mtime is not None:\\n                if not isinstance(mtime, tuple):\\n                    mtime = (mtime, 0)\\n                archive_entry.set_mtime(*mtime)\\n            if ctime is not None:\\n                if not isinstance(ctime, tuple):\\n                    ctime = (ctime, 0)\\n                archive_entry.set_ctime(*ctime)\\n            if birthtime is not None:\\n                if not isinstance(birthtime, tuple):\\n                    birthtime = (birthtime, 0)\\n                archive_entry.set_birthtime(*birthtime)\\n            write_header(archive_pointer, archive_entry_pointer)\\n\\n            for chunk in entry_data:\\n                if not chunk:\\n                    break\\n                write_data(archive_pointer, chunk, len(chunk))\\n\\n            write_finish_entry(archive_pointer)\\n            entry_clear(archive_entry_pointer)\\n\\n\\n@contextmanager\\ndef new_archive_write(format_name, filter_name=None, options=\\'\\', passphrase=None):\\n    archive_p = ffi.write_new()\\n    try:\\n        ffi.get_write_format_function(format_name)(archive_p)\\n        if filter_name:\\n            ffi.get_write_filter_function(filter_name)(archive_p)\\n        if passphrase and \\'encryption\\' not in options:\\n            if format_name == \\'zip\\':\\n                warnings.warn(\\n                    \"The default encryption scheme of zip archives is weak. \"\\n                    \"Use `options=\\'encryption=$type\\'` to specify the encryption \"\\n                    \"type you want to use. The supported values are \\'zipcrypt\\' \"\\n                    \"(the weak default), \\'aes128\\' and \\'aes256\\'.\"\\n                )\\n            options += \\',encryption\\' if options else \\'encryption\\'\\n        if options:\\n            if not isinstance(options, bytes):\\n                options = options.encode(\\'utf-8\\')\\n            ffi.write_set_options(archive_p, options)\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.write_set_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        yield archive_p\\n        ffi.write_close(archive_p)\\n        ffi.write_free(archive_p)\\n    except Exception:\\n        ffi.write_fail(archive_p)\\n        ffi.write_free(archive_p)\\n        raise\\n\\n\\n@contextmanager\\ndef custom_writer(\\n    write_func, format_name, filter_name=None,\\n    open_func=None, close_func=None, block_size=page_size,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n\\n    def write_cb_internal(archive_p, context, buffer_, length):\\n        data = cast(buffer_, POINTER(c_char * length))[0]\\n        return write_func(data)\\n\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    write_cb = WRITE_CALLBACK(write_cb_internal)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_set_bytes_in_last_block(archive_p, 1)\\n        ffi.write_set_bytes_per_block(archive_p, block_size)\\n        ffi.write_open(archive_p, None, open_cb, write_cb, close_cb)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_writer(\\n    fd, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_fd(archive_p, fd)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef file_writer(\\n    filepath, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_filename_w(archive_p, filepath)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef memory_writer(\\n    buf, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        used = byref(c_size_t())\\n        buf_p = cast(buf, c_void_p)\\n        ffi.write_open_memory(archive_p, buf_p, len(buf), used)\\n        yield archive_write_class(archive_p)\\n'"}]}, "get_python_source": {"line": 37, "args": [{"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/__init__.py'"}, "return_value": "'from .entry import ArchiveEntry\\nfrom .exception import ArchiveError\\nfrom .extract import extract_fd, extract_file, extract_memory\\nfrom .read import (\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader\\n)\\nfrom .write import custom_writer, fd_writer, file_writer, memory_writer\\n\\n__all__ = [x.__name__ for x in (\\n    ArchiveEntry,\\n    ArchiveError,\\n    extract_fd, extract_file, extract_memory,\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader,\\n    custom_writer, fd_writer, file_writer, memory_writer\\n)]\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/entry.py'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import c_char_p, create_string_buffer\\n\\nfrom . import ffi\\n\\n\\n@contextmanager\\ndef new_archive_entry():\\n    entry_p = ffi.entry_new()\\n    try:\\n        yield entry_p\\n    finally:\\n        ffi.entry_free(entry_p)\\n\\n\\ndef format_time(seconds, nanos):\\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\\n    if nanos:\\n        return float(seconds) + float(nanos) / 1000000000.0\\n    return int(seconds)\\n\\n\\nclass ArchiveEntry:\\n\\n    __slots__ = (\\'_archive_p\\', \\'_entry_p\\')\\n\\n    def __init__(self, archive_p, entry_p):\\n        self._archive_p = archive_p\\n        self._entry_p = entry_p\\n\\n    def __str__(self):\\n        return self.pathname\\n\\n    @property\\n    def filetype(self):\\n        return ffi.entry_filetype(self._entry_p)\\n\\n    @property\\n    def uid(self):\\n        return ffi.entry_uid(self._entry_p)\\n\\n    @property\\n    def gid(self):\\n        return ffi.entry_gid(self._entry_p)\\n\\n    def get_blocks(self, block_size=ffi.page_size):\\n        archive_p = self._archive_p\\n        buf = create_string_buffer(block_size)\\n        read = ffi.read_data\\n        while 1:\\n            r = read(archive_p, buf, block_size)\\n            if r == 0:\\n                break\\n            yield buf.raw[0:r]\\n\\n    @property\\n    def isblk(self):\\n        return self.filetype & 0o170000 == 0o060000\\n\\n    @property\\n    def ischr(self):\\n        return self.filetype & 0o170000 == 0o020000\\n\\n    @property\\n    def isdir(self):\\n        return self.filetype & 0o170000 == 0o040000\\n\\n    @property\\n    def isfifo(self):\\n        return self.filetype & 0o170000 == 0o010000\\n\\n    @property\\n    def islnk(self):\\n        return bool(ffi.entry_hardlink_w(self._entry_p) or\\n                    ffi.entry_hardlink(self._entry_p))\\n\\n    @property\\n    def issym(self):\\n        return self.filetype & 0o170000 == 0o120000\\n\\n    def _linkpath(self):\\n        return (ffi.entry_symlink_w(self._entry_p) or\\n                ffi.entry_hardlink_w(self._entry_p) or\\n                ffi.entry_symlink(self._entry_p) or\\n                ffi.entry_hardlink(self._entry_p))\\n\\n    # aliases to get the same api as tarfile\\n    linkpath = property(_linkpath)\\n    linkname = property(_linkpath)\\n\\n    @property\\n    def isreg(self):\\n        return self.filetype & 0o170000 == 0o100000\\n\\n    @property\\n    def isfile(self):\\n        return self.isreg\\n\\n    @property\\n    def issock(self):\\n        return self.filetype & 0o170000 == 0o140000\\n\\n    @property\\n    def isdev(self):\\n        return self.ischr or self.isblk or self.isfifo or self.issock\\n\\n    @property\\n    def atime(self):\\n        sec_val = ffi.entry_atime(self._entry_p)\\n        nsec_val = ffi.entry_atime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_atime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_atime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def mtime(self):\\n        sec_val = ffi.entry_mtime(self._entry_p)\\n        nsec_val = ffi.entry_mtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_mtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_mtime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def ctime(self):\\n        sec_val = ffi.entry_ctime(self._entry_p)\\n        nsec_val = ffi.entry_ctime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_ctime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_ctime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def birthtime(self):\\n        sec_val = ffi.entry_birthtime(self._entry_p)\\n        nsec_val = ffi.entry_birthtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_birthtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_birthtime(self._entry_p,\\n                                       timestamp_sec, timestamp_nsec)\\n\\n    def _getpathname(self):\\n        return (ffi.entry_pathname_w(self._entry_p) or\\n                ffi.entry_pathname(self._entry_p))\\n\\n    def _setpathname(self, value):\\n        if not isinstance(value, bytes):\\n            value = value.encode(\\'utf8\\')\\n        ffi.entry_update_pathname_utf8(self._entry_p, c_char_p(value))\\n\\n    pathname = property(_getpathname, _setpathname)\\n    # aliases to get the same api as tarfile\\n    path = property(_getpathname, _setpathname)\\n    name = property(_getpathname, _setpathname)\\n\\n    @property\\n    def size(self):\\n        if ffi.entry_size_is_set(self._entry_p):\\n            return ffi.entry_size(self._entry_p)\\n\\n    @property\\n    def mode(self):\\n        return ffi.entry_mode(self._entry_p)\\n\\n    @property\\n    def strmode(self):\\n        # note we strip the mode because archive_entry_strmode\\n        # returns a trailing space: strcpy(bp, \"?rwxrwxrwx \");\\n        return ffi.entry_strmode(self._entry_p).strip()\\n\\n    @property\\n    def rdevmajor(self):\\n        return ffi.entry_rdevmajor(self._entry_p)\\n\\n    @property\\n    def rdevminor(self):\\n        return ffi.entry_rdevminor(self._entry_p)\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/exception.py'"}, "return_value": "\"\\nclass ArchiveError(Exception):\\n\\n    def __init__(self, msg, errno=None, retcode=None, archive_p=None):\\n        self.msg = msg\\n        self.errno = errno\\n        self.retcode = retcode\\n        self.archive_p = archive_p\\n\\n    def __str__(self):\\n        p = '%s (errno=%s, retcode=%s, archive_p=%s)'\\n        return p % (self.msg, self.errno, self.retcode, self.archive_p)\\n\""}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/extract.py'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import byref, c_longlong, c_size_t, c_void_p\\n\\nfrom .ffi import (\\n    write_disk_new, write_disk_set_options, write_free, write_header,\\n    read_data_block, write_data_block, write_finish_entry, ARCHIVE_EOF\\n)\\nfrom .read import fd_reader, file_reader, memory_reader\\n\\n\\nEXTRACT_OWNER = 0x0001\\nEXTRACT_PERM = 0x0002\\nEXTRACT_TIME = 0x0004\\nEXTRACT_NO_OVERWRITE = 0x0008\\nEXTRACT_UNLINK = 0x0010\\nEXTRACT_ACL = 0x0020\\nEXTRACT_FFLAGS = 0x0040\\nEXTRACT_XATTR = 0x0080\\nEXTRACT_SECURE_SYMLINKS = 0x0100\\nEXTRACT_SECURE_NODOTDOT = 0x0200\\nEXTRACT_NO_AUTODIR = 0x0400\\nEXTRACT_NO_OVERWRITE_NEWER = 0x0800\\nEXTRACT_SPARSE = 0x1000\\nEXTRACT_MAC_METADATA = 0x2000\\nEXTRACT_NO_HFS_COMPRESSION = 0x4000\\nEXTRACT_HFS_COMPRESSION_FORCED = 0x8000\\nEXTRACT_SECURE_NOABSOLUTEPATHS = 0x10000\\nEXTRACT_CLEAR_NOCHANGE_FFLAGS = 0x20000\\n\\n\\n@contextmanager\\ndef new_archive_write_disk(flags):\\n    archive_p = write_disk_new()\\n    write_disk_set_options(archive_p, flags)\\n    try:\\n        yield archive_p\\n    finally:\\n        write_free(archive_p)\\n\\n\\ndef extract_entries(entries, flags=0):\\n    \"\"\"Extracts the given archive entries into the current directory.\\n    \"\"\"\\n    buff, size, offset = c_void_p(), c_size_t(), c_longlong()\\n    buff_p, size_p, offset_p = byref(buff), byref(size), byref(offset)\\n    with new_archive_write_disk(flags) as write_p:\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            read_p = entry._archive_p\\n            while 1:\\n                r = read_data_block(read_p, buff_p, size_p, offset_p)\\n                if r == ARCHIVE_EOF:\\n                    break\\n                write_data_block(write_p, buff, size, offset)\\n            write_finish_entry(write_p)\\n\\n\\ndef extract_fd(fd, flags=0):\\n    \"\"\"Extracts an archive from a file descriptor into the current directory.\\n    \"\"\"\\n    with fd_reader(fd) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_file(filepath, flags=0):\\n    \"\"\"Extracts an archive from a file into the current directory.\"\"\"\\n    with file_reader(filepath) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_memory(buffer_, flags=0):\\n    \"\"\"Extracts an archive from memory into the current directory.\"\"\"\\n    with memory_reader(buffer_) as archive:\\n        extract_entries(archive, flags)\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/ffi.py'"}, "return_value": "'from ctypes import (\\n    c_char_p, c_int, c_uint, c_long, c_longlong, c_size_t, c_int64,\\n    c_void_p, c_wchar_p, CFUNCTYPE, POINTER,\\n)\\n\\ntry:\\n    from ctypes import c_ssize_t\\nexcept ImportError:\\n    from ctypes import c_longlong as c_ssize_t\\n\\nimport ctypes\\nfrom ctypes.util import find_library\\nimport logging\\nimport mmap\\nimport os\\nimport sysconfig\\n\\nfrom .exception import ArchiveError\\n\\n\\nlogger = logging.getLogger(\\'libarchive\\')\\n\\npage_size = mmap.PAGESIZE\\n\\nlibarchive_path = os.environ.get(\\'LIBARCHIVE\\') or find_library(\\'archive\\')\\nlibarchive = ctypes.cdll.LoadLibrary(libarchive_path)\\n\\n\\n# Constants\\n\\nARCHIVE_EOF = 1       # Found end of archive.\\nARCHIVE_OK = 0        # Operation was successful.\\nARCHIVE_RETRY = -10   # Retry might succeed.\\nARCHIVE_WARN = -20    # Partial success.\\nARCHIVE_FAILED = -25  # Current operation cannot complete.\\nARCHIVE_FATAL = -30   # No more operations are possible.\\nREGULAR_FILE = 0o100000\\nDEFAULT_UNIX_PERMISSION = 0o664\\n\\n\\n# Callback types\\n\\nWRITE_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p), c_size_t\\n)\\nREAD_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p)\\n)\\nSEEK_CALLBACK = CFUNCTYPE(\\n    c_longlong, c_void_p, c_void_p, c_longlong, c_int\\n)\\nOPEN_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\nCLOSE_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\n\\nNO_OPEN_CB = ctypes.cast(None, OPEN_CALLBACK)\\nNO_CLOSE_CB = ctypes.cast(None, CLOSE_CALLBACK)\\n\\n\\n# Type aliases, for readability\\n\\nc_archive_p = c_void_p\\nc_archive_entry_p = c_void_p\\n\\nif sysconfig.get_config_var(\\'SIZEOF_TIME_T\\') == 8:\\n    c_time_t = c_int64\\nelse:\\n    c_time_t = c_long\\n\\n\\n# Helper functions\\n\\ndef _error_string(archive_p):\\n    msg = error_string(archive_p)\\n    if msg is None:\\n        return\\n    try:\\n        return msg.decode(\\'ascii\\')\\n    except UnicodeDecodeError:\\n        return msg\\n\\n\\ndef archive_error(archive_p, retcode):\\n    msg = _error_string(archive_p)\\n    return ArchiveError(msg, errno(archive_p), retcode, archive_p)\\n\\n\\ndef check_null(ret, func, args):\\n    if ret is None:\\n        raise ArchiveError(func.__name__+\\' returned NULL\\')\\n    return ret\\n\\n\\ndef check_int(retcode, func, args):\\n    if retcode >= 0:\\n        return retcode\\n    elif retcode == ARCHIVE_WARN:\\n        logger.warning(_error_string(args[0]))\\n        return retcode\\n    else:\\n        raise archive_error(args[0], retcode)\\n\\n\\ndef ffi(name, argtypes, restype, errcheck=None):\\n    f = getattr(libarchive, \\'archive_\\'+name)\\n    f.argtypes = argtypes\\n    f.restype = restype\\n    if errcheck:\\n        f.errcheck = errcheck\\n    globals()[name] = f\\n    return f\\n\\n\\ndef get_read_format_function(format_name):\\n    function_name = \\'read_support_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read format %r is not available\\' % format_name)\\n\\n\\ndef get_read_filter_function(filter_name):\\n    function_name = \\'read_support_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read filter %r is not available\\' % filter_name)\\n\\n\\ndef get_write_format_function(format_name):\\n    function_name = \\'write_set_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write format %r is not available\\' % format_name)\\n\\n\\ndef get_write_filter_function(filter_name):\\n    function_name = \\'write_add_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write filter %r is not available\\' % filter_name)\\n\\n\\n# FFI declarations\\n\\n# library version\\nversion_number = ffi(\\'version_number\\', [], c_int, check_int)\\n\\n# archive_util\\n\\nerrno = ffi(\\'errno\\', [c_archive_p], c_int)\\nerror_string = ffi(\\'error_string\\', [c_archive_p], c_char_p)\\n\\n# archive_entry\\n\\nffi(\\'entry_new\\', [], c_archive_entry_p, check_null)\\n\\nffi(\\'entry_filetype\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_atime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_birthtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_mtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_ctime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_atime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_birthtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_mtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_ctime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_pathname\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_pathname_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_sourcepath\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_size\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_size_is_set\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_mode\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_strmode\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_symlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_symlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_rdevmajor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_rdevminor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_uid\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_gid\\', [c_archive_entry_p], c_longlong)\\n\\nffi(\\'entry_set_size\\', [c_archive_entry_p, c_longlong], None)\\nffi(\\'entry_set_filetype\\', [c_archive_entry_p, c_uint], None)\\nffi(\\'entry_set_perm\\', [c_archive_entry_p, c_int], None)\\nffi(\\'entry_set_atime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_mtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_ctime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_birthtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\n\\nffi(\\'entry_update_pathname_utf8\\', [c_archive_entry_p, c_char_p], None)\\n\\nffi(\\'entry_clear\\', [c_archive_entry_p], c_archive_entry_p)\\nffi(\\'entry_free\\', [c_archive_entry_p], None)\\n\\n# archive_read\\n\\nffi(\\'read_new\\', [], c_archive_p, check_null)\\n\\nREAD_FORMATS = set((\\n    \\'7zip\\', \\'all\\', \\'ar\\', \\'cab\\', \\'cpio\\', \\'empty\\', \\'iso9660\\', \\'lha\\', \\'mtree\\',\\n    \\'rar\\', \\'raw\\', \\'tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(READ_FORMATS):\\n    try:\\n        get_read_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FORMATS.remove(f_name)\\n\\nREAD_FILTERS = set((\\n    \\'all\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'none\\', \\'rpm\\', \\'uu\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(READ_FILTERS):\\n    try:\\n        get_read_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FILTERS.remove(f_name)\\n\\nffi(\\'read_set_seek_callback\\', [c_archive_p, SEEK_CALLBACK], c_int, check_int)\\n\\nffi(\\'read_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'read_open_fd\\', [c_archive_p, c_int, c_size_t], c_int, check_int)\\nffi(\\'read_open_filename_w\\', [c_archive_p, c_wchar_p, c_size_t],\\n    c_int, check_int)\\nffi(\\'read_open_memory\\', [c_archive_p, c_void_p, c_size_t], c_int, check_int)\\n\\nffi(\\'read_next_header\\', [c_archive_p, POINTER(c_void_p)], c_int, check_int)\\nffi(\\'read_next_header2\\', [c_archive_p, c_void_p], c_int, check_int)\\n\\nffi(\\'read_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_disk\\n\\nffi(\\'read_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'read_disk_set_behavior\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'read_disk_set_standard_lookup\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_disk_open\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'read_disk_open_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'read_disk_descend\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_data\\n\\nffi(\\'read_data_block\\',\\n    [c_archive_p, POINTER(c_void_p), POINTER(c_size_t), POINTER(c_longlong)],\\n    c_int, check_int)\\nffi(\\'read_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'read_data_skip\\', [c_archive_p], c_int, check_int)\\n\\n# archive_write\\n\\nffi(\\'write_new\\', [], c_archive_p, check_null)\\nffi(\\'write_set_options\\', [c_archive_p, c_char_p], c_int, check_int)\\n\\nffi(\\'write_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'write_disk_set_options\\', [c_archive_p, c_int], c_int, check_int)\\n\\nWRITE_FORMATS = set((\\n    \\'7zip\\', \\'ar_bsd\\', \\'ar_svr4\\', \\'cpio\\', \\'cpio_newc\\', \\'gnutar\\', \\'iso9660\\',\\n    \\'mtree\\', \\'mtree_classic\\', \\'pax\\', \\'pax_restricted\\', \\'shar\\', \\'shar_dump\\',\\n    \\'ustar\\', \\'v7tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(WRITE_FORMATS):\\n    try:\\n        get_write_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FORMATS.remove(f_name)\\n\\nWRITE_FILTERS = set((\\n    \\'b64encode\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'uuencode\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(WRITE_FILTERS):\\n    try:\\n        get_write_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FILTERS.remove(f_name)\\n\\nffi(\\'write_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'write_open_fd\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_open_filename\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'write_open_filename_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'write_open_memory\\',\\n    [c_archive_p, c_void_p, c_size_t, POINTER(c_size_t)],\\n    c_int, check_int)\\n\\nffi(\\'write_get_bytes_in_last_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_get_bytes_per_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_set_bytes_in_last_block\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_set_bytes_per_block\\', [c_archive_p, c_int], c_int, check_int)\\n\\nffi(\\'write_header\\', [c_archive_p, c_void_p], c_int, check_int)\\nffi(\\'write_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'write_data_block\\', [c_archive_p, c_void_p, c_size_t, c_longlong],\\n    c_int, check_int)\\nffi(\\'write_finish_entry\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_fail\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive encryption\\n\\ntry:\\n    ffi(\\'read_add_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\n    ffi(\\'write_set_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\nexcept AttributeError:\\n    logger.info(\\n        f\"the libarchive being used (version {version_number()}, \"\\n        f\"path {libarchive_path}) doesn\\'t support encryption\"\\n    )\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/flags.py'"}, "return_value": "'READDISK_RESTORE_ATIME = 0x0001\\nREADDISK_HONOR_NODUMP = 0x0002\\nREADDISK_MAC_COPYFILE = 0x0004\\nREADDISK_NO_TRAVERSE_MOUNTS = 0x0008\\nREADDISK_NO_XATTR = 0x0010\\nREADDISK_NO_ACL = 0x0020\\nREADDISK_NO_FFLAGS = 0x0040\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/read.py'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import cast, c_void_p, POINTER, create_string_buffer\\nfrom os import fstat, stat\\n\\nfrom . import ffi\\nfrom .ffi import (\\n    ARCHIVE_EOF, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK, SEEK_CALLBACK,\\n    NO_OPEN_CB, NO_CLOSE_CB, page_size,\\n)\\nfrom .entry import ArchiveEntry, new_archive_entry\\n\\n\\nclass ArchiveRead:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def __iter__(self):\\n        \"\"\"Iterates through an archive\\'s entries.\\n        \"\"\"\\n        archive_p = self._pointer\\n        read_next_header2 = ffi.read_next_header2\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(archive_p, entry_p)\\n            while 1:\\n                r = read_next_header2(archive_p, entry_p)\\n                if r == ARCHIVE_EOF:\\n                    return\\n                yield entry\\n\\n\\n@contextmanager\\ndef new_archive_read(format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Creates an archive struct suitable for reading from an archive.\\n\\n    Returns a pointer if successful. Raises ArchiveError on error.\\n    \"\"\"\\n    archive_p = ffi.read_new()\\n    try:\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.read_add_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        ffi.get_read_filter_function(filter_name)(archive_p)\\n        ffi.get_read_format_function(format_name)(archive_p)\\n        yield archive_p\\n    finally:\\n        ffi.read_free(archive_p)\\n\\n\\n@contextmanager\\ndef custom_reader(\\n    read_func, format_name=\\'all\\', filter_name=\\'all\\',\\n    open_func=None, seek_func=None, close_func=None,\\n    block_size=page_size, archive_read_class=ArchiveRead, passphrase=None,\\n):\\n    \"\"\"Read an archive using a custom function.\\n    \"\"\"\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if seek_func:\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield archive_read_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_reader(\\n    fd, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file descriptor.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = fstat(fd).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_fd(archive_p, fd, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef file_reader(\\n    path, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = stat(path).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_filename_w(archive_p, path, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef memory_reader(buf, format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Read an archive from memory.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        ffi.read_open_memory(archive_p, cast(buf, c_void_p), len(buf))\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef stream_reader(\\n    stream, format_name=\\'all\\', filter_name=\\'all\\', block_size=page_size,\\n    passphrase=None,\\n):\\n    \"\"\"Read an archive from a stream.\\n\\n    The `stream` object must support the standard `readinto` method.\\n\\n    If `stream.seekable()` returns `True`, then an appropriate seek callback is\\n    passed to libarchive.\\n    \"\"\"\\n    buf = create_string_buffer(block_size)\\n    buf_p = cast(buf, c_void_p)\\n\\n    def read_func(archive_p, context, ptrptr):\\n        # readinto the buffer, returns number of bytes read\\n        length = stream.readinto(buf)\\n        # write the address of the buffer into the pointer\\n        ptrptr = cast(ptrptr, POINTER(c_void_p))\\n        ptrptr[0] = buf_p\\n        # tell libarchive how much data was written into the buffer\\n        return length\\n\\n    def seek_func(archive_p, context, offset, whence):\\n        stream.seek(offset, whence)\\n        # tell libarchive the current position\\n        return stream.tell()\\n\\n    open_cb = NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if stream.seekable():\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield ArchiveRead(archive_p)\\n\\n\\nseekable_stream_reader = stream_reader\\n'"}, {"func_args": {"filename": "'/usr/app/src/test_repos/python-libarchive-c/libarchive/write.py'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import byref, cast, c_char, c_size_t, c_void_p, POINTER\\nimport warnings\\n\\nfrom . import ffi\\nfrom .entry import ArchiveEntry, new_archive_entry\\nfrom .ffi import (\\n    OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK, NO_OPEN_CB, NO_CLOSE_CB,\\n    REGULAR_FILE, DEFAULT_UNIX_PERMISSION, ARCHIVE_EOF,\\n    page_size, entry_sourcepath, entry_clear, read_disk_new, read_disk_open_w,\\n    read_next_header2, read_disk_descend, read_free, write_header, write_data,\\n    write_finish_entry, entry_set_size, entry_set_filetype, entry_set_perm,\\n    read_disk_set_behavior\\n)\\n\\n\\n@contextmanager\\ndef new_archive_read_disk(path, flags=0, lookup=False):\\n    archive_p = read_disk_new()\\n    read_disk_set_behavior(archive_p, flags)\\n    if lookup:\\n        ffi.read_disk_set_standard_lookup(archive_p)\\n    read_disk_open_w(archive_p, path)\\n    try:\\n        yield archive_p\\n    finally:\\n        read_free(archive_p)\\n\\n\\nclass ArchiveWrite:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def add_entries(self, entries):\\n        \"\"\"Add the given entries to the archive.\\n        \"\"\"\\n        write_p = self._pointer\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            for block in entry.get_blocks():\\n                write_data(write_p, block, len(block))\\n            write_finish_entry(write_p)\\n\\n    def add_files(self, *paths, **kw):\\n        \"\"\"Read the given paths from disk and add them to the archive.\\n\\n        The keyword arguments (`**kw`) are passed to `new_archive_read_disk`.\\n        \"\"\"\\n        write_p = self._pointer\\n\\n        block_size = ffi.write_get_bytes_per_block(write_p)\\n        if block_size <= 0:\\n            block_size = 10240  # pragma: no cover\\n\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(None, entry_p)\\n            for path in paths:\\n                with new_archive_read_disk(path, **kw) as read_p:\\n                    while 1:\\n                        r = read_next_header2(read_p, entry_p)\\n                        if r == ARCHIVE_EOF:\\n                            break\\n                        entry.pathname = entry.pathname.lstrip(\\'/\\')\\n                        read_disk_descend(read_p)\\n                        write_header(write_p, entry_p)\\n                        if entry.isreg:\\n                            with open(entry_sourcepath(entry_p), \\'rb\\') as f:\\n                                while 1:\\n                                    data = f.read(block_size)\\n                                    if not data:\\n                                        break\\n                                    write_data(write_p, data, len(data))\\n                        write_finish_entry(write_p)\\n                        entry_clear(entry_p)\\n\\n    def add_file_from_memory(\\n        self, entry_path, entry_size, entry_data,\\n        filetype=REGULAR_FILE, permission=DEFAULT_UNIX_PERMISSION,\\n        atime=None, mtime=None, ctime=None, birthtime=None,\\n    ):\\n        \"\"\"\"Add file from memory to archive.\\n\\n        :param entry_path: where entry should be places in archive\\n        :type entry_path: str\\n        :param entry_size: entire size of entry in bytes\\n        :type entry_size: int\\n        :param entry_data: content of entry\\n        :type entry_data: bytes or Iterable[bytes]\\n        :param filetype: which type of file: normal, symlink etc.\\n        should entry be created as\\n        :type filetype: octal number\\n        :param permission: with which permission should entry be created\\n        :type permission: octal number\\n        :param atime: Last access time\\n        :type atime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param mtime: Last modified time\\n        :type mtime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param ctime: Creation time\\n        :type ctime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param birthtime: Birth time (for archive formats that support it)\\n        :type birthtime: int seconds or tuple (int seconds, int nanoseconds)\\n        \"\"\"\\n        archive_pointer = self._pointer\\n\\n        if isinstance(entry_data, bytes):\\n            entry_data = (entry_data,)\\n        elif isinstance(entry_data, str):\\n            raise TypeError(\\n                \"entry_data: expected bytes, got %r\" % type(entry_data)\\n            )\\n\\n        with new_archive_entry() as archive_entry_pointer:\\n            archive_entry = ArchiveEntry(None, archive_entry_pointer)\\n\\n            archive_entry.pathname = entry_path\\n            entry_set_size(archive_entry_pointer, entry_size)\\n            entry_set_filetype(archive_entry_pointer, filetype)\\n            entry_set_perm(archive_entry_pointer, permission)\\n\\n            if atime is not None:\\n                if not isinstance(atime, tuple):\\n                    atime = (atime, 0)\\n                archive_entry.set_atime(*atime)\\n            if mtime is not None:\\n                if not isinstance(mtime, tuple):\\n                    mtime = (mtime, 0)\\n                archive_entry.set_mtime(*mtime)\\n            if ctime is not None:\\n                if not isinstance(ctime, tuple):\\n                    ctime = (ctime, 0)\\n                archive_entry.set_ctime(*ctime)\\n            if birthtime is not None:\\n                if not isinstance(birthtime, tuple):\\n                    birthtime = (birthtime, 0)\\n                archive_entry.set_birthtime(*birthtime)\\n            write_header(archive_pointer, archive_entry_pointer)\\n\\n            for chunk in entry_data:\\n                if not chunk:\\n                    break\\n                write_data(archive_pointer, chunk, len(chunk))\\n\\n            write_finish_entry(archive_pointer)\\n            entry_clear(archive_entry_pointer)\\n\\n\\n@contextmanager\\ndef new_archive_write(format_name, filter_name=None, options=\\'\\', passphrase=None):\\n    archive_p = ffi.write_new()\\n    try:\\n        ffi.get_write_format_function(format_name)(archive_p)\\n        if filter_name:\\n            ffi.get_write_filter_function(filter_name)(archive_p)\\n        if passphrase and \\'encryption\\' not in options:\\n            if format_name == \\'zip\\':\\n                warnings.warn(\\n                    \"The default encryption scheme of zip archives is weak. \"\\n                    \"Use `options=\\'encryption=$type\\'` to specify the encryption \"\\n                    \"type you want to use. The supported values are \\'zipcrypt\\' \"\\n                    \"(the weak default), \\'aes128\\' and \\'aes256\\'.\"\\n                )\\n            options += \\',encryption\\' if options else \\'encryption\\'\\n        if options:\\n            if not isinstance(options, bytes):\\n                options = options.encode(\\'utf-8\\')\\n            ffi.write_set_options(archive_p, options)\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.write_set_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        yield archive_p\\n        ffi.write_close(archive_p)\\n        ffi.write_free(archive_p)\\n    except Exception:\\n        ffi.write_fail(archive_p)\\n        ffi.write_free(archive_p)\\n        raise\\n\\n\\n@contextmanager\\ndef custom_writer(\\n    write_func, format_name, filter_name=None,\\n    open_func=None, close_func=None, block_size=page_size,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n\\n    def write_cb_internal(archive_p, context, buffer_, length):\\n        data = cast(buffer_, POINTER(c_char * length))[0]\\n        return write_func(data)\\n\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    write_cb = WRITE_CALLBACK(write_cb_internal)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_set_bytes_in_last_block(archive_p, 1)\\n        ffi.write_set_bytes_per_block(archive_p, block_size)\\n        ffi.write_open(archive_p, None, open_cb, write_cb, close_cb)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_writer(\\n    fd, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_fd(archive_p, fd)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef file_writer(\\n    filepath, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_filename_w(archive_p, filepath)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef memory_writer(\\n    buf, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        used = byref(c_size_t())\\n        buf_p = cast(buf, c_void_p)\\n        ffi.write_open_memory(archive_p, buf_p, len(buf), used)\\n        yield archive_write_class(archive_p)\\n'"}]}, "source_encoding": {"line": 184, "args": [{"func_args": {"source": "b'from .entry import ArchiveEntry\\nfrom .exception import ArchiveError\\nfrom .extract import extract_fd, extract_file, extract_memory\\nfrom .read import (\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader\\n)\\nfrom .write import custom_writer, fd_writer, file_writer, memory_writer\\n\\n__all__ = [x.__name__ for x in (\\n    ArchiveEntry,\\n    ArchiveError,\\n    extract_fd, extract_file, extract_memory,\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader,\\n    custom_writer, fd_writer, file_writer, memory_writer\\n)]\\n'"}, "return_value": "'utf-8'"}, {"func_args": {"source": "b'from contextlib import contextmanager\\nfrom ctypes import c_char_p, create_string_buffer\\n\\nfrom . import ffi\\n\\n\\n@contextmanager\\ndef new_archive_entry():\\n    entry_p = ffi.entry_new()\\n    try:\\n        yield entry_p\\n    finally:\\n        ffi.entry_free(entry_p)\\n\\n\\ndef format_time(seconds, nanos):\\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\\n    if nanos:\\n        return float(seconds) + float(nanos) / 1000000000.0\\n    return int(seconds)\\n\\n\\nclass ArchiveEntry:\\n\\n    __slots__ = (\\'_archive_p\\', \\'_entry_p\\')\\n\\n    def __init__(self, archive_p, entry_p):\\n        self._archive_p = archive_p\\n        self._entry_p = entry_p\\n\\n    def __str__(self):\\n        return self.pathname\\n\\n    @property\\n    def filetype(self):\\n        return ffi.entry_filetype(self._entry_p)\\n\\n    @property\\n    def uid(self):\\n        return ffi.entry_uid(self._entry_p)\\n\\n    @property\\n    def gid(self):\\n        return ffi.entry_gid(self._entry_p)\\n\\n    def get_blocks(self, block_size=ffi.page_size):\\n        archive_p = self._archive_p\\n        buf = create_string_buffer(block_size)\\n        read = ffi.read_data\\n        while 1:\\n            r = read(archive_p, buf, block_size)\\n            if r == 0:\\n                break\\n            yield buf.raw[0:r]\\n\\n    @property\\n    def isblk(self):\\n        return self.filetype & 0o170000 == 0o060000\\n\\n    @property\\n    def ischr(self):\\n        return self.filetype & 0o170000 == 0o020000\\n\\n    @property\\n    def isdir(self):\\n        return self.filetype & 0o170000 == 0o040000\\n\\n    @property\\n    def isfifo(self):\\n        return self.filetype & 0o170000 == 0o010000\\n\\n    @property\\n    def islnk(self):\\n        return bool(ffi.entry_hardlink_w(self._entry_p) or\\n                    ffi.entry_hardlink(self._entry_p))\\n\\n    @property\\n    def issym(self):\\n        return self.filetype & 0o170000 == 0o120000\\n\\n    def _linkpath(self):\\n        return (ffi.entry_symlink_w(self._entry_p) or\\n                ffi.entry_hardlink_w(self._entry_p) or\\n                ffi.entry_symlink(self._entry_p) or\\n                ffi.entry_hardlink(self._entry_p))\\n\\n    # aliases to get the same api as tarfile\\n    linkpath = property(_linkpath)\\n    linkname = property(_linkpath)\\n\\n    @property\\n    def isreg(self):\\n        return self.filetype & 0o170000 == 0o100000\\n\\n    @property\\n    def isfile(self):\\n        return self.isreg\\n\\n    @property\\n    def issock(self):\\n        return self.filetype & 0o170000 == 0o140000\\n\\n    @property\\n    def isdev(self):\\n        return self.ischr or self.isblk or self.isfifo or self.issock\\n\\n    @property\\n    def atime(self):\\n        sec_val = ffi.entry_atime(self._entry_p)\\n        nsec_val = ffi.entry_atime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_atime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_atime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def mtime(self):\\n        sec_val = ffi.entry_mtime(self._entry_p)\\n        nsec_val = ffi.entry_mtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_mtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_mtime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def ctime(self):\\n        sec_val = ffi.entry_ctime(self._entry_p)\\n        nsec_val = ffi.entry_ctime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_ctime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_ctime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def birthtime(self):\\n        sec_val = ffi.entry_birthtime(self._entry_p)\\n        nsec_val = ffi.entry_birthtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_birthtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_birthtime(self._entry_p,\\n                                       timestamp_sec, timestamp_nsec)\\n\\n    def _getpathname(self):\\n        return (ffi.entry_pathname_w(self._entry_p) or\\n                ffi.entry_pathname(self._entry_p))\\n\\n    def _setpathname(self, value):\\n        if not isinstance(value, bytes):\\n            value = value.encode(\\'utf8\\')\\n        ffi.entry_update_pathname_utf8(self._entry_p, c_char_p(value))\\n\\n    pathname = property(_getpathname, _setpathname)\\n    # aliases to get the same api as tarfile\\n    path = property(_getpathname, _setpathname)\\n    name = property(_getpathname, _setpathname)\\n\\n    @property\\n    def size(self):\\n        if ffi.entry_size_is_set(self._entry_p):\\n            return ffi.entry_size(self._entry_p)\\n\\n    @property\\n    def mode(self):\\n        return ffi.entry_mode(self._entry_p)\\n\\n    @property\\n    def strmode(self):\\n        # note we strip the mode because archive_entry_strmode\\n        # returns a trailing space: strcpy(bp, \"?rwxrwxrwx \");\\n        return ffi.entry_strmode(self._entry_p).strip()\\n\\n    @property\\n    def rdevmajor(self):\\n        return ffi.entry_rdevmajor(self._entry_p)\\n\\n    @property\\n    def rdevminor(self):\\n        return ffi.entry_rdevminor(self._entry_p)\\n'"}, "return_value": "'utf-8'"}, {"func_args": {"source": "b\"\\nclass ArchiveError(Exception):\\n\\n    def __init__(self, msg, errno=None, retcode=None, archive_p=None):\\n        self.msg = msg\\n        self.errno = errno\\n        self.retcode = retcode\\n        self.archive_p = archive_p\\n\\n    def __str__(self):\\n        p = '%s (errno=%s, retcode=%s, archive_p=%s)'\\n        return p % (self.msg, self.errno, self.retcode, self.archive_p)\\n\""}, "return_value": "'utf-8'"}, {"func_args": {"source": "b'from contextlib import contextmanager\\nfrom ctypes import byref, c_longlong, c_size_t, c_void_p\\n\\nfrom .ffi import (\\n    write_disk_new, write_disk_set_options, write_free, write_header,\\n    read_data_block, write_data_block, write_finish_entry, ARCHIVE_EOF\\n)\\nfrom .read import fd_reader, file_reader, memory_reader\\n\\n\\nEXTRACT_OWNER = 0x0001\\nEXTRACT_PERM = 0x0002\\nEXTRACT_TIME = 0x0004\\nEXTRACT_NO_OVERWRITE = 0x0008\\nEXTRACT_UNLINK = 0x0010\\nEXTRACT_ACL = 0x0020\\nEXTRACT_FFLAGS = 0x0040\\nEXTRACT_XATTR = 0x0080\\nEXTRACT_SECURE_SYMLINKS = 0x0100\\nEXTRACT_SECURE_NODOTDOT = 0x0200\\nEXTRACT_NO_AUTODIR = 0x0400\\nEXTRACT_NO_OVERWRITE_NEWER = 0x0800\\nEXTRACT_SPARSE = 0x1000\\nEXTRACT_MAC_METADATA = 0x2000\\nEXTRACT_NO_HFS_COMPRESSION = 0x4000\\nEXTRACT_HFS_COMPRESSION_FORCED = 0x8000\\nEXTRACT_SECURE_NOABSOLUTEPATHS = 0x10000\\nEXTRACT_CLEAR_NOCHANGE_FFLAGS = 0x20000\\n\\n\\n@contextmanager\\ndef new_archive_write_disk(flags):\\n    archive_p = write_disk_new()\\n    write_disk_set_options(archive_p, flags)\\n    try:\\n        yield archive_p\\n    finally:\\n        write_free(archive_p)\\n\\n\\ndef extract_entries(entries, flags=0):\\n    \"\"\"Extracts the given archive entries into the current directory.\\n    \"\"\"\\n    buff, size, offset = c_void_p(), c_size_t(), c_longlong()\\n    buff_p, size_p, offset_p = byref(buff), byref(size), byref(offset)\\n    with new_archive_write_disk(flags) as write_p:\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            read_p = entry._archive_p\\n            while 1:\\n                r = read_data_block(read_p, buff_p, size_p, offset_p)\\n                if r == ARCHIVE_EOF:\\n                    break\\n                write_data_block(write_p, buff, size, offset)\\n            write_finish_entry(write_p)\\n\\n\\ndef extract_fd(fd, flags=0):\\n    \"\"\"Extracts an archive from a file descriptor into the current directory.\\n    \"\"\"\\n    with fd_reader(fd) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_file(filepath, flags=0):\\n    \"\"\"Extracts an archive from a file into the current directory.\"\"\"\\n    with file_reader(filepath) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_memory(buffer_, flags=0):\\n    \"\"\"Extracts an archive from memory into the current directory.\"\"\"\\n    with memory_reader(buffer_) as archive:\\n        extract_entries(archive, flags)\\n'"}, "return_value": "'utf-8'"}, {"func_args": {"source": "b'from ctypes import (\\n    c_char_p, c_int, c_uint, c_long, c_longlong, c_size_t, c_int64,\\n    c_void_p, c_wchar_p, CFUNCTYPE, POINTER,\\n)\\n\\ntry:\\n    from ctypes import c_ssize_t\\nexcept ImportError:\\n    from ctypes import c_longlong as c_ssize_t\\n\\nimport ctypes\\nfrom ctypes.util import find_library\\nimport logging\\nimport mmap\\nimport os\\nimport sysconfig\\n\\nfrom .exception import ArchiveError\\n\\n\\nlogger = logging.getLogger(\\'libarchive\\')\\n\\npage_size = mmap.PAGESIZE\\n\\nlibarchive_path = os.environ.get(\\'LIBARCHIVE\\') or find_library(\\'archive\\')\\nlibarchive = ctypes.cdll.LoadLibrary(libarchive_path)\\n\\n\\n# Constants\\n\\nARCHIVE_EOF = 1       # Found end of archive.\\nARCHIVE_OK = 0        # Operation was successful.\\nARCHIVE_RETRY = -10   # Retry might succeed.\\nARCHIVE_WARN = -20    # Partial success.\\nARCHIVE_FAILED = -25  # Current operation cannot complete.\\nARCHIVE_FATAL = -30   # No more operations are possible.\\nREGULAR_FILE = 0o100000\\nDEFAULT_UNIX_PERMISSION = 0o664\\n\\n\\n# Callback types\\n\\nWRITE_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p), c_size_t\\n)\\nREAD_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p)\\n)\\nSEEK_CALLBACK = CFUNCTYPE(\\n    c_longlong, c_void_p, c_void_p, c_longlong, c_int\\n)\\nOPEN_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\nCLOSE_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\n\\nNO_OPEN_CB = ctypes.cast(None, OPEN_CALLBACK)\\nNO_CLOSE_CB = ctypes.cast(None, CLOSE_CALLBACK)\\n\\n\\n# Type aliases, for readability\\n\\nc_archive_p = c_void_p\\nc_archive_entry_p = c_void_p\\n\\nif sysconfig.get_config_var(\\'SIZEOF_TIME_T\\') == 8:\\n    c_time_t = c_int64\\nelse:\\n    c_time_t = c_long\\n\\n\\n# Helper functions\\n\\ndef _error_string(archive_p):\\n    msg = error_string(archive_p)\\n    if msg is None:\\n        return\\n    try:\\n        return msg.decode(\\'ascii\\')\\n    except UnicodeDecodeError:\\n        return msg\\n\\n\\ndef archive_error(archive_p, retcode):\\n    msg = _error_string(archive_p)\\n    return ArchiveError(msg, errno(archive_p), retcode, archive_p)\\n\\n\\ndef check_null(ret, func, args):\\n    if ret is None:\\n        raise ArchiveError(func.__name__+\\' returned NULL\\')\\n    return ret\\n\\n\\ndef check_int(retcode, func, args):\\n    if retcode >= 0:\\n        return retcode\\n    elif retcode == ARCHIVE_WARN:\\n        logger.warning(_error_string(args[0]))\\n        return retcode\\n    else:\\n        raise archive_error(args[0], retcode)\\n\\n\\ndef ffi(name, argtypes, restype, errcheck=None):\\n    f = getattr(libarchive, \\'archive_\\'+name)\\n    f.argtypes = argtypes\\n    f.restype = restype\\n    if errcheck:\\n        f.errcheck = errcheck\\n    globals()[name] = f\\n    return f\\n\\n\\ndef get_read_format_function(format_name):\\n    function_name = \\'read_support_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read format %r is not available\\' % format_name)\\n\\n\\ndef get_read_filter_function(filter_name):\\n    function_name = \\'read_support_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read filter %r is not available\\' % filter_name)\\n\\n\\ndef get_write_format_function(format_name):\\n    function_name = \\'write_set_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write format %r is not available\\' % format_name)\\n\\n\\ndef get_write_filter_function(filter_name):\\n    function_name = \\'write_add_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write filter %r is not available\\' % filter_name)\\n\\n\\n# FFI declarations\\n\\n# library version\\nversion_number = ffi(\\'version_number\\', [], c_int, check_int)\\n\\n# archive_util\\n\\nerrno = ffi(\\'errno\\', [c_archive_p], c_int)\\nerror_string = ffi(\\'error_string\\', [c_archive_p], c_char_p)\\n\\n# archive_entry\\n\\nffi(\\'entry_new\\', [], c_archive_entry_p, check_null)\\n\\nffi(\\'entry_filetype\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_atime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_birthtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_mtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_ctime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_atime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_birthtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_mtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_ctime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_pathname\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_pathname_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_sourcepath\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_size\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_size_is_set\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_mode\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_strmode\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_symlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_symlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_rdevmajor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_rdevminor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_uid\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_gid\\', [c_archive_entry_p], c_longlong)\\n\\nffi(\\'entry_set_size\\', [c_archive_entry_p, c_longlong], None)\\nffi(\\'entry_set_filetype\\', [c_archive_entry_p, c_uint], None)\\nffi(\\'entry_set_perm\\', [c_archive_entry_p, c_int], None)\\nffi(\\'entry_set_atime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_mtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_ctime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_birthtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\n\\nffi(\\'entry_update_pathname_utf8\\', [c_archive_entry_p, c_char_p], None)\\n\\nffi(\\'entry_clear\\', [c_archive_entry_p], c_archive_entry_p)\\nffi(\\'entry_free\\', [c_archive_entry_p], None)\\n\\n# archive_read\\n\\nffi(\\'read_new\\', [], c_archive_p, check_null)\\n\\nREAD_FORMATS = set((\\n    \\'7zip\\', \\'all\\', \\'ar\\', \\'cab\\', \\'cpio\\', \\'empty\\', \\'iso9660\\', \\'lha\\', \\'mtree\\',\\n    \\'rar\\', \\'raw\\', \\'tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(READ_FORMATS):\\n    try:\\n        get_read_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FORMATS.remove(f_name)\\n\\nREAD_FILTERS = set((\\n    \\'all\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'none\\', \\'rpm\\', \\'uu\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(READ_FILTERS):\\n    try:\\n        get_read_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FILTERS.remove(f_name)\\n\\nffi(\\'read_set_seek_callback\\', [c_archive_p, SEEK_CALLBACK], c_int, check_int)\\n\\nffi(\\'read_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'read_open_fd\\', [c_archive_p, c_int, c_size_t], c_int, check_int)\\nffi(\\'read_open_filename_w\\', [c_archive_p, c_wchar_p, c_size_t],\\n    c_int, check_int)\\nffi(\\'read_open_memory\\', [c_archive_p, c_void_p, c_size_t], c_int, check_int)\\n\\nffi(\\'read_next_header\\', [c_archive_p, POINTER(c_void_p)], c_int, check_int)\\nffi(\\'read_next_header2\\', [c_archive_p, c_void_p], c_int, check_int)\\n\\nffi(\\'read_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_disk\\n\\nffi(\\'read_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'read_disk_set_behavior\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'read_disk_set_standard_lookup\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_disk_open\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'read_disk_open_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'read_disk_descend\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_data\\n\\nffi(\\'read_data_block\\',\\n    [c_archive_p, POINTER(c_void_p), POINTER(c_size_t), POINTER(c_longlong)],\\n    c_int, check_int)\\nffi(\\'read_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'read_data_skip\\', [c_archive_p], c_int, check_int)\\n\\n# archive_write\\n\\nffi(\\'write_new\\', [], c_archive_p, check_null)\\nffi(\\'write_set_options\\', [c_archive_p, c_char_p], c_int, check_int)\\n\\nffi(\\'write_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'write_disk_set_options\\', [c_archive_p, c_int], c_int, check_int)\\n\\nWRITE_FORMATS = set((\\n    \\'7zip\\', \\'ar_bsd\\', \\'ar_svr4\\', \\'cpio\\', \\'cpio_newc\\', \\'gnutar\\', \\'iso9660\\',\\n    \\'mtree\\', \\'mtree_classic\\', \\'pax\\', \\'pax_restricted\\', \\'shar\\', \\'shar_dump\\',\\n    \\'ustar\\', \\'v7tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(WRITE_FORMATS):\\n    try:\\n        get_write_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FORMATS.remove(f_name)\\n\\nWRITE_FILTERS = set((\\n    \\'b64encode\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'uuencode\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(WRITE_FILTERS):\\n    try:\\n        get_write_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FILTERS.remove(f_name)\\n\\nffi(\\'write_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'write_open_fd\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_open_filename\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'write_open_filename_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'write_open_memory\\',\\n    [c_archive_p, c_void_p, c_size_t, POINTER(c_size_t)],\\n    c_int, check_int)\\n\\nffi(\\'write_get_bytes_in_last_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_get_bytes_per_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_set_bytes_in_last_block\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_set_bytes_per_block\\', [c_archive_p, c_int], c_int, check_int)\\n\\nffi(\\'write_header\\', [c_archive_p, c_void_p], c_int, check_int)\\nffi(\\'write_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'write_data_block\\', [c_archive_p, c_void_p, c_size_t, c_longlong],\\n    c_int, check_int)\\nffi(\\'write_finish_entry\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_fail\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive encryption\\n\\ntry:\\n    ffi(\\'read_add_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\n    ffi(\\'write_set_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\nexcept AttributeError:\\n    logger.info(\\n        f\"the libarchive being used (version {version_number()}, \"\\n        f\"path {libarchive_path}) doesn\\'t support encryption\"\\n    )\\n'"}, "return_value": "'utf-8'"}, {"func_args": {"source": "b'READDISK_RESTORE_ATIME = 0x0001\\nREADDISK_HONOR_NODUMP = 0x0002\\nREADDISK_MAC_COPYFILE = 0x0004\\nREADDISK_NO_TRAVERSE_MOUNTS = 0x0008\\nREADDISK_NO_XATTR = 0x0010\\nREADDISK_NO_ACL = 0x0020\\nREADDISK_NO_FFLAGS = 0x0040\\n'"}, "return_value": "'utf-8'"}, {"func_args": {"source": "b'from contextlib import contextmanager\\nfrom ctypes import cast, c_void_p, POINTER, create_string_buffer\\nfrom os import fstat, stat\\n\\nfrom . import ffi\\nfrom .ffi import (\\n    ARCHIVE_EOF, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK, SEEK_CALLBACK,\\n    NO_OPEN_CB, NO_CLOSE_CB, page_size,\\n)\\nfrom .entry import ArchiveEntry, new_archive_entry\\n\\n\\nclass ArchiveRead:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def __iter__(self):\\n        \"\"\"Iterates through an archive\\'s entries.\\n        \"\"\"\\n        archive_p = self._pointer\\n        read_next_header2 = ffi.read_next_header2\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(archive_p, entry_p)\\n            while 1:\\n                r = read_next_header2(archive_p, entry_p)\\n                if r == ARCHIVE_EOF:\\n                    return\\n                yield entry\\n\\n\\n@contextmanager\\ndef new_archive_read(format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Creates an archive struct suitable for reading from an archive.\\n\\n    Returns a pointer if successful. Raises ArchiveError on error.\\n    \"\"\"\\n    archive_p = ffi.read_new()\\n    try:\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.read_add_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        ffi.get_read_filter_function(filter_name)(archive_p)\\n        ffi.get_read_format_function(format_name)(archive_p)\\n        yield archive_p\\n    finally:\\n        ffi.read_free(archive_p)\\n\\n\\n@contextmanager\\ndef custom_reader(\\n    read_func, format_name=\\'all\\', filter_name=\\'all\\',\\n    open_func=None, seek_func=None, close_func=None,\\n    block_size=page_size, archive_read_class=ArchiveRead, passphrase=None,\\n):\\n    \"\"\"Read an archive using a custom function.\\n    \"\"\"\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if seek_func:\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield archive_read_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_reader(\\n    fd, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file descriptor.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = fstat(fd).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_fd(archive_p, fd, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef file_reader(\\n    path, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = stat(path).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_filename_w(archive_p, path, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef memory_reader(buf, format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Read an archive from memory.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        ffi.read_open_memory(archive_p, cast(buf, c_void_p), len(buf))\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef stream_reader(\\n    stream, format_name=\\'all\\', filter_name=\\'all\\', block_size=page_size,\\n    passphrase=None,\\n):\\n    \"\"\"Read an archive from a stream.\\n\\n    The `stream` object must support the standard `readinto` method.\\n\\n    If `stream.seekable()` returns `True`, then an appropriate seek callback is\\n    passed to libarchive.\\n    \"\"\"\\n    buf = create_string_buffer(block_size)\\n    buf_p = cast(buf, c_void_p)\\n\\n    def read_func(archive_p, context, ptrptr):\\n        # readinto the buffer, returns number of bytes read\\n        length = stream.readinto(buf)\\n        # write the address of the buffer into the pointer\\n        ptrptr = cast(ptrptr, POINTER(c_void_p))\\n        ptrptr[0] = buf_p\\n        # tell libarchive how much data was written into the buffer\\n        return length\\n\\n    def seek_func(archive_p, context, offset, whence):\\n        stream.seek(offset, whence)\\n        # tell libarchive the current position\\n        return stream.tell()\\n\\n    open_cb = NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if stream.seekable():\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield ArchiveRead(archive_p)\\n\\n\\nseekable_stream_reader = stream_reader\\n'"}, "return_value": "'utf-8'"}, {"func_args": {"source": "b'from contextlib import contextmanager\\nfrom ctypes import byref, cast, c_char, c_size_t, c_void_p, POINTER\\nimport warnings\\n\\nfrom . import ffi\\nfrom .entry import ArchiveEntry, new_archive_entry\\nfrom .ffi import (\\n    OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK, NO_OPEN_CB, NO_CLOSE_CB,\\n    REGULAR_FILE, DEFAULT_UNIX_PERMISSION, ARCHIVE_EOF,\\n    page_size, entry_sourcepath, entry_clear, read_disk_new, read_disk_open_w,\\n    read_next_header2, read_disk_descend, read_free, write_header, write_data,\\n    write_finish_entry, entry_set_size, entry_set_filetype, entry_set_perm,\\n    read_disk_set_behavior\\n)\\n\\n\\n@contextmanager\\ndef new_archive_read_disk(path, flags=0, lookup=False):\\n    archive_p = read_disk_new()\\n    read_disk_set_behavior(archive_p, flags)\\n    if lookup:\\n        ffi.read_disk_set_standard_lookup(archive_p)\\n    read_disk_open_w(archive_p, path)\\n    try:\\n        yield archive_p\\n    finally:\\n        read_free(archive_p)\\n\\n\\nclass ArchiveWrite:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def add_entries(self, entries):\\n        \"\"\"Add the given entries to the archive.\\n        \"\"\"\\n        write_p = self._pointer\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            for block in entry.get_blocks():\\n                write_data(write_p, block, len(block))\\n            write_finish_entry(write_p)\\n\\n    def add_files(self, *paths, **kw):\\n        \"\"\"Read the given paths from disk and add them to the archive.\\n\\n        The keyword arguments (`**kw`) are passed to `new_archive_read_disk`.\\n        \"\"\"\\n        write_p = self._pointer\\n\\n        block_size = ffi.write_get_bytes_per_block(write_p)\\n        if block_size <= 0:\\n            block_size = 10240  # pragma: no cover\\n\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(None, entry_p)\\n            for path in paths:\\n                with new_archive_read_disk(path, **kw) as read_p:\\n                    while 1:\\n                        r = read_next_header2(read_p, entry_p)\\n                        if r == ARCHIVE_EOF:\\n                            break\\n                        entry.pathname = entry.pathname.lstrip(\\'/\\')\\n                        read_disk_descend(read_p)\\n                        write_header(write_p, entry_p)\\n                        if entry.isreg:\\n                            with open(entry_sourcepath(entry_p), \\'rb\\') as f:\\n                                while 1:\\n                                    data = f.read(block_size)\\n                                    if not data:\\n                                        break\\n                                    write_data(write_p, data, len(data))\\n                        write_finish_entry(write_p)\\n                        entry_clear(entry_p)\\n\\n    def add_file_from_memory(\\n        self, entry_path, entry_size, entry_data,\\n        filetype=REGULAR_FILE, permission=DEFAULT_UNIX_PERMISSION,\\n        atime=None, mtime=None, ctime=None, birthtime=None,\\n    ):\\n        \"\"\"\"Add file from memory to archive.\\n\\n        :param entry_path: where entry should be places in archive\\n        :type entry_path: str\\n        :param entry_size: entire size of entry in bytes\\n        :type entry_size: int\\n        :param entry_data: content of entry\\n        :type entry_data: bytes or Iterable[bytes]\\n        :param filetype: which type of file: normal, symlink etc.\\n        should entry be created as\\n        :type filetype: octal number\\n        :param permission: with which permission should entry be created\\n        :type permission: octal number\\n        :param atime: Last access time\\n        :type atime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param mtime: Last modified time\\n        :type mtime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param ctime: Creation time\\n        :type ctime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param birthtime: Birth time (for archive formats that support it)\\n        :type birthtime: int seconds or tuple (int seconds, int nanoseconds)\\n        \"\"\"\\n        archive_pointer = self._pointer\\n\\n        if isinstance(entry_data, bytes):\\n            entry_data = (entry_data,)\\n        elif isinstance(entry_data, str):\\n            raise TypeError(\\n                \"entry_data: expected bytes, got %r\" % type(entry_data)\\n            )\\n\\n        with new_archive_entry() as archive_entry_pointer:\\n            archive_entry = ArchiveEntry(None, archive_entry_pointer)\\n\\n            archive_entry.pathname = entry_path\\n            entry_set_size(archive_entry_pointer, entry_size)\\n            entry_set_filetype(archive_entry_pointer, filetype)\\n            entry_set_perm(archive_entry_pointer, permission)\\n\\n            if atime is not None:\\n                if not isinstance(atime, tuple):\\n                    atime = (atime, 0)\\n                archive_entry.set_atime(*atime)\\n            if mtime is not None:\\n                if not isinstance(mtime, tuple):\\n                    mtime = (mtime, 0)\\n                archive_entry.set_mtime(*mtime)\\n            if ctime is not None:\\n                if not isinstance(ctime, tuple):\\n                    ctime = (ctime, 0)\\n                archive_entry.set_ctime(*ctime)\\n            if birthtime is not None:\\n                if not isinstance(birthtime, tuple):\\n                    birthtime = (birthtime, 0)\\n                archive_entry.set_birthtime(*birthtime)\\n            write_header(archive_pointer, archive_entry_pointer)\\n\\n            for chunk in entry_data:\\n                if not chunk:\\n                    break\\n                write_data(archive_pointer, chunk, len(chunk))\\n\\n            write_finish_entry(archive_pointer)\\n            entry_clear(archive_entry_pointer)\\n\\n\\n@contextmanager\\ndef new_archive_write(format_name, filter_name=None, options=\\'\\', passphrase=None):\\n    archive_p = ffi.write_new()\\n    try:\\n        ffi.get_write_format_function(format_name)(archive_p)\\n        if filter_name:\\n            ffi.get_write_filter_function(filter_name)(archive_p)\\n        if passphrase and \\'encryption\\' not in options:\\n            if format_name == \\'zip\\':\\n                warnings.warn(\\n                    \"The default encryption scheme of zip archives is weak. \"\\n                    \"Use `options=\\'encryption=$type\\'` to specify the encryption \"\\n                    \"type you want to use. The supported values are \\'zipcrypt\\' \"\\n                    \"(the weak default), \\'aes128\\' and \\'aes256\\'.\"\\n                )\\n            options += \\',encryption\\' if options else \\'encryption\\'\\n        if options:\\n            if not isinstance(options, bytes):\\n                options = options.encode(\\'utf-8\\')\\n            ffi.write_set_options(archive_p, options)\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.write_set_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        yield archive_p\\n        ffi.write_close(archive_p)\\n        ffi.write_free(archive_p)\\n    except Exception:\\n        ffi.write_fail(archive_p)\\n        ffi.write_free(archive_p)\\n        raise\\n\\n\\n@contextmanager\\ndef custom_writer(\\n    write_func, format_name, filter_name=None,\\n    open_func=None, close_func=None, block_size=page_size,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n\\n    def write_cb_internal(archive_p, context, buffer_, length):\\n        data = cast(buffer_, POINTER(c_char * length))[0]\\n        return write_func(data)\\n\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    write_cb = WRITE_CALLBACK(write_cb_internal)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_set_bytes_in_last_block(archive_p, 1)\\n        ffi.write_set_bytes_per_block(archive_p, block_size)\\n        ffi.write_open(archive_p, None, open_cb, write_cb, close_cb)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_writer(\\n    fd, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_fd(archive_p, fd)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef file_writer(\\n    filepath, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_filename_w(archive_p, filepath)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef memory_writer(\\n    buf, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        used = byref(c_size_t())\\n        buf_p = cast(buf, c_void_p)\\n        ffi.write_open_memory(archive_p, buf_p, len(buf), used)\\n        yield archive_write_class(archive_p)\\n'"}, "return_value": "'utf-8'"}]}, "neuter_encoding_declaration": {"line": 214, "args": [{"func_args": {"source": "'from .entry import ArchiveEntry\\nfrom .exception import ArchiveError\\nfrom .extract import extract_fd, extract_file, extract_memory\\nfrom .read import (\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader\\n)\\nfrom .write import custom_writer, fd_writer, file_writer, memory_writer\\n\\n__all__ = [x.__name__ for x in (\\n    ArchiveEntry,\\n    ArchiveError,\\n    extract_fd, extract_file, extract_memory,\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader,\\n    custom_writer, fd_writer, file_writer, memory_writer\\n)]\\n'"}, "return_value": "'from .entry import ArchiveEntry\\nfrom .exception import ArchiveError\\nfrom .extract import extract_fd, extract_file, extract_memory\\nfrom .read import (\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader\\n)\\nfrom .write import custom_writer, fd_writer, file_writer, memory_writer\\n\\n__all__ = [x.__name__ for x in (\\n    ArchiveEntry,\\n    ArchiveError,\\n    extract_fd, extract_file, extract_memory,\\n    custom_reader, fd_reader, file_reader, memory_reader, stream_reader,\\n    seekable_stream_reader,\\n    custom_writer, fd_writer, file_writer, memory_writer\\n)]\\n'"}, {"func_args": {"source": "'from contextlib import contextmanager\\nfrom ctypes import c_char_p, create_string_buffer\\n\\nfrom . import ffi\\n\\n\\n@contextmanager\\ndef new_archive_entry():\\n    entry_p = ffi.entry_new()\\n    try:\\n        yield entry_p\\n    finally:\\n        ffi.entry_free(entry_p)\\n\\n\\ndef format_time(seconds, nanos):\\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\\n    if nanos:\\n        return float(seconds) + float(nanos) / 1000000000.0\\n    return int(seconds)\\n\\n\\nclass ArchiveEntry:\\n\\n    __slots__ = (\\'_archive_p\\', \\'_entry_p\\')\\n\\n    def __init__(self, archive_p, entry_p):\\n        self._archive_p = archive_p\\n        self._entry_p = entry_p\\n\\n    def __str__(self):\\n        return self.pathname\\n\\n    @property\\n    def filetype(self):\\n        return ffi.entry_filetype(self._entry_p)\\n\\n    @property\\n    def uid(self):\\n        return ffi.entry_uid(self._entry_p)\\n\\n    @property\\n    def gid(self):\\n        return ffi.entry_gid(self._entry_p)\\n\\n    def get_blocks(self, block_size=ffi.page_size):\\n        archive_p = self._archive_p\\n        buf = create_string_buffer(block_size)\\n        read = ffi.read_data\\n        while 1:\\n            r = read(archive_p, buf, block_size)\\n            if r == 0:\\n                break\\n            yield buf.raw[0:r]\\n\\n    @property\\n    def isblk(self):\\n        return self.filetype & 0o170000 == 0o060000\\n\\n    @property\\n    def ischr(self):\\n        return self.filetype & 0o170000 == 0o020000\\n\\n    @property\\n    def isdir(self):\\n        return self.filetype & 0o170000 == 0o040000\\n\\n    @property\\n    def isfifo(self):\\n        return self.filetype & 0o170000 == 0o010000\\n\\n    @property\\n    def islnk(self):\\n        return bool(ffi.entry_hardlink_w(self._entry_p) or\\n                    ffi.entry_hardlink(self._entry_p))\\n\\n    @property\\n    def issym(self):\\n        return self.filetype & 0o170000 == 0o120000\\n\\n    def _linkpath(self):\\n        return (ffi.entry_symlink_w(self._entry_p) or\\n                ffi.entry_hardlink_w(self._entry_p) or\\n                ffi.entry_symlink(self._entry_p) or\\n                ffi.entry_hardlink(self._entry_p))\\n\\n    # aliases to get the same api as tarfile\\n    linkpath = property(_linkpath)\\n    linkname = property(_linkpath)\\n\\n    @property\\n    def isreg(self):\\n        return self.filetype & 0o170000 == 0o100000\\n\\n    @property\\n    def isfile(self):\\n        return self.isreg\\n\\n    @property\\n    def issock(self):\\n        return self.filetype & 0o170000 == 0o140000\\n\\n    @property\\n    def isdev(self):\\n        return self.ischr or self.isblk or self.isfifo or self.issock\\n\\n    @property\\n    def atime(self):\\n        sec_val = ffi.entry_atime(self._entry_p)\\n        nsec_val = ffi.entry_atime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_atime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_atime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def mtime(self):\\n        sec_val = ffi.entry_mtime(self._entry_p)\\n        nsec_val = ffi.entry_mtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_mtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_mtime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def ctime(self):\\n        sec_val = ffi.entry_ctime(self._entry_p)\\n        nsec_val = ffi.entry_ctime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_ctime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_ctime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def birthtime(self):\\n        sec_val = ffi.entry_birthtime(self._entry_p)\\n        nsec_val = ffi.entry_birthtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_birthtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_birthtime(self._entry_p,\\n                                       timestamp_sec, timestamp_nsec)\\n\\n    def _getpathname(self):\\n        return (ffi.entry_pathname_w(self._entry_p) or\\n                ffi.entry_pathname(self._entry_p))\\n\\n    def _setpathname(self, value):\\n        if not isinstance(value, bytes):\\n            value = value.encode(\\'utf8\\')\\n        ffi.entry_update_pathname_utf8(self._entry_p, c_char_p(value))\\n\\n    pathname = property(_getpathname, _setpathname)\\n    # aliases to get the same api as tarfile\\n    path = property(_getpathname, _setpathname)\\n    name = property(_getpathname, _setpathname)\\n\\n    @property\\n    def size(self):\\n        if ffi.entry_size_is_set(self._entry_p):\\n            return ffi.entry_size(self._entry_p)\\n\\n    @property\\n    def mode(self):\\n        return ffi.entry_mode(self._entry_p)\\n\\n    @property\\n    def strmode(self):\\n        # note we strip the mode because archive_entry_strmode\\n        # returns a trailing space: strcpy(bp, \"?rwxrwxrwx \");\\n        return ffi.entry_strmode(self._entry_p).strip()\\n\\n    @property\\n    def rdevmajor(self):\\n        return ffi.entry_rdevmajor(self._entry_p)\\n\\n    @property\\n    def rdevminor(self):\\n        return ffi.entry_rdevminor(self._entry_p)\\n'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import c_char_p, create_string_buffer\\n\\nfrom . import ffi\\n\\n\\n@contextmanager\\ndef new_archive_entry():\\n    entry_p = ffi.entry_new()\\n    try:\\n        yield entry_p\\n    finally:\\n        ffi.entry_free(entry_p)\\n\\n\\ndef format_time(seconds, nanos):\\n    \"\"\" return float of seconds.nanos when nanos set, or seconds when not \"\"\"\\n    if nanos:\\n        return float(seconds) + float(nanos) / 1000000000.0\\n    return int(seconds)\\n\\n\\nclass ArchiveEntry:\\n\\n    __slots__ = (\\'_archive_p\\', \\'_entry_p\\')\\n\\n    def __init__(self, archive_p, entry_p):\\n        self._archive_p = archive_p\\n        self._entry_p = entry_p\\n\\n    def __str__(self):\\n        return self.pathname\\n\\n    @property\\n    def filetype(self):\\n        return ffi.entry_filetype(self._entry_p)\\n\\n    @property\\n    def uid(self):\\n        return ffi.entry_uid(self._entry_p)\\n\\n    @property\\n    def gid(self):\\n        return ffi.entry_gid(self._entry_p)\\n\\n    def get_blocks(self, block_size=ffi.page_size):\\n        archive_p = self._archive_p\\n        buf = create_string_buffer(block_size)\\n        read = ffi.read_data\\n        while 1:\\n            r = read(archive_p, buf, block_size)\\n            if r == 0:\\n                break\\n            yield buf.raw[0:r]\\n\\n    @property\\n    def isblk(self):\\n        return self.filetype & 0o170000 == 0o060000\\n\\n    @property\\n    def ischr(self):\\n        return self.filetype & 0o170000 == 0o020000\\n\\n    @property\\n    def isdir(self):\\n        return self.filetype & 0o170000 == 0o040000\\n\\n    @property\\n    def isfifo(self):\\n        return self.filetype & 0o170000 == 0o010000\\n\\n    @property\\n    def islnk(self):\\n        return bool(ffi.entry_hardlink_w(self._entry_p) or\\n                    ffi.entry_hardlink(self._entry_p))\\n\\n    @property\\n    def issym(self):\\n        return self.filetype & 0o170000 == 0o120000\\n\\n    def _linkpath(self):\\n        return (ffi.entry_symlink_w(self._entry_p) or\\n                ffi.entry_hardlink_w(self._entry_p) or\\n                ffi.entry_symlink(self._entry_p) or\\n                ffi.entry_hardlink(self._entry_p))\\n\\n    # aliases to get the same api as tarfile\\n    linkpath = property(_linkpath)\\n    linkname = property(_linkpath)\\n\\n    @property\\n    def isreg(self):\\n        return self.filetype & 0o170000 == 0o100000\\n\\n    @property\\n    def isfile(self):\\n        return self.isreg\\n\\n    @property\\n    def issock(self):\\n        return self.filetype & 0o170000 == 0o140000\\n\\n    @property\\n    def isdev(self):\\n        return self.ischr or self.isblk or self.isfifo or self.issock\\n\\n    @property\\n    def atime(self):\\n        sec_val = ffi.entry_atime(self._entry_p)\\n        nsec_val = ffi.entry_atime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_atime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_atime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def mtime(self):\\n        sec_val = ffi.entry_mtime(self._entry_p)\\n        nsec_val = ffi.entry_mtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_mtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_mtime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def ctime(self):\\n        sec_val = ffi.entry_ctime(self._entry_p)\\n        nsec_val = ffi.entry_ctime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_ctime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_ctime(self._entry_p,\\n                                   timestamp_sec, timestamp_nsec)\\n\\n    @property\\n    def birthtime(self):\\n        sec_val = ffi.entry_birthtime(self._entry_p)\\n        nsec_val = ffi.entry_birthtime_nsec(self._entry_p)\\n        return format_time(sec_val, nsec_val)\\n\\n    def set_birthtime(self, timestamp_sec, timestamp_nsec):\\n        return ffi.entry_set_birthtime(self._entry_p,\\n                                       timestamp_sec, timestamp_nsec)\\n\\n    def _getpathname(self):\\n        return (ffi.entry_pathname_w(self._entry_p) or\\n                ffi.entry_pathname(self._entry_p))\\n\\n    def _setpathname(self, value):\\n        if not isinstance(value, bytes):\\n            value = value.encode(\\'utf8\\')\\n        ffi.entry_update_pathname_utf8(self._entry_p, c_char_p(value))\\n\\n    pathname = property(_getpathname, _setpathname)\\n    # aliases to get the same api as tarfile\\n    path = property(_getpathname, _setpathname)\\n    name = property(_getpathname, _setpathname)\\n\\n    @property\\n    def size(self):\\n        if ffi.entry_size_is_set(self._entry_p):\\n            return ffi.entry_size(self._entry_p)\\n\\n    @property\\n    def mode(self):\\n        return ffi.entry_mode(self._entry_p)\\n\\n    @property\\n    def strmode(self):\\n        # note we strip the mode because archive_entry_strmode\\n        # returns a trailing space: strcpy(bp, \"?rwxrwxrwx \");\\n        return ffi.entry_strmode(self._entry_p).strip()\\n\\n    @property\\n    def rdevmajor(self):\\n        return ffi.entry_rdevmajor(self._entry_p)\\n\\n    @property\\n    def rdevminor(self):\\n        return ffi.entry_rdevminor(self._entry_p)\\n'"}, {"func_args": {"source": "\"\\nclass ArchiveError(Exception):\\n\\n    def __init__(self, msg, errno=None, retcode=None, archive_p=None):\\n        self.msg = msg\\n        self.errno = errno\\n        self.retcode = retcode\\n        self.archive_p = archive_p\\n\\n    def __str__(self):\\n        p = '%s (errno=%s, retcode=%s, archive_p=%s)'\\n        return p % (self.msg, self.errno, self.retcode, self.archive_p)\\n\""}, "return_value": "\"\\nclass ArchiveError(Exception):\\n\\n    def __init__(self, msg, errno=None, retcode=None, archive_p=None):\\n        self.msg = msg\\n        self.errno = errno\\n        self.retcode = retcode\\n        self.archive_p = archive_p\\n\\n    def __str__(self):\\n        p = '%s (errno=%s, retcode=%s, archive_p=%s)'\\n        return p % (self.msg, self.errno, self.retcode, self.archive_p)\\n\""}, {"func_args": {"source": "'from contextlib import contextmanager\\nfrom ctypes import byref, c_longlong, c_size_t, c_void_p\\n\\nfrom .ffi import (\\n    write_disk_new, write_disk_set_options, write_free, write_header,\\n    read_data_block, write_data_block, write_finish_entry, ARCHIVE_EOF\\n)\\nfrom .read import fd_reader, file_reader, memory_reader\\n\\n\\nEXTRACT_OWNER = 0x0001\\nEXTRACT_PERM = 0x0002\\nEXTRACT_TIME = 0x0004\\nEXTRACT_NO_OVERWRITE = 0x0008\\nEXTRACT_UNLINK = 0x0010\\nEXTRACT_ACL = 0x0020\\nEXTRACT_FFLAGS = 0x0040\\nEXTRACT_XATTR = 0x0080\\nEXTRACT_SECURE_SYMLINKS = 0x0100\\nEXTRACT_SECURE_NODOTDOT = 0x0200\\nEXTRACT_NO_AUTODIR = 0x0400\\nEXTRACT_NO_OVERWRITE_NEWER = 0x0800\\nEXTRACT_SPARSE = 0x1000\\nEXTRACT_MAC_METADATA = 0x2000\\nEXTRACT_NO_HFS_COMPRESSION = 0x4000\\nEXTRACT_HFS_COMPRESSION_FORCED = 0x8000\\nEXTRACT_SECURE_NOABSOLUTEPATHS = 0x10000\\nEXTRACT_CLEAR_NOCHANGE_FFLAGS = 0x20000\\n\\n\\n@contextmanager\\ndef new_archive_write_disk(flags):\\n    archive_p = write_disk_new()\\n    write_disk_set_options(archive_p, flags)\\n    try:\\n        yield archive_p\\n    finally:\\n        write_free(archive_p)\\n\\n\\ndef extract_entries(entries, flags=0):\\n    \"\"\"Extracts the given archive entries into the current directory.\\n    \"\"\"\\n    buff, size, offset = c_void_p(), c_size_t(), c_longlong()\\n    buff_p, size_p, offset_p = byref(buff), byref(size), byref(offset)\\n    with new_archive_write_disk(flags) as write_p:\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            read_p = entry._archive_p\\n            while 1:\\n                r = read_data_block(read_p, buff_p, size_p, offset_p)\\n                if r == ARCHIVE_EOF:\\n                    break\\n                write_data_block(write_p, buff, size, offset)\\n            write_finish_entry(write_p)\\n\\n\\ndef extract_fd(fd, flags=0):\\n    \"\"\"Extracts an archive from a file descriptor into the current directory.\\n    \"\"\"\\n    with fd_reader(fd) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_file(filepath, flags=0):\\n    \"\"\"Extracts an archive from a file into the current directory.\"\"\"\\n    with file_reader(filepath) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_memory(buffer_, flags=0):\\n    \"\"\"Extracts an archive from memory into the current directory.\"\"\"\\n    with memory_reader(buffer_) as archive:\\n        extract_entries(archive, flags)\\n'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import byref, c_longlong, c_size_t, c_void_p\\n\\nfrom .ffi import (\\n    write_disk_new, write_disk_set_options, write_free, write_header,\\n    read_data_block, write_data_block, write_finish_entry, ARCHIVE_EOF\\n)\\nfrom .read import fd_reader, file_reader, memory_reader\\n\\n\\nEXTRACT_OWNER = 0x0001\\nEXTRACT_PERM = 0x0002\\nEXTRACT_TIME = 0x0004\\nEXTRACT_NO_OVERWRITE = 0x0008\\nEXTRACT_UNLINK = 0x0010\\nEXTRACT_ACL = 0x0020\\nEXTRACT_FFLAGS = 0x0040\\nEXTRACT_XATTR = 0x0080\\nEXTRACT_SECURE_SYMLINKS = 0x0100\\nEXTRACT_SECURE_NODOTDOT = 0x0200\\nEXTRACT_NO_AUTODIR = 0x0400\\nEXTRACT_NO_OVERWRITE_NEWER = 0x0800\\nEXTRACT_SPARSE = 0x1000\\nEXTRACT_MAC_METADATA = 0x2000\\nEXTRACT_NO_HFS_COMPRESSION = 0x4000\\nEXTRACT_HFS_COMPRESSION_FORCED = 0x8000\\nEXTRACT_SECURE_NOABSOLUTEPATHS = 0x10000\\nEXTRACT_CLEAR_NOCHANGE_FFLAGS = 0x20000\\n\\n\\n@contextmanager\\ndef new_archive_write_disk(flags):\\n    archive_p = write_disk_new()\\n    write_disk_set_options(archive_p, flags)\\n    try:\\n        yield archive_p\\n    finally:\\n        write_free(archive_p)\\n\\n\\ndef extract_entries(entries, flags=0):\\n    \"\"\"Extracts the given archive entries into the current directory.\\n    \"\"\"\\n    buff, size, offset = c_void_p(), c_size_t(), c_longlong()\\n    buff_p, size_p, offset_p = byref(buff), byref(size), byref(offset)\\n    with new_archive_write_disk(flags) as write_p:\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            read_p = entry._archive_p\\n            while 1:\\n                r = read_data_block(read_p, buff_p, size_p, offset_p)\\n                if r == ARCHIVE_EOF:\\n                    break\\n                write_data_block(write_p, buff, size, offset)\\n            write_finish_entry(write_p)\\n\\n\\ndef extract_fd(fd, flags=0):\\n    \"\"\"Extracts an archive from a file descriptor into the current directory.\\n    \"\"\"\\n    with fd_reader(fd) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_file(filepath, flags=0):\\n    \"\"\"Extracts an archive from a file into the current directory.\"\"\"\\n    with file_reader(filepath) as archive:\\n        extract_entries(archive, flags)\\n\\n\\ndef extract_memory(buffer_, flags=0):\\n    \"\"\"Extracts an archive from memory into the current directory.\"\"\"\\n    with memory_reader(buffer_) as archive:\\n        extract_entries(archive, flags)\\n'"}, {"func_args": {"source": "'from ctypes import (\\n    c_char_p, c_int, c_uint, c_long, c_longlong, c_size_t, c_int64,\\n    c_void_p, c_wchar_p, CFUNCTYPE, POINTER,\\n)\\n\\ntry:\\n    from ctypes import c_ssize_t\\nexcept ImportError:\\n    from ctypes import c_longlong as c_ssize_t\\n\\nimport ctypes\\nfrom ctypes.util import find_library\\nimport logging\\nimport mmap\\nimport os\\nimport sysconfig\\n\\nfrom .exception import ArchiveError\\n\\n\\nlogger = logging.getLogger(\\'libarchive\\')\\n\\npage_size = mmap.PAGESIZE\\n\\nlibarchive_path = os.environ.get(\\'LIBARCHIVE\\') or find_library(\\'archive\\')\\nlibarchive = ctypes.cdll.LoadLibrary(libarchive_path)\\n\\n\\n# Constants\\n\\nARCHIVE_EOF = 1       # Found end of archive.\\nARCHIVE_OK = 0        # Operation was successful.\\nARCHIVE_RETRY = -10   # Retry might succeed.\\nARCHIVE_WARN = -20    # Partial success.\\nARCHIVE_FAILED = -25  # Current operation cannot complete.\\nARCHIVE_FATAL = -30   # No more operations are possible.\\nREGULAR_FILE = 0o100000\\nDEFAULT_UNIX_PERMISSION = 0o664\\n\\n\\n# Callback types\\n\\nWRITE_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p), c_size_t\\n)\\nREAD_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p)\\n)\\nSEEK_CALLBACK = CFUNCTYPE(\\n    c_longlong, c_void_p, c_void_p, c_longlong, c_int\\n)\\nOPEN_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\nCLOSE_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\n\\nNO_OPEN_CB = ctypes.cast(None, OPEN_CALLBACK)\\nNO_CLOSE_CB = ctypes.cast(None, CLOSE_CALLBACK)\\n\\n\\n# Type aliases, for readability\\n\\nc_archive_p = c_void_p\\nc_archive_entry_p = c_void_p\\n\\nif sysconfig.get_config_var(\\'SIZEOF_TIME_T\\') == 8:\\n    c_time_t = c_int64\\nelse:\\n    c_time_t = c_long\\n\\n\\n# Helper functions\\n\\ndef _error_string(archive_p):\\n    msg = error_string(archive_p)\\n    if msg is None:\\n        return\\n    try:\\n        return msg.decode(\\'ascii\\')\\n    except UnicodeDecodeError:\\n        return msg\\n\\n\\ndef archive_error(archive_p, retcode):\\n    msg = _error_string(archive_p)\\n    return ArchiveError(msg, errno(archive_p), retcode, archive_p)\\n\\n\\ndef check_null(ret, func, args):\\n    if ret is None:\\n        raise ArchiveError(func.__name__+\\' returned NULL\\')\\n    return ret\\n\\n\\ndef check_int(retcode, func, args):\\n    if retcode >= 0:\\n        return retcode\\n    elif retcode == ARCHIVE_WARN:\\n        logger.warning(_error_string(args[0]))\\n        return retcode\\n    else:\\n        raise archive_error(args[0], retcode)\\n\\n\\ndef ffi(name, argtypes, restype, errcheck=None):\\n    f = getattr(libarchive, \\'archive_\\'+name)\\n    f.argtypes = argtypes\\n    f.restype = restype\\n    if errcheck:\\n        f.errcheck = errcheck\\n    globals()[name] = f\\n    return f\\n\\n\\ndef get_read_format_function(format_name):\\n    function_name = \\'read_support_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read format %r is not available\\' % format_name)\\n\\n\\ndef get_read_filter_function(filter_name):\\n    function_name = \\'read_support_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read filter %r is not available\\' % filter_name)\\n\\n\\ndef get_write_format_function(format_name):\\n    function_name = \\'write_set_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write format %r is not available\\' % format_name)\\n\\n\\ndef get_write_filter_function(filter_name):\\n    function_name = \\'write_add_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write filter %r is not available\\' % filter_name)\\n\\n\\n# FFI declarations\\n\\n# library version\\nversion_number = ffi(\\'version_number\\', [], c_int, check_int)\\n\\n# archive_util\\n\\nerrno = ffi(\\'errno\\', [c_archive_p], c_int)\\nerror_string = ffi(\\'error_string\\', [c_archive_p], c_char_p)\\n\\n# archive_entry\\n\\nffi(\\'entry_new\\', [], c_archive_entry_p, check_null)\\n\\nffi(\\'entry_filetype\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_atime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_birthtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_mtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_ctime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_atime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_birthtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_mtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_ctime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_pathname\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_pathname_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_sourcepath\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_size\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_size_is_set\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_mode\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_strmode\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_symlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_symlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_rdevmajor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_rdevminor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_uid\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_gid\\', [c_archive_entry_p], c_longlong)\\n\\nffi(\\'entry_set_size\\', [c_archive_entry_p, c_longlong], None)\\nffi(\\'entry_set_filetype\\', [c_archive_entry_p, c_uint], None)\\nffi(\\'entry_set_perm\\', [c_archive_entry_p, c_int], None)\\nffi(\\'entry_set_atime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_mtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_ctime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_birthtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\n\\nffi(\\'entry_update_pathname_utf8\\', [c_archive_entry_p, c_char_p], None)\\n\\nffi(\\'entry_clear\\', [c_archive_entry_p], c_archive_entry_p)\\nffi(\\'entry_free\\', [c_archive_entry_p], None)\\n\\n# archive_read\\n\\nffi(\\'read_new\\', [], c_archive_p, check_null)\\n\\nREAD_FORMATS = set((\\n    \\'7zip\\', \\'all\\', \\'ar\\', \\'cab\\', \\'cpio\\', \\'empty\\', \\'iso9660\\', \\'lha\\', \\'mtree\\',\\n    \\'rar\\', \\'raw\\', \\'tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(READ_FORMATS):\\n    try:\\n        get_read_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FORMATS.remove(f_name)\\n\\nREAD_FILTERS = set((\\n    \\'all\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'none\\', \\'rpm\\', \\'uu\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(READ_FILTERS):\\n    try:\\n        get_read_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FILTERS.remove(f_name)\\n\\nffi(\\'read_set_seek_callback\\', [c_archive_p, SEEK_CALLBACK], c_int, check_int)\\n\\nffi(\\'read_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'read_open_fd\\', [c_archive_p, c_int, c_size_t], c_int, check_int)\\nffi(\\'read_open_filename_w\\', [c_archive_p, c_wchar_p, c_size_t],\\n    c_int, check_int)\\nffi(\\'read_open_memory\\', [c_archive_p, c_void_p, c_size_t], c_int, check_int)\\n\\nffi(\\'read_next_header\\', [c_archive_p, POINTER(c_void_p)], c_int, check_int)\\nffi(\\'read_next_header2\\', [c_archive_p, c_void_p], c_int, check_int)\\n\\nffi(\\'read_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_disk\\n\\nffi(\\'read_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'read_disk_set_behavior\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'read_disk_set_standard_lookup\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_disk_open\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'read_disk_open_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'read_disk_descend\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_data\\n\\nffi(\\'read_data_block\\',\\n    [c_archive_p, POINTER(c_void_p), POINTER(c_size_t), POINTER(c_longlong)],\\n    c_int, check_int)\\nffi(\\'read_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'read_data_skip\\', [c_archive_p], c_int, check_int)\\n\\n# archive_write\\n\\nffi(\\'write_new\\', [], c_archive_p, check_null)\\nffi(\\'write_set_options\\', [c_archive_p, c_char_p], c_int, check_int)\\n\\nffi(\\'write_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'write_disk_set_options\\', [c_archive_p, c_int], c_int, check_int)\\n\\nWRITE_FORMATS = set((\\n    \\'7zip\\', \\'ar_bsd\\', \\'ar_svr4\\', \\'cpio\\', \\'cpio_newc\\', \\'gnutar\\', \\'iso9660\\',\\n    \\'mtree\\', \\'mtree_classic\\', \\'pax\\', \\'pax_restricted\\', \\'shar\\', \\'shar_dump\\',\\n    \\'ustar\\', \\'v7tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(WRITE_FORMATS):\\n    try:\\n        get_write_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FORMATS.remove(f_name)\\n\\nWRITE_FILTERS = set((\\n    \\'b64encode\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'uuencode\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(WRITE_FILTERS):\\n    try:\\n        get_write_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FILTERS.remove(f_name)\\n\\nffi(\\'write_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'write_open_fd\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_open_filename\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'write_open_filename_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'write_open_memory\\',\\n    [c_archive_p, c_void_p, c_size_t, POINTER(c_size_t)],\\n    c_int, check_int)\\n\\nffi(\\'write_get_bytes_in_last_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_get_bytes_per_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_set_bytes_in_last_block\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_set_bytes_per_block\\', [c_archive_p, c_int], c_int, check_int)\\n\\nffi(\\'write_header\\', [c_archive_p, c_void_p], c_int, check_int)\\nffi(\\'write_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'write_data_block\\', [c_archive_p, c_void_p, c_size_t, c_longlong],\\n    c_int, check_int)\\nffi(\\'write_finish_entry\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_fail\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive encryption\\n\\ntry:\\n    ffi(\\'read_add_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\n    ffi(\\'write_set_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\nexcept AttributeError:\\n    logger.info(\\n        f\"the libarchive being used (version {version_number()}, \"\\n        f\"path {libarchive_path}) doesn\\'t support encryption\"\\n    )\\n'"}, "return_value": "'from ctypes import (\\n    c_char_p, c_int, c_uint, c_long, c_longlong, c_size_t, c_int64,\\n    c_void_p, c_wchar_p, CFUNCTYPE, POINTER,\\n)\\n\\ntry:\\n    from ctypes import c_ssize_t\\nexcept ImportError:\\n    from ctypes import c_longlong as c_ssize_t\\n\\nimport ctypes\\nfrom ctypes.util import find_library\\nimport logging\\nimport mmap\\nimport os\\nimport sysconfig\\n\\nfrom .exception import ArchiveError\\n\\n\\nlogger = logging.getLogger(\\'libarchive\\')\\n\\npage_size = mmap.PAGESIZE\\n\\nlibarchive_path = os.environ.get(\\'LIBARCHIVE\\') or find_library(\\'archive\\')\\nlibarchive = ctypes.cdll.LoadLibrary(libarchive_path)\\n\\n\\n# Constants\\n\\nARCHIVE_EOF = 1       # Found end of archive.\\nARCHIVE_OK = 0        # Operation was successful.\\nARCHIVE_RETRY = -10   # Retry might succeed.\\nARCHIVE_WARN = -20    # Partial success.\\nARCHIVE_FAILED = -25  # Current operation cannot complete.\\nARCHIVE_FATAL = -30   # No more operations are possible.\\nREGULAR_FILE = 0o100000\\nDEFAULT_UNIX_PERMISSION = 0o664\\n\\n\\n# Callback types\\n\\nWRITE_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p), c_size_t\\n)\\nREAD_CALLBACK = CFUNCTYPE(\\n    c_ssize_t, c_void_p, c_void_p, POINTER(c_void_p)\\n)\\nSEEK_CALLBACK = CFUNCTYPE(\\n    c_longlong, c_void_p, c_void_p, c_longlong, c_int\\n)\\nOPEN_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\nCLOSE_CALLBACK = CFUNCTYPE(c_int, c_void_p, c_void_p)\\n\\nNO_OPEN_CB = ctypes.cast(None, OPEN_CALLBACK)\\nNO_CLOSE_CB = ctypes.cast(None, CLOSE_CALLBACK)\\n\\n\\n# Type aliases, for readability\\n\\nc_archive_p = c_void_p\\nc_archive_entry_p = c_void_p\\n\\nif sysconfig.get_config_var(\\'SIZEOF_TIME_T\\') == 8:\\n    c_time_t = c_int64\\nelse:\\n    c_time_t = c_long\\n\\n\\n# Helper functions\\n\\ndef _error_string(archive_p):\\n    msg = error_string(archive_p)\\n    if msg is None:\\n        return\\n    try:\\n        return msg.decode(\\'ascii\\')\\n    except UnicodeDecodeError:\\n        return msg\\n\\n\\ndef archive_error(archive_p, retcode):\\n    msg = _error_string(archive_p)\\n    return ArchiveError(msg, errno(archive_p), retcode, archive_p)\\n\\n\\ndef check_null(ret, func, args):\\n    if ret is None:\\n        raise ArchiveError(func.__name__+\\' returned NULL\\')\\n    return ret\\n\\n\\ndef check_int(retcode, func, args):\\n    if retcode >= 0:\\n        return retcode\\n    elif retcode == ARCHIVE_WARN:\\n        logger.warning(_error_string(args[0]))\\n        return retcode\\n    else:\\n        raise archive_error(args[0], retcode)\\n\\n\\ndef ffi(name, argtypes, restype, errcheck=None):\\n    f = getattr(libarchive, \\'archive_\\'+name)\\n    f.argtypes = argtypes\\n    f.restype = restype\\n    if errcheck:\\n        f.errcheck = errcheck\\n    globals()[name] = f\\n    return f\\n\\n\\ndef get_read_format_function(format_name):\\n    function_name = \\'read_support_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read format %r is not available\\' % format_name)\\n\\n\\ndef get_read_filter_function(filter_name):\\n    function_name = \\'read_support_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the read filter %r is not available\\' % filter_name)\\n\\n\\ndef get_write_format_function(format_name):\\n    function_name = \\'write_set_format_\\' + format_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write format %r is not available\\' % format_name)\\n\\n\\ndef get_write_filter_function(filter_name):\\n    function_name = \\'write_add_filter_\\' + filter_name\\n    func = globals().get(function_name)\\n    if func:\\n        return func\\n    try:\\n        return ffi(function_name, [c_archive_p], c_int, check_int)\\n    except AttributeError:\\n        raise ValueError(\\'the write filter %r is not available\\' % filter_name)\\n\\n\\n# FFI declarations\\n\\n# library version\\nversion_number = ffi(\\'version_number\\', [], c_int, check_int)\\n\\n# archive_util\\n\\nerrno = ffi(\\'errno\\', [c_archive_p], c_int)\\nerror_string = ffi(\\'error_string\\', [c_archive_p], c_char_p)\\n\\n# archive_entry\\n\\nffi(\\'entry_new\\', [], c_archive_entry_p, check_null)\\n\\nffi(\\'entry_filetype\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_atime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_birthtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_mtime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_ctime\\', [c_archive_entry_p], c_time_t)\\nffi(\\'entry_atime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_birthtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_mtime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_ctime_nsec\\', [c_archive_entry_p], c_long)\\nffi(\\'entry_pathname\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_pathname_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_sourcepath\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_size\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_size_is_set\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_mode\\', [c_archive_entry_p], c_int)\\nffi(\\'entry_strmode\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_hardlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_symlink\\', [c_archive_entry_p], c_char_p)\\nffi(\\'entry_symlink_w\\', [c_archive_entry_p], c_wchar_p)\\nffi(\\'entry_rdevmajor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_rdevminor\\', [c_archive_entry_p], c_uint)\\nffi(\\'entry_uid\\', [c_archive_entry_p], c_longlong)\\nffi(\\'entry_gid\\', [c_archive_entry_p], c_longlong)\\n\\nffi(\\'entry_set_size\\', [c_archive_entry_p, c_longlong], None)\\nffi(\\'entry_set_filetype\\', [c_archive_entry_p, c_uint], None)\\nffi(\\'entry_set_perm\\', [c_archive_entry_p, c_int], None)\\nffi(\\'entry_set_atime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_mtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_ctime\\', [c_archive_entry_p, c_time_t, c_long], None)\\nffi(\\'entry_set_birthtime\\', [c_archive_entry_p, c_time_t, c_long], None)\\n\\nffi(\\'entry_update_pathname_utf8\\', [c_archive_entry_p, c_char_p], None)\\n\\nffi(\\'entry_clear\\', [c_archive_entry_p], c_archive_entry_p)\\nffi(\\'entry_free\\', [c_archive_entry_p], None)\\n\\n# archive_read\\n\\nffi(\\'read_new\\', [], c_archive_p, check_null)\\n\\nREAD_FORMATS = set((\\n    \\'7zip\\', \\'all\\', \\'ar\\', \\'cab\\', \\'cpio\\', \\'empty\\', \\'iso9660\\', \\'lha\\', \\'mtree\\',\\n    \\'rar\\', \\'raw\\', \\'tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(READ_FORMATS):\\n    try:\\n        get_read_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FORMATS.remove(f_name)\\n\\nREAD_FILTERS = set((\\n    \\'all\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'none\\', \\'rpm\\', \\'uu\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(READ_FILTERS):\\n    try:\\n        get_read_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        READ_FILTERS.remove(f_name)\\n\\nffi(\\'read_set_seek_callback\\', [c_archive_p, SEEK_CALLBACK], c_int, check_int)\\n\\nffi(\\'read_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'read_open_fd\\', [c_archive_p, c_int, c_size_t], c_int, check_int)\\nffi(\\'read_open_filename_w\\', [c_archive_p, c_wchar_p, c_size_t],\\n    c_int, check_int)\\nffi(\\'read_open_memory\\', [c_archive_p, c_void_p, c_size_t], c_int, check_int)\\n\\nffi(\\'read_next_header\\', [c_archive_p, POINTER(c_void_p)], c_int, check_int)\\nffi(\\'read_next_header2\\', [c_archive_p, c_void_p], c_int, check_int)\\n\\nffi(\\'read_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_disk\\n\\nffi(\\'read_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'read_disk_set_behavior\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'read_disk_set_standard_lookup\\', [c_archive_p], c_int, check_int)\\nffi(\\'read_disk_open\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'read_disk_open_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'read_disk_descend\\', [c_archive_p], c_int, check_int)\\n\\n# archive_read_data\\n\\nffi(\\'read_data_block\\',\\n    [c_archive_p, POINTER(c_void_p), POINTER(c_size_t), POINTER(c_longlong)],\\n    c_int, check_int)\\nffi(\\'read_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'read_data_skip\\', [c_archive_p], c_int, check_int)\\n\\n# archive_write\\n\\nffi(\\'write_new\\', [], c_archive_p, check_null)\\nffi(\\'write_set_options\\', [c_archive_p, c_char_p], c_int, check_int)\\n\\nffi(\\'write_disk_new\\', [], c_archive_p, check_null)\\nffi(\\'write_disk_set_options\\', [c_archive_p, c_int], c_int, check_int)\\n\\nWRITE_FORMATS = set((\\n    \\'7zip\\', \\'ar_bsd\\', \\'ar_svr4\\', \\'cpio\\', \\'cpio_newc\\', \\'gnutar\\', \\'iso9660\\',\\n    \\'mtree\\', \\'mtree_classic\\', \\'pax\\', \\'pax_restricted\\', \\'shar\\', \\'shar_dump\\',\\n    \\'ustar\\', \\'v7tar\\', \\'xar\\', \\'zip\\', \\'warc\\'\\n))\\nfor f_name in list(WRITE_FORMATS):\\n    try:\\n        get_write_format_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FORMATS.remove(f_name)\\n\\nWRITE_FILTERS = set((\\n    \\'b64encode\\', \\'bzip2\\', \\'compress\\', \\'grzip\\', \\'gzip\\', \\'lrzip\\', \\'lzip\\', \\'lzma\\',\\n    \\'lzop\\', \\'uuencode\\', \\'xz\\', \\'lz4\\', \\'zstd\\'\\n))\\nfor f_name in list(WRITE_FILTERS):\\n    try:\\n        get_write_filter_function(f_name)\\n    except ValueError as e:  # pragma: no cover\\n        logger.info(str(e))\\n        WRITE_FILTERS.remove(f_name)\\n\\nffi(\\'write_open\\',\\n    [c_archive_p, c_void_p, OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK],\\n    c_int, check_int)\\nffi(\\'write_open_fd\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_open_filename\\', [c_archive_p, c_char_p], c_int, check_int)\\nffi(\\'write_open_filename_w\\', [c_archive_p, c_wchar_p], c_int, check_int)\\nffi(\\'write_open_memory\\',\\n    [c_archive_p, c_void_p, c_size_t, POINTER(c_size_t)],\\n    c_int, check_int)\\n\\nffi(\\'write_get_bytes_in_last_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_get_bytes_per_block\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_set_bytes_in_last_block\\', [c_archive_p, c_int], c_int, check_int)\\nffi(\\'write_set_bytes_per_block\\', [c_archive_p, c_int], c_int, check_int)\\n\\nffi(\\'write_header\\', [c_archive_p, c_void_p], c_int, check_int)\\nffi(\\'write_data\\', [c_archive_p, c_void_p, c_size_t], c_ssize_t, check_int)\\nffi(\\'write_data_block\\', [c_archive_p, c_void_p, c_size_t, c_longlong],\\n    c_int, check_int)\\nffi(\\'write_finish_entry\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_fail\\', [c_archive_p], c_int, check_int)\\n\\nffi(\\'write_close\\', [c_archive_p], c_int, check_int)\\nffi(\\'write_free\\', [c_archive_p], c_int, check_int)\\n\\n# archive encryption\\n\\ntry:\\n    ffi(\\'read_add_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\n    ffi(\\'write_set_passphrase\\', [c_archive_p, c_char_p], c_int, check_int)\\nexcept AttributeError:\\n    logger.info(\\n        f\"the libarchive being used (version {version_number()}, \"\\n        f\"path {libarchive_path}) doesn\\'t support encryption\"\\n    )\\n'"}, {"func_args": {"source": "'READDISK_RESTORE_ATIME = 0x0001\\nREADDISK_HONOR_NODUMP = 0x0002\\nREADDISK_MAC_COPYFILE = 0x0004\\nREADDISK_NO_TRAVERSE_MOUNTS = 0x0008\\nREADDISK_NO_XATTR = 0x0010\\nREADDISK_NO_ACL = 0x0020\\nREADDISK_NO_FFLAGS = 0x0040\\n'"}, "return_value": "'READDISK_RESTORE_ATIME = 0x0001\\nREADDISK_HONOR_NODUMP = 0x0002\\nREADDISK_MAC_COPYFILE = 0x0004\\nREADDISK_NO_TRAVERSE_MOUNTS = 0x0008\\nREADDISK_NO_XATTR = 0x0010\\nREADDISK_NO_ACL = 0x0020\\nREADDISK_NO_FFLAGS = 0x0040\\n'"}, {"func_args": {"source": "'from contextlib import contextmanager\\nfrom ctypes import cast, c_void_p, POINTER, create_string_buffer\\nfrom os import fstat, stat\\n\\nfrom . import ffi\\nfrom .ffi import (\\n    ARCHIVE_EOF, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK, SEEK_CALLBACK,\\n    NO_OPEN_CB, NO_CLOSE_CB, page_size,\\n)\\nfrom .entry import ArchiveEntry, new_archive_entry\\n\\n\\nclass ArchiveRead:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def __iter__(self):\\n        \"\"\"Iterates through an archive\\'s entries.\\n        \"\"\"\\n        archive_p = self._pointer\\n        read_next_header2 = ffi.read_next_header2\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(archive_p, entry_p)\\n            while 1:\\n                r = read_next_header2(archive_p, entry_p)\\n                if r == ARCHIVE_EOF:\\n                    return\\n                yield entry\\n\\n\\n@contextmanager\\ndef new_archive_read(format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Creates an archive struct suitable for reading from an archive.\\n\\n    Returns a pointer if successful. Raises ArchiveError on error.\\n    \"\"\"\\n    archive_p = ffi.read_new()\\n    try:\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.read_add_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        ffi.get_read_filter_function(filter_name)(archive_p)\\n        ffi.get_read_format_function(format_name)(archive_p)\\n        yield archive_p\\n    finally:\\n        ffi.read_free(archive_p)\\n\\n\\n@contextmanager\\ndef custom_reader(\\n    read_func, format_name=\\'all\\', filter_name=\\'all\\',\\n    open_func=None, seek_func=None, close_func=None,\\n    block_size=page_size, archive_read_class=ArchiveRead, passphrase=None,\\n):\\n    \"\"\"Read an archive using a custom function.\\n    \"\"\"\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if seek_func:\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield archive_read_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_reader(\\n    fd, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file descriptor.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = fstat(fd).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_fd(archive_p, fd, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef file_reader(\\n    path, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = stat(path).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_filename_w(archive_p, path, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef memory_reader(buf, format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Read an archive from memory.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        ffi.read_open_memory(archive_p, cast(buf, c_void_p), len(buf))\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef stream_reader(\\n    stream, format_name=\\'all\\', filter_name=\\'all\\', block_size=page_size,\\n    passphrase=None,\\n):\\n    \"\"\"Read an archive from a stream.\\n\\n    The `stream` object must support the standard `readinto` method.\\n\\n    If `stream.seekable()` returns `True`, then an appropriate seek callback is\\n    passed to libarchive.\\n    \"\"\"\\n    buf = create_string_buffer(block_size)\\n    buf_p = cast(buf, c_void_p)\\n\\n    def read_func(archive_p, context, ptrptr):\\n        # readinto the buffer, returns number of bytes read\\n        length = stream.readinto(buf)\\n        # write the address of the buffer into the pointer\\n        ptrptr = cast(ptrptr, POINTER(c_void_p))\\n        ptrptr[0] = buf_p\\n        # tell libarchive how much data was written into the buffer\\n        return length\\n\\n    def seek_func(archive_p, context, offset, whence):\\n        stream.seek(offset, whence)\\n        # tell libarchive the current position\\n        return stream.tell()\\n\\n    open_cb = NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if stream.seekable():\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield ArchiveRead(archive_p)\\n\\n\\nseekable_stream_reader = stream_reader\\n'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import cast, c_void_p, POINTER, create_string_buffer\\nfrom os import fstat, stat\\n\\nfrom . import ffi\\nfrom .ffi import (\\n    ARCHIVE_EOF, OPEN_CALLBACK, READ_CALLBACK, CLOSE_CALLBACK, SEEK_CALLBACK,\\n    NO_OPEN_CB, NO_CLOSE_CB, page_size,\\n)\\nfrom .entry import ArchiveEntry, new_archive_entry\\n\\n\\nclass ArchiveRead:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def __iter__(self):\\n        \"\"\"Iterates through an archive\\'s entries.\\n        \"\"\"\\n        archive_p = self._pointer\\n        read_next_header2 = ffi.read_next_header2\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(archive_p, entry_p)\\n            while 1:\\n                r = read_next_header2(archive_p, entry_p)\\n                if r == ARCHIVE_EOF:\\n                    return\\n                yield entry\\n\\n\\n@contextmanager\\ndef new_archive_read(format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Creates an archive struct suitable for reading from an archive.\\n\\n    Returns a pointer if successful. Raises ArchiveError on error.\\n    \"\"\"\\n    archive_p = ffi.read_new()\\n    try:\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.read_add_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        ffi.get_read_filter_function(filter_name)(archive_p)\\n        ffi.get_read_format_function(format_name)(archive_p)\\n        yield archive_p\\n    finally:\\n        ffi.read_free(archive_p)\\n\\n\\n@contextmanager\\ndef custom_reader(\\n    read_func, format_name=\\'all\\', filter_name=\\'all\\',\\n    open_func=None, seek_func=None, close_func=None,\\n    block_size=page_size, archive_read_class=ArchiveRead, passphrase=None,\\n):\\n    \"\"\"Read an archive using a custom function.\\n    \"\"\"\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if seek_func:\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield archive_read_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_reader(\\n    fd, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file descriptor.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = fstat(fd).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_fd(archive_p, fd, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef file_reader(\\n    path, format_name=\\'all\\', filter_name=\\'all\\', block_size=4096, passphrase=None,\\n):\\n    \"\"\"Read an archive from a file.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        try:\\n            block_size = stat(path).st_blksize\\n        except (OSError, AttributeError):  # pragma: no cover\\n            pass\\n        ffi.read_open_filename_w(archive_p, path, block_size)\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef memory_reader(buf, format_name=\\'all\\', filter_name=\\'all\\', passphrase=None):\\n    \"\"\"Read an archive from memory.\\n    \"\"\"\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        ffi.read_open_memory(archive_p, cast(buf, c_void_p), len(buf))\\n        yield ArchiveRead(archive_p)\\n\\n\\n@contextmanager\\ndef stream_reader(\\n    stream, format_name=\\'all\\', filter_name=\\'all\\', block_size=page_size,\\n    passphrase=None,\\n):\\n    \"\"\"Read an archive from a stream.\\n\\n    The `stream` object must support the standard `readinto` method.\\n\\n    If `stream.seekable()` returns `True`, then an appropriate seek callback is\\n    passed to libarchive.\\n    \"\"\"\\n    buf = create_string_buffer(block_size)\\n    buf_p = cast(buf, c_void_p)\\n\\n    def read_func(archive_p, context, ptrptr):\\n        # readinto the buffer, returns number of bytes read\\n        length = stream.readinto(buf)\\n        # write the address of the buffer into the pointer\\n        ptrptr = cast(ptrptr, POINTER(c_void_p))\\n        ptrptr[0] = buf_p\\n        # tell libarchive how much data was written into the buffer\\n        return length\\n\\n    def seek_func(archive_p, context, offset, whence):\\n        stream.seek(offset, whence)\\n        # tell libarchive the current position\\n        return stream.tell()\\n\\n    open_cb = NO_OPEN_CB\\n    read_cb = READ_CALLBACK(read_func)\\n    close_cb = NO_CLOSE_CB\\n    seek_cb = SEEK_CALLBACK(seek_func)\\n    with new_archive_read(format_name, filter_name, passphrase) as archive_p:\\n        if stream.seekable():\\n            ffi.read_set_seek_callback(archive_p, seek_cb)\\n        ffi.read_open(archive_p, None, open_cb, read_cb, close_cb)\\n        yield ArchiveRead(archive_p)\\n\\n\\nseekable_stream_reader = stream_reader\\n'"}, {"func_args": {"source": "'from contextlib import contextmanager\\nfrom ctypes import byref, cast, c_char, c_size_t, c_void_p, POINTER\\nimport warnings\\n\\nfrom . import ffi\\nfrom .entry import ArchiveEntry, new_archive_entry\\nfrom .ffi import (\\n    OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK, NO_OPEN_CB, NO_CLOSE_CB,\\n    REGULAR_FILE, DEFAULT_UNIX_PERMISSION, ARCHIVE_EOF,\\n    page_size, entry_sourcepath, entry_clear, read_disk_new, read_disk_open_w,\\n    read_next_header2, read_disk_descend, read_free, write_header, write_data,\\n    write_finish_entry, entry_set_size, entry_set_filetype, entry_set_perm,\\n    read_disk_set_behavior\\n)\\n\\n\\n@contextmanager\\ndef new_archive_read_disk(path, flags=0, lookup=False):\\n    archive_p = read_disk_new()\\n    read_disk_set_behavior(archive_p, flags)\\n    if lookup:\\n        ffi.read_disk_set_standard_lookup(archive_p)\\n    read_disk_open_w(archive_p, path)\\n    try:\\n        yield archive_p\\n    finally:\\n        read_free(archive_p)\\n\\n\\nclass ArchiveWrite:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def add_entries(self, entries):\\n        \"\"\"Add the given entries to the archive.\\n        \"\"\"\\n        write_p = self._pointer\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            for block in entry.get_blocks():\\n                write_data(write_p, block, len(block))\\n            write_finish_entry(write_p)\\n\\n    def add_files(self, *paths, **kw):\\n        \"\"\"Read the given paths from disk and add them to the archive.\\n\\n        The keyword arguments (`**kw`) are passed to `new_archive_read_disk`.\\n        \"\"\"\\n        write_p = self._pointer\\n\\n        block_size = ffi.write_get_bytes_per_block(write_p)\\n        if block_size <= 0:\\n            block_size = 10240  # pragma: no cover\\n\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(None, entry_p)\\n            for path in paths:\\n                with new_archive_read_disk(path, **kw) as read_p:\\n                    while 1:\\n                        r = read_next_header2(read_p, entry_p)\\n                        if r == ARCHIVE_EOF:\\n                            break\\n                        entry.pathname = entry.pathname.lstrip(\\'/\\')\\n                        read_disk_descend(read_p)\\n                        write_header(write_p, entry_p)\\n                        if entry.isreg:\\n                            with open(entry_sourcepath(entry_p), \\'rb\\') as f:\\n                                while 1:\\n                                    data = f.read(block_size)\\n                                    if not data:\\n                                        break\\n                                    write_data(write_p, data, len(data))\\n                        write_finish_entry(write_p)\\n                        entry_clear(entry_p)\\n\\n    def add_file_from_memory(\\n        self, entry_path, entry_size, entry_data,\\n        filetype=REGULAR_FILE, permission=DEFAULT_UNIX_PERMISSION,\\n        atime=None, mtime=None, ctime=None, birthtime=None,\\n    ):\\n        \"\"\"\"Add file from memory to archive.\\n\\n        :param entry_path: where entry should be places in archive\\n        :type entry_path: str\\n        :param entry_size: entire size of entry in bytes\\n        :type entry_size: int\\n        :param entry_data: content of entry\\n        :type entry_data: bytes or Iterable[bytes]\\n        :param filetype: which type of file: normal, symlink etc.\\n        should entry be created as\\n        :type filetype: octal number\\n        :param permission: with which permission should entry be created\\n        :type permission: octal number\\n        :param atime: Last access time\\n        :type atime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param mtime: Last modified time\\n        :type mtime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param ctime: Creation time\\n        :type ctime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param birthtime: Birth time (for archive formats that support it)\\n        :type birthtime: int seconds or tuple (int seconds, int nanoseconds)\\n        \"\"\"\\n        archive_pointer = self._pointer\\n\\n        if isinstance(entry_data, bytes):\\n            entry_data = (entry_data,)\\n        elif isinstance(entry_data, str):\\n            raise TypeError(\\n                \"entry_data: expected bytes, got %r\" % type(entry_data)\\n            )\\n\\n        with new_archive_entry() as archive_entry_pointer:\\n            archive_entry = ArchiveEntry(None, archive_entry_pointer)\\n\\n            archive_entry.pathname = entry_path\\n            entry_set_size(archive_entry_pointer, entry_size)\\n            entry_set_filetype(archive_entry_pointer, filetype)\\n            entry_set_perm(archive_entry_pointer, permission)\\n\\n            if atime is not None:\\n                if not isinstance(atime, tuple):\\n                    atime = (atime, 0)\\n                archive_entry.set_atime(*atime)\\n            if mtime is not None:\\n                if not isinstance(mtime, tuple):\\n                    mtime = (mtime, 0)\\n                archive_entry.set_mtime(*mtime)\\n            if ctime is not None:\\n                if not isinstance(ctime, tuple):\\n                    ctime = (ctime, 0)\\n                archive_entry.set_ctime(*ctime)\\n            if birthtime is not None:\\n                if not isinstance(birthtime, tuple):\\n                    birthtime = (birthtime, 0)\\n                archive_entry.set_birthtime(*birthtime)\\n            write_header(archive_pointer, archive_entry_pointer)\\n\\n            for chunk in entry_data:\\n                if not chunk:\\n                    break\\n                write_data(archive_pointer, chunk, len(chunk))\\n\\n            write_finish_entry(archive_pointer)\\n            entry_clear(archive_entry_pointer)\\n\\n\\n@contextmanager\\ndef new_archive_write(format_name, filter_name=None, options=\\'\\', passphrase=None):\\n    archive_p = ffi.write_new()\\n    try:\\n        ffi.get_write_format_function(format_name)(archive_p)\\n        if filter_name:\\n            ffi.get_write_filter_function(filter_name)(archive_p)\\n        if passphrase and \\'encryption\\' not in options:\\n            if format_name == \\'zip\\':\\n                warnings.warn(\\n                    \"The default encryption scheme of zip archives is weak. \"\\n                    \"Use `options=\\'encryption=$type\\'` to specify the encryption \"\\n                    \"type you want to use. The supported values are \\'zipcrypt\\' \"\\n                    \"(the weak default), \\'aes128\\' and \\'aes256\\'.\"\\n                )\\n            options += \\',encryption\\' if options else \\'encryption\\'\\n        if options:\\n            if not isinstance(options, bytes):\\n                options = options.encode(\\'utf-8\\')\\n            ffi.write_set_options(archive_p, options)\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.write_set_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        yield archive_p\\n        ffi.write_close(archive_p)\\n        ffi.write_free(archive_p)\\n    except Exception:\\n        ffi.write_fail(archive_p)\\n        ffi.write_free(archive_p)\\n        raise\\n\\n\\n@contextmanager\\ndef custom_writer(\\n    write_func, format_name, filter_name=None,\\n    open_func=None, close_func=None, block_size=page_size,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n\\n    def write_cb_internal(archive_p, context, buffer_, length):\\n        data = cast(buffer_, POINTER(c_char * length))[0]\\n        return write_func(data)\\n\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    write_cb = WRITE_CALLBACK(write_cb_internal)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_set_bytes_in_last_block(archive_p, 1)\\n        ffi.write_set_bytes_per_block(archive_p, block_size)\\n        ffi.write_open(archive_p, None, open_cb, write_cb, close_cb)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_writer(\\n    fd, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_fd(archive_p, fd)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef file_writer(\\n    filepath, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_filename_w(archive_p, filepath)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef memory_writer(\\n    buf, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        used = byref(c_size_t())\\n        buf_p = cast(buf, c_void_p)\\n        ffi.write_open_memory(archive_p, buf_p, len(buf), used)\\n        yield archive_write_class(archive_p)\\n'"}, "return_value": "'from contextlib import contextmanager\\nfrom ctypes import byref, cast, c_char, c_size_t, c_void_p, POINTER\\nimport warnings\\n\\nfrom . import ffi\\nfrom .entry import ArchiveEntry, new_archive_entry\\nfrom .ffi import (\\n    OPEN_CALLBACK, WRITE_CALLBACK, CLOSE_CALLBACK, NO_OPEN_CB, NO_CLOSE_CB,\\n    REGULAR_FILE, DEFAULT_UNIX_PERMISSION, ARCHIVE_EOF,\\n    page_size, entry_sourcepath, entry_clear, read_disk_new, read_disk_open_w,\\n    read_next_header2, read_disk_descend, read_free, write_header, write_data,\\n    write_finish_entry, entry_set_size, entry_set_filetype, entry_set_perm,\\n    read_disk_set_behavior\\n)\\n\\n\\n@contextmanager\\ndef new_archive_read_disk(path, flags=0, lookup=False):\\n    archive_p = read_disk_new()\\n    read_disk_set_behavior(archive_p, flags)\\n    if lookup:\\n        ffi.read_disk_set_standard_lookup(archive_p)\\n    read_disk_open_w(archive_p, path)\\n    try:\\n        yield archive_p\\n    finally:\\n        read_free(archive_p)\\n\\n\\nclass ArchiveWrite:\\n\\n    def __init__(self, archive_p):\\n        self._pointer = archive_p\\n\\n    def add_entries(self, entries):\\n        \"\"\"Add the given entries to the archive.\\n        \"\"\"\\n        write_p = self._pointer\\n        for entry in entries:\\n            write_header(write_p, entry._entry_p)\\n            for block in entry.get_blocks():\\n                write_data(write_p, block, len(block))\\n            write_finish_entry(write_p)\\n\\n    def add_files(self, *paths, **kw):\\n        \"\"\"Read the given paths from disk and add them to the archive.\\n\\n        The keyword arguments (`**kw`) are passed to `new_archive_read_disk`.\\n        \"\"\"\\n        write_p = self._pointer\\n\\n        block_size = ffi.write_get_bytes_per_block(write_p)\\n        if block_size <= 0:\\n            block_size = 10240  # pragma: no cover\\n\\n        with new_archive_entry() as entry_p:\\n            entry = ArchiveEntry(None, entry_p)\\n            for path in paths:\\n                with new_archive_read_disk(path, **kw) as read_p:\\n                    while 1:\\n                        r = read_next_header2(read_p, entry_p)\\n                        if r == ARCHIVE_EOF:\\n                            break\\n                        entry.pathname = entry.pathname.lstrip(\\'/\\')\\n                        read_disk_descend(read_p)\\n                        write_header(write_p, entry_p)\\n                        if entry.isreg:\\n                            with open(entry_sourcepath(entry_p), \\'rb\\') as f:\\n                                while 1:\\n                                    data = f.read(block_size)\\n                                    if not data:\\n                                        break\\n                                    write_data(write_p, data, len(data))\\n                        write_finish_entry(write_p)\\n                        entry_clear(entry_p)\\n\\n    def add_file_from_memory(\\n        self, entry_path, entry_size, entry_data,\\n        filetype=REGULAR_FILE, permission=DEFAULT_UNIX_PERMISSION,\\n        atime=None, mtime=None, ctime=None, birthtime=None,\\n    ):\\n        \"\"\"\"Add file from memory to archive.\\n\\n        :param entry_path: where entry should be places in archive\\n        :type entry_path: str\\n        :param entry_size: entire size of entry in bytes\\n        :type entry_size: int\\n        :param entry_data: content of entry\\n        :type entry_data: bytes or Iterable[bytes]\\n        :param filetype: which type of file: normal, symlink etc.\\n        should entry be created as\\n        :type filetype: octal number\\n        :param permission: with which permission should entry be created\\n        :type permission: octal number\\n        :param atime: Last access time\\n        :type atime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param mtime: Last modified time\\n        :type mtime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param ctime: Creation time\\n        :type ctime: int seconds or tuple (int seconds, int nanoseconds)\\n        :param birthtime: Birth time (for archive formats that support it)\\n        :type birthtime: int seconds or tuple (int seconds, int nanoseconds)\\n        \"\"\"\\n        archive_pointer = self._pointer\\n\\n        if isinstance(entry_data, bytes):\\n            entry_data = (entry_data,)\\n        elif isinstance(entry_data, str):\\n            raise TypeError(\\n                \"entry_data: expected bytes, got %r\" % type(entry_data)\\n            )\\n\\n        with new_archive_entry() as archive_entry_pointer:\\n            archive_entry = ArchiveEntry(None, archive_entry_pointer)\\n\\n            archive_entry.pathname = entry_path\\n            entry_set_size(archive_entry_pointer, entry_size)\\n            entry_set_filetype(archive_entry_pointer, filetype)\\n            entry_set_perm(archive_entry_pointer, permission)\\n\\n            if atime is not None:\\n                if not isinstance(atime, tuple):\\n                    atime = (atime, 0)\\n                archive_entry.set_atime(*atime)\\n            if mtime is not None:\\n                if not isinstance(mtime, tuple):\\n                    mtime = (mtime, 0)\\n                archive_entry.set_mtime(*mtime)\\n            if ctime is not None:\\n                if not isinstance(ctime, tuple):\\n                    ctime = (ctime, 0)\\n                archive_entry.set_ctime(*ctime)\\n            if birthtime is not None:\\n                if not isinstance(birthtime, tuple):\\n                    birthtime = (birthtime, 0)\\n                archive_entry.set_birthtime(*birthtime)\\n            write_header(archive_pointer, archive_entry_pointer)\\n\\n            for chunk in entry_data:\\n                if not chunk:\\n                    break\\n                write_data(archive_pointer, chunk, len(chunk))\\n\\n            write_finish_entry(archive_pointer)\\n            entry_clear(archive_entry_pointer)\\n\\n\\n@contextmanager\\ndef new_archive_write(format_name, filter_name=None, options=\\'\\', passphrase=None):\\n    archive_p = ffi.write_new()\\n    try:\\n        ffi.get_write_format_function(format_name)(archive_p)\\n        if filter_name:\\n            ffi.get_write_filter_function(filter_name)(archive_p)\\n        if passphrase and \\'encryption\\' not in options:\\n            if format_name == \\'zip\\':\\n                warnings.warn(\\n                    \"The default encryption scheme of zip archives is weak. \"\\n                    \"Use `options=\\'encryption=$type\\'` to specify the encryption \"\\n                    \"type you want to use. The supported values are \\'zipcrypt\\' \"\\n                    \"(the weak default), \\'aes128\\' and \\'aes256\\'.\"\\n                )\\n            options += \\',encryption\\' if options else \\'encryption\\'\\n        if options:\\n            if not isinstance(options, bytes):\\n                options = options.encode(\\'utf-8\\')\\n            ffi.write_set_options(archive_p, options)\\n        if passphrase:\\n            if not isinstance(passphrase, bytes):\\n                passphrase = passphrase.encode(\\'utf-8\\')\\n            try:\\n                ffi.write_set_passphrase(archive_p, passphrase)\\n            except AttributeError:\\n                raise NotImplementedError(\\n                    f\"the libarchive being used (version {ffi.version_number()}, \"\\n                    f\"path {ffi.libarchive_path}) doesn\\'t support encryption\"\\n                )\\n        yield archive_p\\n        ffi.write_close(archive_p)\\n        ffi.write_free(archive_p)\\n    except Exception:\\n        ffi.write_fail(archive_p)\\n        ffi.write_free(archive_p)\\n        raise\\n\\n\\n@contextmanager\\ndef custom_writer(\\n    write_func, format_name, filter_name=None,\\n    open_func=None, close_func=None, block_size=page_size,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n\\n    def write_cb_internal(archive_p, context, buffer_, length):\\n        data = cast(buffer_, POINTER(c_char * length))[0]\\n        return write_func(data)\\n\\n    open_cb = OPEN_CALLBACK(open_func) if open_func else NO_OPEN_CB\\n    write_cb = WRITE_CALLBACK(write_cb_internal)\\n    close_cb = CLOSE_CALLBACK(close_func) if close_func else NO_CLOSE_CB\\n\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_set_bytes_in_last_block(archive_p, 1)\\n        ffi.write_set_bytes_per_block(archive_p, block_size)\\n        ffi.write_open(archive_p, None, open_cb, write_cb, close_cb)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef fd_writer(\\n    fd, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_fd(archive_p, fd)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef file_writer(\\n    filepath, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        ffi.write_open_filename_w(archive_p, filepath)\\n        yield archive_write_class(archive_p)\\n\\n\\n@contextmanager\\ndef memory_writer(\\n    buf, format_name, filter_name=None,\\n    archive_write_class=ArchiveWrite, options=\\'\\', passphrase=None,\\n):\\n    with new_archive_write(format_name, filter_name, options,\\n                           passphrase) as archive_p:\\n        used = byref(c_size_t())\\n        buf_p = cast(buf, c_void_p)\\n        ffi.write_open_memory(archive_p, buf_p, len(buf), used)\\n        yield archive_write_class(archive_p)\\n'"}]}, "_ellipsize": {"line": 29, "args": [{"func_args": {"s": "'<_pytest.config.Config object at 0xffff9b5cb130>'", "maxsize": "240"}, "return_value": "'<_pytest.config.Config object at 0xffff9b5cb130>'"}, {"func_args": {"s": "'<_pytest.config.Config object at 0xffff9b5cb130>'", "maxsize": "240"}, "return_value": "'<_pytest.config.Config object at 0xffff9b5cb130>'"}, {"func_args": {"s": "'<function _main at 0xffff9b928700>'", "maxsize": "240"}, "return_value": "'<function _main at 0xffff9b928700>'"}, {"func_args": {"s": "'<function _main at 0xffff9b928700>'", "maxsize": "240"}, "return_value": "'<function _main at 0xffff9b928700>'"}, {"func_args": {"s": "'<_pytest.config.Config object at 0xffff9b5cb130>'", "maxsize": "240"}, "return_value": "'<_pytest.config.Config object at 0xffff9b5cb130>'"}, {"func_args": {"s": "'<_pytest.config.Config object at 0xffff9b5cb130>'", "maxsize": "240"}, "return_value": "'<_pytest.config.Config object at 0xffff9b5cb130>'"}, {"func_args": {"s": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'", "maxsize": "240"}, "return_value": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'"}, {"func_args": {"s": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'", "maxsize": "240"}, "return_value": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'"}, {"func_args": {"s": "\"<_HookCaller 'pytest_runtestloop'>\"", "maxsize": "240"}, "return_value": "\"<_HookCaller 'pytest_runtestloop'>\""}, {"func_args": {"s": "\"<_HookCaller 'pytest_runtestloop'>\"", "maxsize": "240"}, "return_value": "\"<_HookCaller 'pytest_runtestloop'>\""}, {"func_args": {"s": "'()'", "maxsize": "240"}, "return_value": "'()'"}, {"func_args": {"s": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'", "maxsize": "240"}, "return_value": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'"}, {"func_args": {"s": "\"{'session': <Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>}\"", "maxsize": "240"}, "return_value": "\"{'session': <Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>}\""}, {"func_args": {"s": "\"'session'\"", "maxsize": "240"}, "return_value": "\"'session'\""}, {"func_args": {"s": "'True'", "maxsize": "240"}, "return_value": "'True'"}, {"func_args": {"s": "'True'", "maxsize": "240"}, "return_value": "'True'"}, {"func_args": {"s": "'<_pytest.config.PytestPluginManager object at 0xffffa116c910>'", "maxsize": "240"}, "return_value": "'<_pytest.config.PytestPluginManager object at 0xffffa116c910>'"}, {"func_args": {"s": "'<_pytest.config.PytestPluginManager object at 0xffffa116c910>'", "maxsize": "240"}, "return_value": "'<_pytest.config.PytestPluginManager object at 0xffffa116c910>'"}, {"func_args": {"s": "\"'pytest_runtestloop'\"", "maxsize": "240"}, "return_value": "\"'pytest_runtestloop'\""}, {"func_args": {"s": "\"<HookImpl plugin_name='main', plugin=<module '_pytest.main' from '/usr/app/src/test_repos/python-libarchive-c/.tox/py38/lib/python3.8/site-packages/_pytest/main.py'>>\"", "maxsize": "240"}, "return_value": "\"<HookImpl plugin_name='main', plugin=<module '_pytest.main' from '/usr/app/src/test_repos/python-libarchive-c/.tox/py38/lib/python3.8/site-packages/_pytest/main.py'>>\""}, {"func_args": {"s": "\"<HookImpl plugin_name='_cov', plugin=<pytest_cov.plugin.CovPlugin object at 0xffff99da9610>>\"", "maxsize": "240"}, "return_value": "\"<HookImpl plugin_name='_cov', plugin=<pytest_cov.plugin.CovPlugin object at 0xffff99da9610>>\""}, {"func_args": {"s": "\"<HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0xffff999ed2e0>>\"", "maxsize": "240"}, "return_value": "\"<HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0xffff999ed2e0>>\""}, {"func_args": {"s": "\"[<HookImpl plugin_name='main', plugin=<module '_pytest.main' from '/usr/app/src/test_repos/python-libarchive-c/.tox/py38/lib/python3.8/site-packages/_pytest/main.py'>>, <HookImpl plugin_name='_cov', plugin=<pytest_cov.plugin.CovPlugin object at 0xffff99da9610>>, <HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0xffff999ed2e0>>]\"", "maxsize": "240"}, "return_value": "\"[<HookImpl plugin_name='main', plugin=<module '_pytest.main' from '/usr/app/src/test_repos/python-libarchive-c/.tox/py...ff99da9610>>, <HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0xffff999ed2e0>>]\""}, {"func_args": {"s": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'", "maxsize": "240"}, "return_value": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'"}, {"func_args": {"s": "\"{'session': <Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>}\"", "maxsize": "240"}, "return_value": "\"{'session': <Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>}\""}, {"func_args": {"s": "'True'", "maxsize": "240"}, "return_value": "'True'"}, {"func_args": {"s": "'True'", "maxsize": "240"}, "return_value": "'True'"}, {"func_args": {"s": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'", "maxsize": "240"}, "return_value": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'"}, {"func_args": {"s": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'", "maxsize": "240"}, "return_value": "'<Session python-libarchive-c exitstatus=<ExitCode.OK: 0> testsfailed=6 testscollected=0>'"}], "text": "def _ellipsize(s: str, maxsize: int) -> str:\n    if len(s) > maxsize:\n        i = max(0, (maxsize - 3) // 2)\n        j = max(0, maxsize - 3 - i)\n        return s[:i] + \"...\" + s[len(s) - j :]\n    return s"}, "wcwidth": {"line": 4, "args": [{"func_args": {"c": "'E'"}, "return_value": "1"}, {"func_args": {"c": "'R'"}, "return_value": "1"}, {"func_args": {"c": "'O'"}, "return_value": "1"}, {"func_args": {"c": "' '"}, "return_value": "1"}, {"func_args": {"c": "'t'"}, "return_value": "1"}, {"func_args": {"c": "'e'"}, "return_value": "1"}, {"func_args": {"c": "'s'"}, "return_value": "1"}, {"func_args": {"c": "'/'"}, "return_value": "1"}, {"func_args": {"c": "'_'"}, "return_value": "1"}, {"func_args": {"c": "'a'"}, "return_value": "1"}, {"func_args": {"c": "'i'"}, "return_value": "1"}, {"func_args": {"c": "'m'"}, "return_value": "1"}, {"func_args": {"c": "'c'"}, "return_value": "1"}, {"func_args": {"c": "'.'"}, "return_value": "1"}, {"func_args": {"c": "'p'"}, "return_value": "1"}, {"func_args": {"c": "'y'"}, "return_value": "1"}, {"func_args": {"c": "'-'"}, "return_value": "1"}, {"func_args": {"c": "'A'"}, "return_value": "1"}, {"func_args": {"c": "'r'"}, "return_value": "1"}, {"func_args": {"c": "'b'"}, "return_value": "1"}, {"func_args": {"c": "'u'"}, "return_value": "1"}, {"func_args": {"c": "'o'"}, "return_value": "1"}, {"func_args": {"c": "':'"}, "return_value": "1"}, {"func_args": {"c": "'h'"}, "return_value": "1"}, {"func_args": {"c": "'n'"}, "return_value": "1"}, {"func_args": {"c": "'l'"}, "return_value": "1"}, {"func_args": {"c": "'v'"}, "return_value": "1"}, {"func_args": {"c": "'x'"}, "return_value": "1"}, {"func_args": {"c": "'3'"}, "return_value": "1"}, {"func_args": {"c": "'8'"}, "return_value": "1"}, {"func_args": {"c": "'d'"}, "return_value": "1"}, {"func_args": {"c": "'f'"}, "return_value": "1"}, {"func_args": {"c": "'w'"}, "return_value": "1"}, {"func_args": {"c": "'g'"}, "return_value": "1"}]}, "wcswidth": {"line": 43, "args": [{"func_args": {"s": "'ERROR tests/test_atime_mtime_ctime.py'"}, "return_value": "37"}, {"func_args": {"s": "' - '"}, "return_value": "3"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'"}, "return_value": "122"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/'"}, "return_value": "40"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos'"}, "return_value": "39"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repo'"}, "return_value": "38"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_rep'"}, "return_value": "37"}, {"func_args": {"s": "'ERROR tests/test_convert.py'"}, "return_value": "27"}, {"func_args": {"s": "' - '"}, "return_value": "3"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'"}, "return_value": "122"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-lib'"}, "return_value": "50"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-li'"}, "return_value": "49"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-l'"}, "return_value": "48"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-'"}, "return_value": "47"}, {"func_args": {"s": "'ERROR tests/test_entry.py'"}, "return_value": "25"}, {"func_args": {"s": "' - '"}, "return_value": "3"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'"}, "return_value": "122"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libar'"}, "return_value": "52"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-liba'"}, "return_value": "51"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-lib'"}, "return_value": "50"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-li'"}, "return_value": "49"}, {"func_args": {"s": "'ERROR tests/test_errors.py'"}, "return_value": "26"}, {"func_args": {"s": "' - '"}, "return_value": "3"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'"}, "return_value": "122"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-liba'"}, "return_value": "51"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-lib'"}, "return_value": "50"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-li'"}, "return_value": "49"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-l'"}, "return_value": "48"}, {"func_args": {"s": "'ERROR tests/test_rwx.py'"}, "return_value": "23"}, {"func_args": {"s": "' - '"}, "return_value": "3"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'"}, "return_value": "122"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarch'"}, "return_value": "54"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarc'"}, "return_value": "53"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libar'"}, "return_value": "52"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-liba'"}, "return_value": "51"}, {"func_args": {"s": "'ERROR tests/test_security_flags.py'"}, "return_value": "34"}, {"func_args": {"s": "' - '"}, "return_value": "3"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/python-libarchive-c/.tox/py38/bin/python: undefined symbol: archive_version_number'"}, "return_value": "122"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/pyt'"}, "return_value": "43"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/py'"}, "return_value": "42"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/p'"}, "return_value": "41"}, {"func_args": {"s": "'AttributeError: /usr/app/src/test_repos/'"}, "return_value": "40"}], "text": "def wcswidth(s: str) -> int:\n    \"\"\"Determine how many columns are needed to display a string in a terminal.\n\n    Returns -1 if the string contains non-printable characters.\n    \"\"\"\n    width = 0\n    for c in unicodedata.normalize(\"NFC\", s):\n        wc = wcwidth(c)\n        if wc < 0:\n            return -1\n        width += wc\n    return width"}}